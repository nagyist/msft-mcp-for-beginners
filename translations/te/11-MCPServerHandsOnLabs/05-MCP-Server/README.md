<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "240e365cc324d23a0033e5615b5feb5e",
  "translation_date": "2025-12-11T14:33:00+00:00",
  "source_file": "11-MCPServerHandsOnLabs/05-MCP-Server/README.md",
  "language_code": "te"
}
-->
# MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞Ö‡∞Æ‡∞≤‡±Å

## üéØ ‡∞à ‡∞™‡±ç‡∞∞‡∞Ø‡±ã‡∞ó‡∞∂‡∞æ‡∞≤‡∞≤‡±ã ‡∞è‡∞Æ‡∞ø ‡∞®‡±á‡∞∞‡±ç‡∞ö‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡∞æ‡∞∞‡±Å

‡∞à ‡∞π‡±ç‡∞Ø‡∞æ‡∞Ç‡∞°‡±ç‡∞∏‡±ç-‡∞Ü‡∞®‡±ç ‡∞™‡±ç‡∞∞‡∞Ø‡±ã‡∞ó‡∞∂‡∞æ‡∞≤ FastMCP ‡∞´‡±ç‡∞∞‡±á‡∞Æ‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞™‡±ç‡∞∞‡±ä‡∞°‡∞ï‡±ç‡∞∑‡∞®‡±ç-‡∞∞‡±Ü‡∞°‡±Ä MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞Ö‡∞Æ‡∞≤‡±Å ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞®‡∞ø‡∞∞‡±ç‡∞¶‡±á‡∞∂‡∞Ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ï‡±ã‡∞∞‡±ç ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞æ‡∞£‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞ø, ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç‚Äå‡∞®‡±Å ‡∞Ö‡∞Æ‡∞≤‡±Å ‡∞ö‡±á‡∞∏‡∞ø, ‡∞°‡±á‡∞ü‡∞æ ‡∞Ø‡∞æ‡∞ï‡±ç‡∞∏‡±Ü‡∞∏‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞ü‡±Ç‡∞≤‡±ç‡∞∏‡±ç ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞ø, AI ‡∞Ü‡∞ß‡∞æ‡∞∞‡∞ø‡∞§ ‡∞∞‡∞ø‡∞ü‡±à‡∞≤‡±ç ‡∞µ‡∞ø‡∞∂‡±ç‡∞≤‡±á‡∞∑‡∞£‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞™‡±Å‡∞®‡∞æ‡∞¶‡∞ø ‡∞è‡∞∞‡±ç‡∞™‡∞æ‡∞ü‡±Å‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å.

## ‡∞Ö‡∞µ‡∞≤‡±ã‡∞ï‡∞®‡∞Ç

MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞Æ‡∞æ ‡∞∞‡∞ø‡∞ü‡±à‡∞≤‡±ç ‡∞µ‡∞ø‡∞∂‡±ç‡∞≤‡±á‡∞∑‡∞£ ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞æ‡∞∞‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞π‡±É‡∞¶‡∞Ø‡∞Ç. ‡∞á‡∞¶‡∞ø AI ‡∞Ö‡∞∏‡∞ø‡∞∏‡±ç‡∞ü‡±Ü‡∞Ç‡∞ü‡±ç‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å PostgreSQL ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞Æ‡∞ß‡±ç‡∞Ø ‡∞¨‡±ç‡∞∞‡∞ø‡∞°‡±ç‡∞ú‡±ç‚Äå‡∞ó‡∞æ ‡∞™‡∞®‡∞ø‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø, ‡∞µ‡±ç‡∞Ø‡∞æ‡∞™‡∞æ‡∞∞ ‡∞°‡±á‡∞ü‡∞æ‡∞ï‡±Å ‡∞∏‡±Å‡∞∞‡∞ï‡±ç‡∞∑‡∞ø‡∞§, ‡∞§‡±Ü‡∞≤‡∞ø‡∞µ‡±à‡∞® ‡∞Ø‡∞æ‡∞ï‡±ç‡∞∏‡±Ü‡∞∏‡±ç‚Äå‡∞®‡±Å ‡∞í‡∞ï ‡∞™‡±ç‡∞∞‡∞Æ‡∞æ‡∞£‡±Ä‡∞ï‡±É‡∞§ ‡∞™‡±ç‡∞∞‡±ã‡∞ü‡±ã‡∞ï‡∞æ‡∞≤‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.

‡∞à ‡∞™‡±ç‡∞∞‡∞Ø‡±ã‡∞ó‡∞∂‡∞æ‡∞≤ ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞Ç‡∞ü‡∞∞‡±ç‚Äå‡∞™‡±ç‡∞∞‡±à‡∞ú‡±ç ‡∞®‡∞Æ‡±Ç‡∞®‡∞æ‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞â‡∞§‡±ç‡∞§‡∞Æ ‡∞Ü‡∞ö‡∞æ‡∞∞‡∞æ‡∞≤‡∞®‡±Å ‡∞Ö‡∞®‡±Å‡∞∏‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞í‡∞ï ‡∞¨‡∞≤‡∞Æ‡±à‡∞®, ‡∞∏‡±ç‡∞ï‡±á‡∞≤‡∞¨‡±Å‡∞≤‡±ç MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‡∞®‡±á‡∞∞‡±ç‡∞™‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.

## ‡∞®‡±á‡∞∞‡±ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±á ‡∞≤‡∞ï‡±ç‡∞∑‡±ç‡∞Ø‡∞æ‡∞≤‡±Å

‡∞à ‡∞™‡±ç‡∞∞‡∞Ø‡±ã‡∞ó‡∞∂‡∞æ‡∞≤ ‡∞Æ‡±Å‡∞ó‡∞ø‡∞Ç‡∞™‡±Å ‡∞µ‡∞∞‡∞ï‡±Å, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ö‡±á‡∞Ø‡∞ó‡∞≤‡±Å‡∞ó‡±Å‡∞§‡∞æ‡∞∞‡±Å:

- **‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø** ‡∞∏‡∞∞‡±à‡∞® ‡∞Ü‡∞∞‡±ç‡∞ï‡∞ø‡∞ü‡±Ü‡∞ï‡±ç‡∞ö‡∞∞‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡∞Ç‡∞∏‡±ç‡∞•‡∞§‡±ã FastMCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç
- **‡∞Ö‡∞Æ‡∞≤‡±Å ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø** ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞™‡±Ç‡∞≤‡∞ø‡∞Ç‡∞ó‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞≤‡±ã‡∞™‡∞æ‡∞≤ ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£‡∞§‡±ã ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç
- **‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø** ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞∏‡±ç‡∞ï‡±Ä‡∞Æ‡∞æ ‡∞á‡∞Ç‡∞ü‡±ç‡∞∞‡±ã‡∞∏‡±ç‡∞™‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ï‡±ç‡∞µ‡±Ü‡∞∞‡±Ä ‡∞Ö‡∞Æ‡∞≤‡±Å ‡∞ï‡±ã‡∞∏‡∞Ç MCP ‡∞ü‡±Ç‡∞≤‡±ç‡∞∏‡±ç
- **‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø** ‡∞∞‡±ã ‡∞≤‡±Ü‡∞µ‡∞≤‡±ç ‡∞∏‡±Ü‡∞ï‡±ç‡∞Ø‡±Ç‡∞∞‡∞ø‡∞ü‡±Ä (RLS) ‡∞ï‡∞æ‡∞Ç‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£
- **‡∞ö‡±á‡∞∞‡±ç‡∞ö‡∞Ç‡∞°‡∞ø** ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞™‡∞∞‡±ç‡∞Ø‡∞µ‡±á‡∞ï‡±ç‡∞∑‡∞£ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡∞∞‡∞ø‡∞∂‡±Ä‡∞≤‡∞® ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞≤‡±Å
- **‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø** ‡∞Æ‡±Ä MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞Ö‡∞Æ‡∞≤‡±Å‡∞®‡±Å ‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞ø‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å VS ‡∞ï‡±ã‡∞°‡±ç‚Äå‡∞§‡±ã

## üìÅ ‡∞™‡±ç‡∞∞‡∞æ‡∞ú‡±Ü‡∞ï‡±ç‡∞ü‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞æ‡∞£‡∞Ç

MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞∏‡∞Ç‡∞∏‡±ç‡∞•‡∞®‡±Å ‡∞™‡∞∞‡∞ø‡∞∂‡±Ä‡∞≤‡∞ø‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç:

```
mcp_server/
‚îú‚îÄ‚îÄ __init__.py                 # Package initialization
‚îú‚îÄ‚îÄ config.py                   # Configuration management
‚îú‚îÄ‚îÄ health_check.py             # Health monitoring endpoints
‚îú‚îÄ‚îÄ sales_analysis.py           # Main MCP server implementation
‚îú‚îÄ‚îÄ sales_analysis_postgres.py  # Database integration layer
‚îî‚îÄ‚îÄ sales_analysis_text_embeddings.py  # AI/semantic search integration
```

## üîß ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£

### ‡∞é‡∞®‡±ç‡∞µ‡∞ø‡∞∞‡∞æ‡∞®‡±ç‚Äå‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç (`config.py`)

‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ó‡∞æ, ‡∞¨‡∞≤‡∞Æ‡±à‡∞® ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞∏‡∞ø‡∞∏‡±ç‡∞ü‡∞Æ‡±ç‚Äå‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç:

```python
# mcp_server/config.py
"""
Configuration management for the MCP server.
Handles environment variables, validation, and defaults.
"""
import os
import logging
from typing import Optional, Dict, Any
from dataclasses import dataclass
from dotenv import load_dotenv

# .env ‡∞´‡±à‡∞≤‡±ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞µ‡∞æ‡∞§‡∞æ‡∞µ‡∞∞‡∞£ ‡∞ö‡∞∞‡∞æ‡∞≤‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
load_dotenv()

logger = logging.getLogger(__name__)

@dataclass
class DatabaseConfig:
    """Database connection configuration."""
    host: str
    port: int
    database: str
    user: str
    password: str
    min_connections: int = 2
    max_connections: int = 10
    command_timeout: int = 30
    
    @classmethod
    def from_env(cls) -> 'DatabaseConfig':
        """Create configuration from environment variables."""
        return cls(
            host=os.getenv('POSTGRES_HOST', 'localhost'),
            port=int(os.getenv('POSTGRES_PORT', '5432')),
            database=os.getenv('POSTGRES_DB', 'zava'),
            user=os.getenv('POSTGRES_USER', 'postgres'),
            password=os.getenv('POSTGRES_PASSWORD', ''),
            min_connections=int(os.getenv('POSTGRES_MIN_CONNECTIONS', '2')),
            max_connections=int(os.getenv('POSTGRES_MAX_CONNECTIONS', '10')),
            command_timeout=int(os.getenv('POSTGRES_COMMAND_TIMEOUT', '30'))
        )
    
    def to_asyncpg_params(self) -> Dict[str, Any]:
        """Convert to asyncpg connection parameters."""
        return {
            'host': self.host,
            'port': self.port,
            'database': self.database,
            'user': self.user,
            'password': self.password,
            'command_timeout': self.command_timeout,
            'server_settings': {
                'application_name': 'zava-mcp-server',
                'jit': 'off',  # ‡∞∏‡±ç‡∞•‡∞ø‡∞∞‡∞§‡±ç‡∞µ‡∞Ç ‡∞ï‡±ã‡∞∏‡∞Ç JIT ‡∞®‡±Å ‡∞®‡∞ø‡∞≤‡∞ø‡∞™‡∞ø‡∞µ‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
                'work_mem': '4MB',
                'statement_timeout': f'{self.command_timeout}s'
            }
        }

@dataclass
class AzureConfig:
    """Azure AI services configuration."""
    project_endpoint: str
    openai_endpoint: str
    embedding_model_deployment: str
    client_id: str
    client_secret: str
    tenant_id: str
    
    @classmethod
    def from_env(cls) -> 'AzureConfig':
        """Create configuration from environment variables."""
        return cls(
            project_endpoint=os.getenv('PROJECT_ENDPOINT', ''),
            openai_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),
            embedding_model_deployment=os.getenv('EMBEDDING_MODEL_DEPLOYMENT_NAME', 'text-embedding-3-small'),
            client_id=os.getenv('AZURE_CLIENT_ID', ''),
            client_secret=os.getenv('AZURE_CLIENT_SECRET', ''),
            tenant_id=os.getenv('AZURE_TENANT_ID', '')
        )
    
    def is_configured(self) -> bool:
        """Check if all required Azure configuration is present."""
        return all([
            self.project_endpoint,
            self.openai_endpoint,
            self.client_id,
            self.client_secret,
            self.tenant_id
        ])

@dataclass
class ServerConfig:
    """MCP server configuration."""
    host: str = '0.0.0.0'
    port: int = 8000
    log_level: str = 'INFO'
    enable_cors: bool = True
    enable_health_check: bool = True
    applicationinsights_connection_string: Optional[str] = None
    
    @classmethod
    def from_env(cls) -> 'ServerConfig':
        """Create configuration from environment variables."""
        return cls(
            host=os.getenv('MCP_SERVER_HOST', '0.0.0.0'),
            port=int(os.getenv('MCP_SERVER_PORT', '8000')),
            log_level=os.getenv('LOG_LEVEL', 'INFO').upper(),
            enable_cors=os.getenv('ENABLE_CORS', 'true').lower() == 'true',
            enable_health_check=os.getenv('ENABLE_HEALTH_CHECK', 'true').lower() == 'true',
            applicationinsights_connection_string=os.getenv('APPLICATIONINSIGHTS_CONNECTION_STRING')
        )

class MCPServerConfig:
    """Main configuration class for the MCP server."""
    
    def __init__(self):
        self.database = DatabaseConfig.from_env()
        self.azure = AzureConfig.from_env()
        self.server = ServerConfig.from_env()
        
        # ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç‚Äå‡∞®‡±Å ‡∞ß‡±É‡∞µ‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        self._validate_config()
    
    def _validate_config(self):
        """Validate configuration and log warnings for missing values."""
        if not self.database.password:
            logger.warning("Database password is empty. This may cause connection issues.")
        
        if not self.azure.is_configured():
            logger.warning("Azure configuration is incomplete. AI features may not work.")
        
        logger.info(f"Configuration loaded - Database: {self.database.host}:{self.database.port}")
        logger.info(f"Server will run on {self.server.host}:{self.server.port}")

# ‡∞ó‡±ç‡∞≤‡±ã‡∞¨‡∞≤‡±ç ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£
config = MCPServerConfig()
```

### ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞≤‡±Å

- **‡∞é‡∞®‡±ç‡∞µ‡∞ø‡∞∞‡∞æ‡∞®‡±ç‚Äå‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç ‡∞µ‡±á‡∞∞‡∞ø‡∞Ø‡∞¨‡±Å‡∞≤‡±ç ‡∞≤‡±ã‡∞°‡∞ø‡∞Ç‡∞ó‡±ç**: ‡∞Ü‡∞ü‡±ã‡∞Æ‡±á‡∞ü‡∞ø‡∞ï‡±ç .env ‡∞´‡±à‡∞≤‡±ç ‡∞Æ‡∞¶‡±ç‡∞¶‡∞§‡±Å
- **‡∞ü‡±à‡∞™‡±ç ‡∞∏‡±á‡∞´‡±ç‡∞ü‡±Ä**: ‡∞°‡±á‡∞ü‡∞æ‡∞ï‡±ç‡∞≤‡∞æ‡∞∏‡±ç ‡∞ß‡±É‡∞µ‡±Ä‡∞ï‡∞∞‡∞£ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ü‡±à‡∞™‡±ç ‡∞∏‡±Ç‡∞ö‡∞®‡∞≤‡±Å
- **‡∞´‡±ç‡∞≤‡±Ü‡∞ï‡±ç‡∞∏‡∞ø‡∞¨‡±Å‡∞≤‡±ç ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç‡∞∏‡±ç**: ‡∞Ö‡∞≠‡∞ø‡∞µ‡±É‡∞¶‡±ç‡∞ß‡∞ø‡∞ï‡∞ø ‡∞Ö‡∞®‡±Å‡∞ï‡±Ç‡∞≤‡∞Æ‡±à‡∞® ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç‡∞∏‡±ç
- **‡∞ß‡±É‡∞µ‡±Ä‡∞ï‡∞∞‡∞£**: ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï ‡∞≤‡±ã‡∞™ ‡∞∏‡∞Ç‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡∞§‡±ã ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞ß‡±É‡∞µ‡±Ä‡∞ï‡∞∞‡∞£
- **‡∞∏‡±Ü‡∞ï‡±ç‡∞Ø‡±Ç‡∞∞‡∞ø‡∞ü‡±Ä**: ‡∞∏‡±Å‡∞®‡±ç‡∞®‡∞ø‡∞§‡∞Æ‡±à‡∞® ‡∞µ‡∞ø‡∞≤‡±Å‡∞µ‡∞≤‡±Å ‡∞ï‡±á‡∞µ‡∞≤‡∞Ç ‡∞é‡∞®‡±ç‡∞µ‡∞ø‡∞∞‡∞æ‡∞®‡±ç‚Äå‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç ‡∞µ‡±á‡∞∞‡∞ø‡∞Ø‡∞¨‡±Å‡∞≤‡±ç‡∞∏‡±ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø

## üóÑÔ∏è ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞≤‡±á‡∞Ø‡∞∞‡±ç

### PostgreSQL ‡∞™‡±ç‡∞∞‡±ä‡∞µ‡±à‡∞°‡∞∞‡±ç (`sales_analysis_postgres.py`)

‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞≤‡±á‡∞Ø‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞Ö‡∞Æ‡∞≤‡±Å ‡∞ö‡±á‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç:

```python
# mcp_server/sales_analysis_postgres.py
"""
PostgreSQL database integration for MCP server.
Handles connections, queries, and schema introspection.
"""
import asyncio
import asyncpg
import logging
from typing import Dict, Any, List, Optional, Tuple
from contextlib import asynccontextmanager
from datetime import datetime
import json

from .config import config

logger = logging.getLogger(__name__)

class PostgreSQLSchemaProvider:
    """Provides PostgreSQL database access and schema information."""
    
    def __init__(self):
        self.connection_pool: Optional[asyncpg.Pool] = None
        self.postgres_config = config.database.to_asyncpg_params()
        
    async def create_pool(self) -> None:
        """Create connection pool for database operations."""
        if self.connection_pool is None:
            try:
                self.connection_pool = await asyncpg.create_pool(
                    **self.postgres_config,
                    min_size=config.database.min_connections,
                    max_size=config.database.max_connections,
                    max_inactive_connection_lifetime=300  # 5 ‡∞®‡∞ø‡∞Æ‡∞ø‡∞∑‡∞æ‡∞≤‡±Å
                )
                logger.info("Database connection pool created successfully")
            except Exception as e:
                logger.error(f"Failed to create database connection pool: {e}")
                raise
    
    async def close_pool(self) -> None:
        """Close the connection pool."""
        if self.connection_pool:
            await self.connection_pool.close()
            self.connection_pool = None
            logger.info("Database connection pool closed")
    
    @asynccontextmanager
    async def get_connection(self):
        """Get a database connection from the pool."""
        if not self.connection_pool:
            await self.create_pool()
        
        async with self.connection_pool.acquire() as connection:
            yield connection
    
    async def set_rls_context(self, connection: asyncpg.Connection, rls_user_id: str) -> None:
        """Set Row Level Security context for the connection."""
        try:
            await connection.execute(
                "SELECT set_config('app.current_rls_user_id', $1, false)",
                rls_user_id
            )
            logger.debug(f"RLS context set for user: {rls_user_id}")
        except Exception as e:
            logger.error(f"Failed to set RLS context: {e}")
            raise
    
    async def get_table_schema(self, table_name: str, rls_user_id: str) -> Dict[str, Any]:
        """Get detailed schema information for a specific table."""
        async with self.get_connection() as conn:
            await self.set_rls_context(conn, rls_user_id)
            
            # ‡∞∏‡±ç‡∞ï‡±Ä‡∞Æ‡∞æ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡∞ü‡±ç‡∞ü‡∞ø‡∞ï ‡∞™‡±á‡∞∞‡±Å‡∞®‡±Å ‡∞™‡∞æ‡∞∞‡±ç‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
            if '.' in table_name:
                schema_name, table_name = table_name.split('.', 1)
            else:
                schema_name = 'retail'  # ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç ‡∞∏‡±ç‡∞ï‡±Ä‡∞Æ‡∞æ
            
            # ‡∞ï‡∞æ‡∞≤‡∞Æ‡±ç ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø
            columns_query = """
                SELECT 
                    column_name,
                    data_type,
                    is_nullable,
                    column_default,
                    character_maximum_length,
                    numeric_precision,
                    numeric_scale,
                    ordinal_position
                FROM information_schema.columns 
                WHERE table_schema = $1 AND table_name = $2
                ORDER BY ordinal_position
            """
            
            columns = await conn.fetch(columns_query, schema_name, table_name)
            
            if not columns:
                raise ValueError(f"Table {schema_name}.{table_name} not found or not accessible")
            
            # ‡∞´‡∞æ‡∞∞‡±Ü‡∞®‡±ç ‡∞ï‡±Ä ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞æ‡∞≤‡∞®‡±Å ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø
            fk_query = """
                SELECT 
                    kcu.column_name,
                    ccu.table_schema AS foreign_table_schema,
                    ccu.table_name AS foreign_table_name,
                    ccu.column_name AS foreign_column_name
                FROM information_schema.table_constraints tc
                JOIN information_schema.key_column_usage kcu 
                    ON tc.constraint_name = kcu.constraint_name
                JOIN information_schema.constraint_column_usage ccu 
                    ON ccu.constraint_name = tc.constraint_name
                WHERE tc.constraint_type = 'FOREIGN KEY' 
                    AND tc.table_schema = $1 
                    AND tc.table_name = $2
            """
            
            foreign_keys = await conn.fetch(fk_query, schema_name, table_name)
            
            # ‡∞∏‡±Ç‡∞ö‡∞ø‡∞ï‡∞≤‡∞®‡±Å ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø
            index_query = """
                SELECT 
                    indexname,
                    indexdef
                FROM pg_indexes 
                WHERE schemaname = $1 AND tablename = $2
            """
            
            indexes = await conn.fetch(index_query, schema_name, table_name)
            
            # ‡∞∏‡±ç‡∞ï‡±Ä‡∞Æ‡∞æ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞æ‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
            schema_info = {
                "table_name": f"{schema_name}.{table_name}",
                "columns": [
                    {
                        "name": col["column_name"],
                        "type": col["data_type"],
                        "nullable": col["is_nullable"] == "YES",
                        "default": col["column_default"],
                        "max_length": col["character_maximum_length"],
                        "precision": col["numeric_precision"],
                        "scale": col["numeric_scale"],
                        "position": col["ordinal_position"]
                    }
                    for col in columns
                ],
                "foreign_keys": [
                    {
                        "column": fk["column_name"],
                        "references": f"{fk['foreign_table_schema']}.{fk['foreign_table_name']}.{fk['foreign_column_name']}"
                    }
                    for fk in foreign_keys
                ],
                "indexes": [
                    {
                        "name": idx["indexname"],
                        "definition": idx["indexdef"]
                    }
                    for idx in indexes
                ]
            }
            
            return schema_info
    
    async def get_multiple_table_schemas(
        self, 
        table_names: List[str], 
        rls_user_id: str
    ) -> str:
        """Get schema information for multiple tables."""
        schemas = []
        
        for table_name in table_names:
            try:
                schema = await self.get_table_schema(table_name, rls_user_id)
                schemas.append(self._format_schema_for_ai(schema))
            except Exception as e:
                logger.warning(f"Failed to get schema for {table_name}: {e}")
                schemas.append(f"Error retrieving schema for {table_name}: {str(e)}")
        
        return "\n\n".join(schemas)
    
    def _format_schema_for_ai(self, schema: Dict[str, Any]) -> str:
        """Format schema information for AI consumption."""
        table_name = schema["table_name"]
        columns = schema["columns"]
        foreign_keys = schema["foreign_keys"]
        
        # ‡∞ï‡∞æ‡∞≤‡∞Æ‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞ö‡∞®‡∞æ‡∞≤‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        column_lines = []
        for col in columns:
            nullable = "NULL" if col["nullable"] else "NOT NULL"
            type_info = col["type"]
            
            if col["max_length"]:
                type_info += f"({col['max_length']})"
            elif col["precision"] and col["scale"]:
                type_info += f"({col['precision']},{col['scale']})"
            
            default_info = f" DEFAULT {col['default']}" if col["default"] else ""
            
            column_lines.append(f"  {col['name']} {type_info} {nullable}{default_info}")
        
        # ‡∞´‡∞æ‡∞∞‡±Ü‡∞®‡±ç ‡∞ï‡±Ä ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        fk_lines = []
        for fk in foreign_keys:
            fk_lines.append(f"  {fk['column']} -> {fk['references']}")
        
        # ‡∞ö‡∞¶‡∞µ‡∞¶‡∞ó‡∞ø‡∞® ‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞æ‡∞ü‡±ç‚Äå‡∞≤‡±ã ‡∞ï‡∞≤‡∞™‡∞Ç‡∞°‡∞ø
        schema_text = f"Table: {table_name}\n"
        schema_text += "Columns:\n" + "\n".join(column_lines)
        
        if fk_lines:
            schema_text += "\n\nForeign Keys:\n" + "\n".join(fk_lines)
        
        return schema_text
    
    async def execute_query(
        self, 
        sql_query: str, 
        rls_user_id: str,
        max_rows: int = 20
    ) -> str:
        """Execute a SQL query with Row Level Security context."""
        async with self.get_connection() as conn:
            await self.set_rls_context(conn, rls_user_id)
            
            try:
                # ‡∞í‡∞ï ‡∞ï‡±ç‡∞µ‡±Ü‡∞∞‡±Ä ‡∞ü‡±à‡∞Æ‡±å‡∞ü‡±ç ‡∞∏‡±Ü‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
                rows = await asyncio.wait_for(
                    conn.fetch(sql_query),
                    timeout=config.database.command_timeout
                )
                
                if not rows:
                    return "Query executed successfully. No rows returned."
                
                # ‡∞´‡∞≤‡∞ø‡∞§‡∞æ‡∞≤ ‡∞∏‡±Ü‡∞ü‡±ç ‡∞™‡∞∞‡∞ø‡∞Æ‡∞ø‡∞§‡∞ø
                limited_rows = rows[:max_rows]
                
                # ‡∞´‡∞≤‡∞ø‡∞§‡∞æ‡∞≤‡∞®‡±Å ‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞æ‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
                result = self._format_query_results(limited_rows, len(rows), max_rows)
                
                logger.info(f"Query executed successfully. Returned {len(limited_rows)} rows.")
                return result
                
            except asyncio.TimeoutError:
                error_msg = f"Query timeout after {config.database.command_timeout} seconds"
                logger.error(error_msg)
                raise Exception(error_msg)
            except Exception as e:
                logger.error(f"Query execution failed: {e}")
                raise
    
    def _format_query_results(
        self, 
        rows: List[asyncpg.Record], 
        total_rows: int,
        max_rows: int
    ) -> str:
        """Format query results for AI consumption."""
        if not rows:
            return "No results found."
        
        # ‡∞ï‡∞æ‡∞≤‡∞Æ‡±ç ‡∞™‡±á‡∞∞‡±ç‡∞≤‡∞®‡±Å ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø
        columns = list(rows[0].keys())
        
        # ‡∞π‡±Ü‡∞°‡±ç‡∞°‡∞∞‡±ç ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        result_lines = [f"Results ({len(rows)} of {total_rows} rows):"]
        result_lines.append("=" * 50)
        
        # ‡∞ï‡∞æ‡∞≤‡∞Æ‡±ç ‡∞π‡±Ü‡∞°‡±ç‡∞°‡∞∞‡±ç‡∞≤‡∞®‡±Å ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        header = " | ".join(columns)
        result_lines.append(header)
        result_lines.append("-" * len(header))
        
        # ‡∞°‡±á‡∞ü‡∞æ ‡∞µ‡∞∞‡±Å‡∞∏‡∞≤‡∞®‡±Å ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        for row in rows:
            formatted_values = []
            for col in columns:
                value = row[col]
                if value is None:
                    formatted_values.append("NULL")
                elif isinstance(value, datetime):
                    formatted_values.append(value.strftime("%Y-%m-%d %H:%M:%S"))
                elif isinstance(value, (dict, list)):
                    formatted_values.append(json.dumps(value))
                else:
                    formatted_values.append(str(value))
            
            result_lines.append(" | ".join(formatted_values))
        
        # ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Æ‡±à‡∞§‡±á ‡∞ü‡±ç‡∞∞‡∞Ç‡∞ï‡±á‡∞∑‡∞®‡±ç ‡∞®‡±ã‡∞ü‡±Ä‡∞∏‡±Å‡∞®‡±Å ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        if total_rows > max_rows:
            result_lines.append(f"\n... and {total_rows - max_rows} more rows (truncated for display)")
        
        return "\n".join(result_lines)
    
    async def get_current_utc_date(self) -> str:
        """Get current UTC date/time."""
        async with self.get_connection() as conn:
            result = await conn.fetchval("SELECT NOW() AT TIME ZONE 'UTC'")
            return result.isoformat() + "Z"
    
    async def health_check(self) -> Dict[str, Any]:
        """Perform database health check."""
        try:
            async with self.get_connection() as conn:
                # ‡∞∏‡∞æ‡∞¶‡∞æ ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞ü‡∞ø‡∞µ‡∞ø‡∞ü‡±Ä ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑
                result = await conn.fetchval("SELECT 1")
                
                # ‡∞™‡±Ç‡∞≤‡±ç ‡∞∏‡±ç‡∞•‡∞ø‡∞§‡∞ø‡∞®‡∞ø ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
                pool_info = {
                    "min_size": self.connection_pool._minsize if self.connection_pool else 0,
                    "max_size": self.connection_pool._maxsize if self.connection_pool else 0,
                    "current_size": self.connection_pool.get_size() if self.connection_pool else 0,
                    "idle_size": self.connection_pool.get_idle_size() if self.connection_pool else 0
                }
                
                return {
                    "status": "healthy",
                    "database_responsive": result == 1,
                    "pool_info": pool_info
                }
                
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e)
            }

# ‡∞ó‡±ç‡∞≤‡±ã‡∞¨‡∞≤‡±ç ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞™‡±ç‡∞∞‡±ä‡∞µ‡±à‡∞°‡∞∞‡±ç ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£
db_provider = PostgreSQLSchemaProvider()
```

### ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞≤‡±á‡∞Ø‡∞∞‡±ç ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞≤‡±Å

- **‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞™‡±Ç‡∞≤‡∞ø‡∞Ç‡∞ó‡±ç**: asyncpg ‡∞§‡±ã ‡∞∏‡∞Æ‡∞∞‡±ç‡∞•‡∞µ‡∞Ç‡∞§‡∞Æ‡±à‡∞® ‡∞µ‡∞®‡∞∞‡±Å‡∞≤ ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£
- **RLS ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç**: ‡∞Ü‡∞ü‡±ã‡∞Æ‡±á‡∞ü‡∞ø‡∞ï‡±ç ‡∞∞‡±ã ‡∞≤‡±Ü‡∞µ‡∞≤‡±ç ‡∞∏‡±Ü‡∞ï‡±ç‡∞Ø‡±Ç‡∞∞‡∞ø‡∞ü‡±Ä ‡∞ï‡∞æ‡∞Ç‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞∏‡±Ü‡∞ü‡±ç‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç
- **‡∞∏‡±ç‡∞ï‡±Ä‡∞Æ‡∞æ ‡∞á‡∞Ç‡∞ü‡±ç‡∞∞‡±ã‡∞∏‡±ç‡∞™‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç**: ‡∞°‡±à‡∞®‡∞Æ‡∞ø‡∞ï‡±ç ‡∞ü‡±á‡∞¨‡±Å‡∞≤‡±ç ‡∞∏‡±ç‡∞ï‡±Ä‡∞Æ‡∞æ ‡∞ï‡∞®‡±Å‡∞ó‡±ä‡∞®‡∞°‡∞Ç
- **‡∞≤‡±ã‡∞™‡∞æ‡∞≤ ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£**: ‡∞∏‡∞Æ‡∞ó‡±ç‡∞∞ ‡∞≤‡±ã‡∞™ ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞≤‡∞æ‡∞ó‡∞ø‡∞Ç‡∞ó‡±ç
- **‡∞ï‡±ç‡∞µ‡±Ü‡∞∞‡±Ä ‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞æ‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç**: AI-‡∞∏‡±ç‡∞®‡±á‡∞π‡∞™‡±Ç‡∞∞‡±ç‡∞µ‡∞ï ‡∞´‡∞≤‡∞ø‡∞§‡∞æ‡∞≤ ‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞æ‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç
- **‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞™‡∞∞‡±ç‡∞Ø‡∞µ‡±á‡∞ï‡±ç‡∞∑‡∞£**: ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞ü‡∞ø‡∞µ‡∞ø‡∞ü‡±Ä ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±Ç‡∞≤‡±ç ‡∞∏‡±ç‡∞•‡∞ø‡∞§‡∞ø ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä‡∞≤‡±Å

## üîß ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞Ö‡∞Æ‡∞≤‡±Å

### FastMCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç (`sales_analysis.py`)

‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞Ö‡∞Æ‡∞≤‡±Å ‡∞ö‡±á‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç:

```python
# mcp_server/sales_analysis.py
"""
Main MCP server implementation for Zava Retail Sales Analysis.
Provides AI assistants with secure access to retail database.
"""
import logging
import asyncio
from typing import Dict, Any, List, Annotated
from contextlib import asynccontextmanager

from fastmcp import FastMCP, Context
from pydantic import Field

from .config import config
from .sales_analysis_postgres import db_provider
from .health_check import setup_health_endpoints

# ‡∞≤‡∞æ‡∞ó‡∞ø‡∞Ç‡∞ó‡±ç‚Äå‡∞®‡±Å ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
logging.basicConfig(
    level=getattr(logging, config.server.log_level),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastMCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞á‡∞®‡±ç‡∞∏‡±ç‡∞ü‡∞æ‡∞®‡±ç‡∞∏‡±ç ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
mcp = FastMCP("Zava Retail Sales Analysis")

# ‡∞∏‡±ç‡∞ï‡±Ä‡∞Æ‡∞æ ‡∞Ø‡∞æ‡∞ï‡±ç‡∞∏‡±Ü‡∞∏‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞ö‡±Ü‡∞≤‡±ç‡∞≤‡±Å‡∞¨‡∞æ‡∞ü‡±Å ‡∞Ö‡∞Ø‡±ç‡∞Ø‡±á ‡∞™‡∞ü‡±ç‡∞ü‡∞ø‡∞ï‡∞≤ ‡∞ú‡∞æ‡∞¨‡∞ø‡∞§‡∞æ
VALID_TABLES = [
    "retail.stores",
    "retail.customers", 
    "retail.categories",
    "retail.product_types",
    "retail.products",
    "retail.orders",
    "retail.order_items",
    "retail.inventory"
]

def get_rls_user_id(ctx: Context) -> str:
    """Extract Row Level Security User ID from request context."""
    # HTTP ‡∞Æ‡±ã‡∞°‡±ç‚Äå‡∞≤‡±ã, ‡∞π‡±Ü‡∞°‡±ç‡∞°‡∞∞‡±ç‡∞≤ ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø
    if hasattr(ctx, 'headers') and ctx.headers:
        rls_user_id = ctx.headers.get("x-rls-user-id")
        if rls_user_id:
            logger.debug(f"RLS User ID from headers: {rls_user_id}")
            return rls_user_id
    
    # ‡∞Ö‡∞≠‡∞ø‡∞µ‡±É‡∞¶‡±ç‡∞ß‡∞ø/‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑ ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç ‡∞´‡∞æ‡∞≤‡±ç‡∞¨‡±ç‡∞Ø‡∞æ‡∞ï‡±ç
    default_id = "00000000-0000-0000-0000-000000000000"
    logger.warning(f"No RLS User ID found, using default: {default_id}")
    return default_id

@mcp.tool()
async def get_multiple_table_schemas(
    ctx: Context,
    table_names: Annotated[List[str], Field(description="List of table names to retrieve schemas for. Valid tables: " + ", ".join(VALID_TABLES))]
) -> str:
    """
    Retrieve database schemas for multiple tables in a single request.
    
    This tool provides comprehensive schema information including:
    - Column names, types, and constraints
    - Foreign key relationships
    - Index information
    - Table structure for AI query planning
    
    Args:
        table_names: List of valid table names from the retail schema
        
    Returns:
        Formatted schema information for all requested tables
    """
    rls_user_id = get_rls_user_id(ctx)
    
    # ‡∞™‡∞ü‡±ç‡∞ü‡∞ø‡∞ï ‡∞™‡±á‡∞∞‡±ç‡∞≤‡∞®‡±Å ‡∞ß‡±É‡∞µ‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
    invalid_tables = [table for table in table_names if table not in VALID_TABLES]
    if invalid_tables:
        logger.warning(f"Invalid table names requested: {invalid_tables}")
        return f"Error: Invalid table names: {', '.join(invalid_tables)}. Valid tables are: {', '.join(VALID_TABLES)}"
    
    try:
        logger.info(f"Retrieving schemas for tables: {table_names} (User: {rls_user_id})")
        result = await db_provider.get_multiple_table_schemas(table_names, rls_user_id)
        return result
    except Exception as e:
        logger.error(f"Error retrieving table schemas: {e}")
        return f"Error retrieving table schemas: {e!s}"

@mcp.tool()
async def execute_sales_query(
    ctx: Context,
    postgresql_query: Annotated[str, Field(description="A well-formed PostgreSQL query to execute against the retail database. Always get table schemas first before writing queries.")]
) -> str:
    """
    Execute PostgreSQL queries against the retail sales database with Row Level Security.
    
    This tool allows AI assistants to run analytical queries on retail data including:
    - Sales performance analysis
    - Customer behavior insights  
    - Inventory management queries
    - Product performance metrics
    - Store-specific reporting
    
    Important: Row Level Security ensures users only see data they're authorized to access.
    
    Args:
        postgresql_query: SQL query to execute (automatically filtered by RLS)
        
    Returns:
        Query results formatted for AI analysis (limited to 20 rows for readability)
    """
    rls_user_id = get_rls_user_id(ctx)
    
    try:
        logger.info(f"Executing query for user: {rls_user_id}")
        logger.debug(f"Query: {postgresql_query[:100]}...")
        
        result = await db_provider.execute_query(postgresql_query, rls_user_id)
        return result
    except Exception as e:
        logger.error(f"Error executing database query: {e}")
        return f"Error executing database query: {e!s}"

@mcp.tool()
async def get_current_utc_date(ctx: Context) -> str:
    """
    Get the current UTC date and time in ISO format.
    
    Useful for time-sensitive queries and date-based analysis.
    
    Returns:
        Current UTC date/time in ISO format (YYYY-MM-DDTHH:MM:SS.fffffZ)
    """
    try:
        result = await db_provider.get_current_utc_date()
        logger.debug(f"Current UTC date retrieved: {result}")
        return result
    except Exception as e:
        logger.error(f"Error getting current UTC date: {e}")
        return f"Error getting current UTC date: {e!s}"

# ‡∞Ö‡∞™‡±ç‡∞≤‡∞ø‡∞ï‡±á‡∞∑‡∞®‡±ç ‡∞ú‡±Ä‡∞µ‡∞® ‡∞ö‡∞ï‡±ç‡∞∞ ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£
@asynccontextmanager
async def lifespan(app):
    """Manage application startup and shutdown."""
    logger.info("Starting Zava Retail MCP Server...")
    
    try:
        # ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞™‡±Ç‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        await db_provider.create_pool()
        logger.info("Database connection pool initialized")
        
        # ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞ü‡∞ø‡∞µ‡∞ø‡∞ü‡±Ä‡∞®‡∞ø ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        health_status = await db_provider.health_check()
        if health_status["status"] != "healthy":
            logger.error(f"Database health check failed: {health_status}")
            raise Exception("Database not healthy")
        
        logger.info("MCP Server startup complete")
        yield
        
    except Exception as e:
        logger.error(f"Startup failed: {e}")
        raise
    finally:
        # ‡∞∂‡±Å‡∞≠‡±ç‡∞∞‡∞™‡∞∞‡∞ö‡∞°‡∞Ç
        logger.info("Shutting down MCP Server...")
        await db_provider.close_pool()
        logger.info("MCP Server shutdown complete")

# ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞Ö‡∞™‡±ç‡∞≤‡∞ø‡∞ï‡±á‡∞∑‡∞®‡±ç‚Äå‡∞®‡±Å ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
def create_app():
    """Create and configure the MCP server application."""
    
    # FastMCP ‡∞Ø‡∞æ‡∞™‡±ç ‡∞á‡∞®‡±ç‡∞∏‡±ç‡∞ü‡∞æ‡∞®‡±ç‡∞∏‡±ç‚Äå‡∞®‡±Å ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø
    app = mcp.sse_app()
    
    # ‡∞ú‡±Ä‡∞µ‡∞® ‡∞ö‡∞ï‡±ç‡∞∞ ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£‡∞®‡±Å ‡∞∏‡±Ü‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
    app.router.lifespan_context = lifespan
    
    # ‡∞é‡∞®‡±á‡∞¨‡±Å‡∞≤‡±ç ‡∞Ö‡∞Ø‡∞ø‡∞§‡±á ‡∞π‡±Ü‡∞≤‡±ç‡∞§‡±ç ‡∞ö‡±Ü‡∞ï‡±ç ‡∞é‡∞Ç‡∞°‡±ç‡∞™‡∞æ‡∞Ø‡∞ø‡∞Ç‡∞ü‡±ç‡∞≤‡∞®‡±Å ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
    if config.server.enable_health_check:
        setup_health_endpoints(app, db_provider)
    
    # ‡∞é‡∞®‡±á‡∞¨‡±Å‡∞≤‡±ç ‡∞Ö‡∞Ø‡∞ø‡∞§‡±á CORS ‡∞®‡±Å ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
    if config.server.enable_cors:
        from fastapi.middleware.cors import CORSMiddleware
        app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],  # ‡∞â‡∞§‡±ç‡∞™‡∞§‡±ç‡∞§‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞§‡∞ó‡∞ø‡∞® ‡∞µ‡∞ø‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
    
    logger.info(f"MCP Server configured - CORS: {config.server.enable_cors}, Health: {config.server.enable_health_check}")
    
    return app

# ‡∞Ö‡∞™‡±ç‡∞≤‡∞ø‡∞ï‡±á‡∞∑‡∞®‡±ç ‡∞á‡∞®‡±ç‡∞∏‡±ç‡∞ü‡∞æ‡∞®‡±ç‡∞∏‡±ç ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
app = create_app()

# ‡∞Ö‡∞≠‡∞ø‡∞µ‡±É‡∞¶‡±ç‡∞ß‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞™‡±ç‡∞∞‡∞µ‡±á‡∞∂ ‡∞¨‡∞ø‡∞Ç‡∞¶‡±Å‡∞µ‡±Å
if __name__ == "__main__":
    import uvicorn
    
    logger.info(f"Starting development server on {config.server.host}:{config.server.port}")
    
    uvicorn.run(
        "sales_analysis:app",
        host=config.server.host,
        port=config.server.port,
        reload=True,
        log_level=config.server.log_level.lower()
    )
```

### ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞≤‡∞ï‡±ç‡∞∑‡∞£‡∞æ‡∞≤‡±Å

- **‡∞ü‡±Ç‡∞≤‡±ç ‡∞∞‡∞ø‡∞ú‡∞ø‡∞∏‡±ç‡∞ü‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç**: ‡∞ü‡±à‡∞™‡±ç ‡∞∏‡±á‡∞´‡±ç‡∞ü‡±Ä‡∞§‡±ã ‡∞°‡∞ø‡∞ï‡±ç‡∞≤‡∞∞‡±á‡∞ü‡∞ø‡∞µ‡±ç ‡∞ü‡±Ç‡∞≤‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞ö‡∞®‡∞≤‡±Å
- **RLS ‡∞ï‡∞æ‡∞Ç‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£**: ‡∞Ü‡∞ü‡±ã‡∞Æ‡±á‡∞ü‡∞ø‡∞ï‡±ç ‡∞Ø‡±Ç‡∞ú‡∞∞‡±ç ‡∞ê‡∞°‡±Ü‡∞Ç‡∞ü‡∞ø‡∞ü‡±Ä ‡∞é‡∞ï‡±ç‡∞∏‡±ç‚Äå‡∞ü‡±ç‡∞∞‡∞æ‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ï‡∞æ‡∞Ç‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞∏‡±Ü‡∞ü‡±ç‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç
- **‡∞≤‡±ã‡∞™‡∞æ‡∞≤ ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£**: ‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó‡∞¶‡∞æ‡∞∞‡±Å‡∞≤‡∞ï‡±Å ‡∞∏‡±ç‡∞®‡±á‡∞π‡∞™‡±Ç‡∞∞‡±ç‡∞µ‡∞ï ‡∞∏‡∞Ç‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡∞§‡±ã ‡∞∏‡∞Æ‡∞ó‡±ç‡∞∞ ‡∞≤‡±ã‡∞™ ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£
- **‡∞≤‡±à‡∞´‡±ç‚Äå‡∞∏‡±à‡∞ï‡∞ø‡∞≤‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£**: ‡∞∏‡∞∞‡±à‡∞® ‡∞∏‡±ç‡∞ü‡∞æ‡∞∞‡±ç‡∞ü‡±ç‚Äå‡∞Ö‡∞™‡±ç/‡∞∑‡∞ü‡±ç‚Äå‡∞°‡±å‡∞®‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡∞®‡∞∞‡±Å ‡∞∂‡±Å‡∞≠‡±ç‡∞∞‡∞™‡∞∞‡∞ø‡∞ö‡±á ‡∞™‡±ç‡∞∞‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø
- **‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞™‡∞∞‡±ç‡∞Ø‡∞µ‡±á‡∞ï‡±ç‡∞∑‡∞£**: ‡∞¨‡∞ø‡∞≤‡±ç‡∞ü‡±ç-‡∞á‡∞®‡±ç ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞é‡∞Ç‡∞°‡±ç‡∞™‡∞æ‡∞Ø‡∞ø‡∞Ç‡∞ü‡±ç‡∞≤‡±Å
- **‡∞Ö‡∞≠‡∞ø‡∞µ‡±É‡∞¶‡±ç‡∞ß‡∞ø ‡∞Æ‡∞¶‡±ç‡∞¶‡∞§‡±Å**: ‡∞π‡∞æ‡∞ü‡±ç ‡∞∞‡±Ä‡∞≤‡±ã‡∞°‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞°‡±Ä‡∞¨‡∞ó‡±ç‡∞ó‡∞ø‡∞Ç‡∞ó‡±ç ‡∞∏‡∞æ‡∞Æ‡∞∞‡±ç‡∞•‡±ç‡∞Ø‡∞æ‡∞≤‡±Å

## üè• ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞™‡∞∞‡±ç‡∞Ø‡∞µ‡±á‡∞ï‡±ç‡∞∑‡∞£

### ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞Ö‡∞Æ‡∞≤‡±Å (`health_check.py`)

```python
# mcp_server/health_check.py
"""
Health check endpoints for monitoring MCP server status.
"""
import logging
from typing import Dict, Any
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse

logger = logging.getLogger(__name__)

def setup_health_endpoints(app: FastAPI, db_provider) -> None:
    """Add health check endpoints to the FastAPI application."""
    
    @app.get("/health")
    async def health_check() -> JSONResponse:
        """Basic health check endpoint."""
        return JSONResponse(
            status_code=200,
            content={
                "status": "healthy",
                "service": "zava-retail-mcp-server",
                "timestamp": await db_provider.get_current_utc_date()
            }
        )
    
    @app.get("/health/detailed")
    async def detailed_health_check() -> JSONResponse:
        """Detailed health check including database connectivity."""
        health_status = {
            "service": "zava-retail-mcp-server",
            "status": "healthy",
            "components": {}
        }
        
        overall_healthy = True
        
        # ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç‚Äå‡∞®‡±Å ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
        try:
            db_health = await db_provider.health_check()
            health_status["components"]["database"] = db_health
            
            if db_health["status"] != "healthy":
                overall_healthy = False
                
        except Exception as e:
            health_status["components"]["database"] = {
                "status": "unhealthy",
                "error": str(e)
            }
            overall_healthy = False
        
        # ‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç ‡∞∏‡±ç‡∞•‡∞ø‡∞§‡∞ø‡∞®‡∞ø ‡∞®‡∞µ‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        if not overall_healthy:
            health_status["status"] = "unhealthy"
        
        status_code = 200 if overall_healthy else 503
        
        return JSONResponse(
            status_code=status_code,
            content=health_status
        )
    
    @app.get("/health/ready")
    async def readiness_check() -> JSONResponse:
        """Kubernetes readiness probe endpoint."""
        try:
            # ‡∞ï‡±Ä‡∞≤‡∞ï ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡∞æ‡∞≤‡∞ø‡∞ü‡±Ä‡∞®‡∞ø ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
            db_health = await db_provider.health_check()
            
            if db_health["status"] != "healthy":
                raise HTTPException(status_code=503, detail="Database not ready")
            
            return JSONResponse(
                status_code=200,
                content={"status": "ready"}
            )
            
        except Exception as e:
            logger.error(f"Readiness check failed: {e}")
            raise HTTPException(status_code=503, detail="Service not ready")
    
    @app.get("/health/live")
    async def liveness_check() -> JSONResponse:
        """Kubernetes liveness probe endpoint."""
        return JSONResponse(
            status_code=200,
            content={"status": "alive"}
        )
    
    logger.info("Health check endpoints configured")
```

## üß™ ‡∞Æ‡±Ä MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç

### ‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞ø‡∞ï ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑

1. **MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø**:
   ```bash
   # ‡∞µ‡∞∞‡±ç‡∞ö‡±Å‡∞µ‡∞≤‡±ç ‡∞é‡∞®‡±ç‡∞µ‡∞ø‡∞∞‡∞æ‡∞®‡±ç‚Äå‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
   source mcp-env/bin/activate  # macOS/Linux
   # mcp-env\Scripts\activate   # Windows
   
   # ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
   cd mcp_server
   python sales_analysis.py
   ```

2. **‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞é‡∞Ç‡∞°‡±ç‡∞™‡∞æ‡∞Ø‡∞ø‡∞Ç‡∞ü‡±ç‡∞≤‡∞®‡±Å ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø**:
   ```bash
   # ‡∞™‡±ç‡∞∞‡∞æ‡∞•‡∞Æ‡∞ø‡∞ï ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä
   curl http://localhost:8000/health
   
   # ‡∞µ‡∞ø‡∞™‡±Å‡∞≤‡∞Æ‡±à‡∞® ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä
   curl http://localhost:8000/health/detailed
   ```

3. **MCP ‡∞ü‡±Ç‡∞≤‡±ç‡∞∏‡±ç‚Äå‡∞®‡±Å ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø**:
   ```bash
   # ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞¨‡∞æ‡∞ü‡±Å‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® ‡∞∏‡∞æ‡∞ß‡∞®‡∞æ‡∞≤‡∞®‡±Å ‡∞ú‡∞æ‡∞¨‡∞ø‡∞§‡∞æ ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
   curl -X POST http://localhost:8000/mcp \
     -H "Content-Type: application/json" \
     -H "x-rls-user-id: 00000000-0000-0000-0000-000000000000" \
     -d '{"method": "tools/list", "params": {}}'
   
   # ‡∞™‡∞ü‡±ç‡∞ü‡∞ø‡∞ï ‡∞∏‡±ç‡∞ï‡±Ä‡∞Æ‡∞æ‡∞≤‡∞®‡±Å ‡∞™‡±ä‡∞Ç‡∞¶‡∞Ç‡∞°‡∞ø
   curl -X POST http://localhost:8000/mcp \
     -H "Content-Type: application/json" \
     -H "x-rls-user-id: 00000000-0000-0000-0000-000000000000" \
     -d '{
       "method": "tools/call",
       "params": {
         "name": "get_multiple_table_schemas",
         "arguments": {
           "table_names": ["retail.stores", "retail.products"]
         }
       }
     }'
   ```

### VS ‡∞ï‡±ã‡∞°‡±ç ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑

1. **VS ‡∞ï‡±ã‡∞°‡±ç MCP ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø**:
   ```json
   // .vscode/mcp.json
   {
       "servers": {
           "zava-retail-test": {
               "url": "http://127.0.0.1:8000/mcp",
               "type": "http",
               "headers": {"x-rls-user-id": "00000000-0000-0000-0000-000000000000"}
           }
       }
   }
   ```

2. **AI ‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞≤‡±ã ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø**:
   - VS ‡∞ï‡±ã‡∞°‡±ç AI ‡∞ö‡∞æ‡∞ü‡±ç ‡∞§‡±Ü‡∞∞‡∞µ‡∞Ç‡∞°‡∞ø
   - `#zava` ‡∞ü‡±à‡∞™‡±ç ‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡±Ä ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç‚Äå‡∞®‡±Å ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø
   - ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø: "‡∞è ‡∞ü‡±á‡∞¨‡±Å‡∞≤‡±ç‡∞∏‡±ç ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞¨‡∞æ‡∞ü‡±Å‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø?"
   - ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø: "‡∞Ü‡∞∞‡±ç‡∞°‡∞∞‡±ç‡∞≤ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø ‡∞Ü‡∞ß‡∞æ‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞ü‡∞æ‡∞™‡±ç 5 ‡∞∏‡±ç‡∞ü‡±ã‡∞∞‡±ç‡∞≤‡∞®‡±Å ‡∞ö‡±Ç‡∞™‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø"

### ‡∞Ø‡±Ç‡∞®‡∞ø‡∞ü‡±ç ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑

‡∞∏‡∞Æ‡∞ó‡±ç‡∞∞ ‡∞Ø‡±Ç‡∞®‡∞ø‡∞ü‡±ç ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞≤‡∞®‡±Å ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø:

```python
# ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞≤‡±Å/test_mcp_server.py
import pytest
import asyncio
from mcp_server.sales_analysis_postgres import PostgreSQLSchemaProvider
from mcp_server.config import config

@pytest.mark.asyncio
async def test_database_connection():
    """Test database connectivity."""
    db = PostgreSQLSchemaProvider()
    
    try:
        await db.create_pool()
        health = await db.health_check()
        assert health["status"] == "healthy"
    finally:
        await db.close_pool()

@pytest.mark.asyncio
async def test_table_schema_retrieval():
    """Test table schema retrieval."""
    db = PostgreSQLSchemaProvider()
    
    try:
        await db.create_pool()
        schema = await db.get_table_schema("retail.stores", "00000000-0000-0000-0000-000000000000")
        
        assert schema["table_name"] == "retail.stores"
        assert len(schema["columns"]) > 0
        
    finally:
        await db.close_pool()

@pytest.mark.asyncio
async def test_query_execution():
    """Test query execution with RLS."""
    db = PostgreSQLSchemaProvider()
    
    try:
        await db.create_pool()
        result = await db.execute_query(
            "SELECT COUNT(*) as store_count FROM retail.stores",
            "00000000-0000-0000-0000-000000000000"
        )
        
        assert "store_count" in result
        
    finally:
        await db.close_pool()
```

## üéØ ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞™‡∞æ‡∞†‡∞æ‡∞≤‡±Å

‡∞à ‡∞™‡±ç‡∞∞‡∞Ø‡±ã‡∞ó‡∞∂‡∞æ‡∞≤ ‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø ‡∞ö‡±á‡∞∏‡∞ø‡∞® ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§, ‡∞Æ‡±Ä ‡∞µ‡∞¶‡±ç‡∞¶ ‡∞â‡∞Ç‡∞°‡∞æ‡∞≤‡∞ø:

‚úÖ **‡∞™‡∞®‡∞ø‡∞ö‡±á‡∞∏‡±á MCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç**: ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç‚Äå‡∞§‡±ã FastMCP ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç  
‚úÖ **‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£**: ‡∞¨‡∞≤‡∞Æ‡±à‡∞® ‡∞é‡∞®‡±ç‡∞µ‡∞ø‡∞∞‡∞æ‡∞®‡±ç‚Äå‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç ‡∞Ü‡∞ß‡∞æ‡∞∞‡∞ø‡∞§ ‡∞ï‡∞æ‡∞®‡±ç‡∞´‡∞ø‡∞ó‡∞∞‡±á‡∞∑‡∞®‡±ç  
‚úÖ **‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞≤‡±á‡∞Ø‡∞∞‡±ç**: ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞™‡±Ç‡∞≤‡∞ø‡∞Ç‡∞ó‡±ç‚Äå‡∞§‡±ã PostgreSQL ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç  
‚úÖ **MCP ‡∞ü‡±Ç‡∞≤‡±ç‡∞∏‡±ç**: ‡∞∏‡±ç‡∞ï‡±Ä‡∞Æ‡∞æ ‡∞á‡∞Ç‡∞ü‡±ç‡∞∞‡±ã‡∞∏‡±ç‡∞™‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ï‡±ç‡∞µ‡±Ü‡∞∞‡±Ä ‡∞Ö‡∞Æ‡∞≤‡±Å ‡∞ü‡±Ç‡∞≤‡±ç‡∞∏‡±ç  
‚úÖ **RLS ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç**: ‡∞∞‡±ã ‡∞≤‡±Ü‡∞µ‡∞≤‡±ç ‡∞∏‡±Ü‡∞ï‡±ç‡∞Ø‡±Ç‡∞∞‡∞ø‡∞ü‡±Ä ‡∞ï‡∞æ‡∞Ç‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£  
‚úÖ **‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞™‡∞∞‡±ç‡∞Ø‡∞µ‡±á‡∞ï‡±ç‡∞∑‡∞£**: ‡∞∏‡∞Æ‡∞ó‡±ç‡∞∞ ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞é‡∞Ç‡∞°‡±ç‡∞™‡∞æ‡∞Ø‡∞ø‡∞Ç‡∞ü‡±ç‡∞≤‡±Å  
‚úÖ **‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑‡∞æ ‡∞µ‡±ç‡∞Ø‡±Ç‡∞π‡∞Ç**: ‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞ø‡∞ï ‡∞™‡∞∞‡±Ä‡∞ï‡±ç‡∞∑ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å VS ‡∞ï‡±ã‡∞°‡±ç ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç  

## üöÄ ‡∞§‡∞¶‡±Å‡∞™‡∞∞‡∞ø ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø

**[Lab 06: Tool Development](../06-Tools/README.md)** ‡∞§‡±ã ‡∞ï‡±ä‡∞®‡∞∏‡∞æ‡∞ó‡∞Ç‡∞°‡∞ø:

- ‡∞Æ‡±Ä MCP ‡∞ü‡±Ç‡∞≤‡±ç ‡∞∏‡±á‡∞ï‡∞∞‡∞£‡∞®‡±Å ‡∞µ‡∞ø‡∞∏‡±ç‡∞§‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
- ‡∞Ö‡∞ß‡±Å‡∞®‡∞æ‡∞§‡∞® ‡∞ï‡±ç‡∞µ‡±Ü‡∞∞‡±Ä ‡∞®‡∞Æ‡±Ç‡∞®‡∞æ‡∞≤‡∞®‡±Å ‡∞Ö‡∞Æ‡∞≤‡±Å ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
- ‡∞°‡±á‡∞ü‡∞æ ‡∞ß‡±É‡∞µ‡±Ä‡∞ï‡∞∞‡∞£ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Æ‡∞æ‡∞∞‡±ç‡∞™‡∞ø‡∞°‡∞ø ‡∞ö‡±á‡∞∞‡±ç‡∞ö‡∞Ç‡∞°‡∞ø
- ‡∞™‡±ç‡∞∞‡∞§‡±ç‡∞Ø‡±á‡∞ï ‡∞µ‡∞ø‡∞∂‡±ç‡∞≤‡±á‡∞∑‡∞£ ‡∞ü‡±Ç‡∞≤‡±ç‡∞∏‡±ç ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø

## üìö ‡∞Ö‡∞¶‡∞®‡∞™‡±Å ‡∞µ‡∞®‡∞∞‡±Å‡∞≤‡±Å

### FastMCP ‡∞´‡±ç‡∞∞‡±á‡∞Æ‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç
- [FastMCP ‡∞°‡∞æ‡∞ï‡±ç‡∞Ø‡±Å‡∞Æ‡±Ü‡∞Ç‡∞ü‡±á‡∞∑‡∞®‡±ç](https://github.com/modelcontextprotocol/python-sdk) - ‡∞Ö‡∞ß‡∞ø‡∞ï‡∞æ‡∞∞‡∞ø‡∞ï FastMCP ‡∞ó‡±à‡∞°‡±ç
- [MCP ‡∞∏‡±ç‡∞™‡±Ü‡∞∏‡∞ø‡∞´‡∞ø‡∞ï‡±á‡∞∑‡∞®‡±ç](https://modelcontextprotocol.io/docs/) - ‡∞™‡±ç‡∞∞‡±ã‡∞ü‡±ã‡∞ï‡∞æ‡∞≤‡±ç ‡∞∏‡±ç‡∞™‡±Ü‡∞∏‡∞ø‡∞´‡∞ø‡∞ï‡±á‡∞∑‡∞®‡±ç
- [‡∞ü‡±Ç‡∞≤‡±ç ‡∞°‡±Ü‡∞µ‡∞≤‡∞™‡±ç‚Äå‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç ‡∞ó‡±à‡∞°‡±ç](https://modelcontextprotocol.io/docs/tools/) - MCP ‡∞ü‡±Ç‡∞≤‡±ç‡∞∏‡±ç ‡∞∏‡±É‡∞∑‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç

### ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ó‡±ç‡∞∞‡±á‡∞∑‡∞®‡±ç
- [asyncpg ‡∞°‡∞æ‡∞ï‡±ç‡∞Ø‡±Å‡∞Æ‡±Ü‡∞Ç‡∞ü‡±á‡∞∑‡∞®‡±ç](https://magicstack.github.io/asyncpg/current/) - PostgreSQL async ‡∞°‡±ç‡∞∞‡±à‡∞µ‡∞∞‡±ç
- [‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞™‡±Ç‡∞≤‡∞ø‡∞Ç‡∞ó‡±ç ‡∞â‡∞§‡±ç‡∞§‡∞Æ ‡∞Ü‡∞ö‡∞æ‡∞∞‡∞æ‡∞≤‡±Å](https://www.postgresql.org/docs/current/runtime-config-connection.html) - PostgreSQL ‡∞ü‡±ç‡∞Ø‡±Ç‡∞®‡∞ø‡∞Ç‡∞ó‡±ç
- [‡∞∞‡±ã ‡∞≤‡±Ü‡∞µ‡∞≤‡±ç ‡∞∏‡±Ü‡∞ï‡±ç‡∞Ø‡±Ç‡∞∞‡∞ø‡∞ü‡±Ä ‡∞ó‡±à‡∞°‡±ç](https://www.postgresql.org/docs/current/ddl-rowsecurity.html) - RLS ‡∞Ö‡∞Æ‡∞≤‡±Å

### FastAPI ‡∞®‡∞Æ‡±Ç‡∞®‡∞æ‡∞≤‡±Å
- [FastAPI ‡∞°‡∞æ‡∞ï‡±ç‡∞Ø‡±Å‡∞Æ‡±Ü‡∞Ç‡∞ü‡±á‡∞∑‡∞®‡±ç](https://fastapi.tiangolo.com/) - ‡∞µ‡±Ü‡∞¨‡±ç ‡∞´‡±ç‡∞∞‡±á‡∞Æ‡±ç‚Äå‡∞µ‡∞∞‡±ç‡∞ï‡±ç ‡∞∏‡±Ç‡∞ö‡∞ø‡∞ï
- [‡∞°‡∞ø‡∞™‡±Ü‡∞Ç‡∞°‡±Ü‡∞®‡±ç‡∞∏‡±Ä ‡∞á‡∞Ç‡∞ú‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç](https://fastapi.tiangolo.com/tutorial/dependencies/) - FastAPI ‡∞®‡∞Æ‡±Ç‡∞®‡∞æ‡∞≤‡±Å
- [‡∞¨‡±ç‡∞Ø‡∞æ‡∞ï‡±ç‚Äå‡∞ó‡±ç‡∞∞‡±å‡∞Ç‡∞°‡±ç ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç‡∞∏‡±ç](https://fastapi.tiangolo.com/tutorial/background-tasks/) - ‡∞Ö‡∞∏‡∞ø‡∞Ç‡∞ï‡±ç ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞£

---

**‡∞§‡∞¶‡±Å‡∞™‡∞∞‡∞ø**: ‡∞Æ‡±Ä ‡∞ü‡±Ç‡∞≤‡±ç‡∞∏‡±ç‚Äå‡∞®‡±Å ‡∞µ‡∞ø‡∞∏‡±ç‡∞§‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞æ? [Lab 06: Tool Development](../06-Tools/README.md) ‡∞§‡±ã ‡∞ï‡±ä‡∞®‡∞∏‡∞æ‡∞ó‡∞Ç‡∞°‡∞ø

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**‡∞Ö‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞§**:  
‡∞à ‡∞™‡∞§‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø AI ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶ ‡∞∏‡±á‡∞µ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Ö‡∞®‡±Å‡∞µ‡∞¶‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞Æ‡±á‡∞Æ‡±Å ‡∞ñ‡∞ö‡±ç‡∞ö‡∞ø‡∞§‡∞§‡±ç‡∞µ‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±Ä, ‡∞Ü‡∞ü‡±ã‡∞Æ‡±á‡∞ü‡±Ü‡∞°‡±ç ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±ç‡∞≤‡±ã ‡∞™‡±ä‡∞∞‡∞™‡∞æ‡∞ü‡±ç‡∞≤‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞§‡∞™‡±ç‡∞™‡∞ø‡∞¶‡∞æ‡∞≤‡±Å ‡∞â‡∞Ç‡∞°‡∞µ‡∞ö‡±ç‡∞ö‡±Å. ‡∞Æ‡±Ç‡∞≤ ‡∞™‡∞§‡±ç‡∞∞‡∞Ç ‡∞¶‡∞æ‡∞®‡∞ø ‡∞∏‡±ç‡∞µ‡∞¶‡±á‡∞∂‡±Ä ‡∞≠‡∞æ‡∞∑‡∞≤‡±ã ‡∞Ö‡∞ß‡∞ø‡∞ï‡∞æ‡∞∞‡∞ø‡∞ï ‡∞Æ‡±Ç‡∞≤‡∞Ç‡∞ó‡∞æ ‡∞™‡∞∞‡∞ø‡∞ó‡∞£‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ø. ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡∞ø‡∞ï‡∞ø, ‡∞™‡±ç‡∞∞‡±ä‡∞´‡±Ü‡∞∑‡∞®‡∞≤‡±ç ‡∞Æ‡∞æ‡∞®‡∞µ ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶‡∞Ç ‡∞∏‡∞ø‡∞´‡∞æ‡∞∞‡±ç‡∞∏‡±Å ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø. ‡∞à ‡∞Ö‡∞®‡±Å‡∞µ‡∞æ‡∞¶‡∞Ç ‡∞µ‡∞æ‡∞°‡∞ï‡∞Ç‡∞≤‡±ã ‡∞è‡∞∞‡±ç‡∞™‡∞°‡∞ø‡∞® ‡∞è‡∞µ‡±à‡∞®‡∞æ ‡∞Ö‡∞™‡∞æ‡∞∞‡±ç‡∞•‡∞æ‡∞≤‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞§‡∞™‡±ç‡∞™‡±Å‡∞¶‡∞æ‡∞∞‡±Å‡∞≤‡±Å ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞Æ‡±á‡∞Æ‡±Å ‡∞¨‡∞æ‡∞ß‡±ç‡∞Ø‡∞§ ‡∞µ‡∞π‡∞ø‡∞Ç‡∞ö‡∞Æ‡±Å.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->