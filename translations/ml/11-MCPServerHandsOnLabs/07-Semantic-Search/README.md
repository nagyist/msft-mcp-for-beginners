# เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต เดเดจเตเดฑเดเตเดฐเตเดทเตป

## ๐ฏ เด เดฒเดพเดฌเต เดเตพเดเตเดเตเดณเตเดณเตเดจเตเดจเดคเต

เด เดฒเดพเดฌเต Azure OpenAI embeddings เดเด PostgreSQL-เดจเตเดฑเต pgvector เดเดเตเดธเตเดฑเตเดฑเตปเดทเตป เดเด เดเดชเดฏเตเดเดฟเดเตเดเต เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต เดเดดเดฟเดตเตเดเตพ เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเดจเตเดจเดคเดฟเดจเต เดธเดฎเดเตเดฐเดฎเดพเดฏ เดฎเดพเตผเดเตเดเดจเดฟเตผเดฆเตเดฆเตเดถเด เดจเตฝเดเตเดจเตเดจเต. เดธเตเดตเดพเดญเดพเดตเดฟเด เดญเดพเดทเดพ เดเตเดตเตเดฑเดฟเดฏเตเดเตพ เดฎเดจเดธเตเดธเดฟเดฒเดพเดเตเดเดฟ เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเดฎเดพเดจเดคเดฏเตเดเต เดเดเดฟเดธเตเดฅเดพเดจเดคเตเดคเดฟเตฝ เดชเตเดฐเดธเดเตเดคเดฎเดพเดฏ เดซเดฒเดเตเดเตพ เดจเตฝเดเตเดจเตเดจ AI-เดถเดเตเดคเดฟเดฏเตเดณเตเดณ เดเตฝเดชเตเดชเดจเตเดจ เดธเตเตผเดเตเดเต เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเดพเตป เดจเดฟเดเตเดเตพเดเตเดเต เดชเดเดฟเดเตเดเดพเด.

## เดเดตเดฒเตเดเดจเด

เดชเดฐเดฎเตเดชเดฐเดพเดเดค เดเตเดตเตเดกเต เดเดเดฟเดธเตเดฅเดพเดจเดฎเดพเดเตเดเดฟเดฏเตเดณเตเดณ เดธเตเตผเดเตเดเต เดธเดพเดงเดพเดฐเดฃเดฏเดพเดฏเดฟ เดเดชเดฏเตเดเตเดคเต เดเดฆเตเดฆเตเดถเตเดฏเดตเตเด เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดเตผเดคเตเดฅเดตเตเด เดชเดฟเดเดฟเดเตเดเดพเตป เดชเดฐเดพเดเดฏเดชเตเดชเตเดเตเดจเตเดจเต. เดตเตเดเตเดเตผ embeddings เดเดชเดฏเตเดเดฟเดเตเดเตเดณเตเดณ เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต "เดฎเดดเดเตเดเดพเดฒเดคเตเดคเต เดเดเดพเตป เดธเตเดเดฐเตเดฏเดฎเตเดณเตเดณ เดทเตเดธเต" เดชเตเดฒเตเดณเตเดณ เดธเตเดตเดพเดญเดพเดตเดฟเด เดญเดพเดทเดพ เดเตเดตเตเดฑเดฟเดฏเตเดเตพ เดเตฝเดชเตเดชเดจเตเดจ เดตเดฟเดตเดฐเดฃเดเตเดเดณเดฟเตฝ เด เดเตเดคเตเดฏเดฎเดพเดฏ เดตเดพเดเตเดเตเดเตพ เดเดฒเตเดฒเตเดเตเดเดฟเดฒเตเด เดชเตเดฐเดธเดเตเดคเดฎเดพเดฏ เดเตฝเดชเตเดชเดจเตเดจเดเตเดเตพ เดเดฃเตเดเตเดคเตเดคเดพเตป เดธเดนเดพเดฏเดฟเดเตเดเตเดจเตเดจเต.

Azure OpenAI-เดฏเตเดเต เดถเดเตเดคเดฎเดพเดฏ embedding เดฎเตเดกเดฒเตเดเดณเตเด PostgreSQL-เดจเตเดฑเต pgvector เดเดเตเดธเตเดฑเตเดฑเตปเดทเดจเตเด เดธเดเดฏเตเดเดฟเดชเตเดชเดฟเดเตเดเต เดเดฏเตผเดจเตเดจ เดชเตเดฐเดเดเดจ เดถเตเดทเดฟเดฏเตเดณเตเดณ, เดธเตเดเตเดฏเดฟเดฒเดฌเดฟเตพ เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต เดธเดฟเดธเตเดฑเตเดฑเด เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเต เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดเตฝเดชเตเดชเดจเตเดจ เดเดฃเตเดเตเดคเตเดคเดฒเดฟเดฒเตเดเต เดฑเตเดเตเดเตเดฏเดฟเตฝ เดเดจเตเดญเดตเด เดฎเตเดเตเดเดชเตเดชเตเดเตเดคเตเดคเตเดเดฏเดพเดฃเต เดเดเตเดเดณเตเดเต เดจเดเดชเตเดชเดพเดเตเดเตฝ.

## เดชเดเดจ เดฒเดเตเดทเตเดฏเดเตเดเตพ

เด เดฒเดพเดฌเต เดชเตเตผเดคเตเดคเดฟเดฏเดพเดเตเดเดฟเดฏเดพเตฝ, เดจเดฟเดเตเดเตพเดเตเดเต เดเดดเดฟเดฏเตเด:

- **เดเดจเตเดฑเดเตเดฐเตเดฑเตเดฑเต เดเตเดฏเตเดฏเตเด** Azure OpenAI embedding เดฎเตเดกเดฒเตเดเตพ เดเตเดเตเดธเตเดฑเตเดฑเต เดตเตเดเตเดเดฑเตเดธเตเดทเดจเดพเดฏเดฟ  
- **เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด** pgvector เดซเดฒเดชเตเดฐเดฆเดฎเดพเดฏ เดธเดฎเดพเดจเดค เดธเตเตผเดเตเดเต เดชเตเดฐเดตเตผเดคเตเดคเดจเดเตเดเตพเดเตเดเต  
- **เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเตเด** เดธเตเดตเดพเดญเดพเดตเดฟเด เดญเดพเดทเดพ เดเตฝเดชเตเดชเดจเตเดจ เดเตเดตเตเดฑเดฟเดฏเตเดเตพเดเตเดเตเดณเตเดณ เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต เดเตเดณเตเดเตพ  
- **เดธเตเดทเตเดเดฟเดเตเดเตเด** เดชเดฐเดฎเตเดชเดฐเดพเดเดคเดตเตเด เดตเตเดเตเดเตผ เดธเตเตผเดเตเดเตเด เดธเดเดฏเตเดเดฟเดชเตเดชเดฟเดเตเด เดนเตเดฌเตเดฐเดฟเดกเต เดธเตเตผเดเตเดเต  
- **เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเต เดเตเดฏเตเดฏเตเด** เดชเตเดฐเตเดกเดเตเดทเตป เดชเตเดฐเดเดเดจเดคเตเดคเดฟเดจเดพเดฏเดฟ เดตเตเดเตเดเตผ เดเตเดตเตเดฑเดฟเดเตพ  
- **เดกเดฟเดธเตเตป เดเตเดฏเตเดฏเตเด** embedding เดธเดฎเดพเดจเดค เดเดชเดฏเตเดเดฟเดเตเดเต เดถเตเดชเดพเตผเดถเดพ เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ  

## ๐ง เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต เดเตผเดเตเดเดฟเดเตเดเตเดเตผ

### เดตเตเดเตเดเตผ เดธเตเตผเดเตเดเต เดชเตเดชเตเดชเตโเดฒเตเตป

```
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ                User Query                       โ
โ         "comfortable running shoes"            โ
โโโโโโโโโโโโโโโโโโโโโโโฌโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
                      โ
โโโโโโโโโโโโโโโโโโโโโโโผโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ           Azure OpenAI API                     โ
โ        text-embedding-3-small                  โ
โ        Input: Query Text                       โ
โ        Output: 1536-dimensional vector         โ
โโโโโโโโโโโโโโโโโโโโโโโฌโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
                      โ
โโโโโโโโโโโโโโโโโโโโโโโผโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ              pgvector Search                   โ
โ      Cosine Similarity: embedding <=> vector   โ
โ      WHERE similarity > threshold              โ
โ      ORDER BY similarity DESC                  โ
โโโโโโโโโโโโโโโโโโโโโโโฌโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
                      โ
โโโโโโโโโโโโโโโโโโโโโโโผโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ            Ranked Results                      โ
โ    1. Nike Air Zoom (0.89 similarity)         โ
โ    2. Adidas Ultraboost (0.85 similarity)     โ
โ    3. New Balance Fresh Foam (0.82 similarity) โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
```

### embedding เดธเตเดทเตเดเดฟเดเตเดเตฝ เดคเดจเตเดคเตเดฐเด

```python
# mcp_server/embeddings/embedding_manager.py
"""
Comprehensive embedding management for semantic search.
"""
import asyncio
import hashlib
import json
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
import numpy as np
from azure.ai.projects.aio import AIProjectClient
from azure.identity.aio import DefaultAzureCredential
from azure.core.exceptions import HttpResponseError
import logging

logger = logging.getLogger(__name__)

class EmbeddingManager:
    """Manage text embeddings for semantic search."""
    
    def __init__(self, project_endpoint: str, deployment_name: str = "text-embedding-3-small"):
        self.project_endpoint = project_endpoint
        self.deployment_name = deployment_name
        self.credential = DefaultAzureCredential()
        self.client = None
        
        # เดเดเดฌเตเดกเตเดกเดฟเดเดเต เดเตเตบเดซเดฟเดเดฑเตเดทเตป
        self.embedding_dimension = 1536  # เดเตเดเตเดธเตเดฑเตเดฑเต-เดเดเดฌเตเดกเตเดกเดฟเดเดเต-3-เดธเตเดฎเตเตพ เดกเตเดฎเตเตปเดทเตป
        self.max_tokens = 8000  # เดเดฐเต เดเดญเตเดฏเตผเดคเตเดฅเดจเดฏเตเดเตเดเตเด เดชเดฐเดฎเดพเดตเดงเดฟ เดเตเดเตเดเดฃเตเดเตพ
        self.batch_size = 100  # เดฌเดพเดเตเดเต เดชเตเดฐเตเดธเดธเตเดธเดฟเดเดเต เดตเดฒเตเดชเตเดชเด
        
        # เดเดพเดทเดฟเดเดเต เดเตเตบเดซเดฟเดเดฑเตเดทเตป
        self.embedding_cache = {}
        self.cache_ttl = timedelta(hours=24)
        
        # เดจเดฟเดฐเดเตเดเต เดชเดฐเดฟเดงเดฟ
        self.rate_limit_requests = 1000  # เดเดฐเต เดฎเดฟเดจเดฟเดฑเตเดฑเดฟเดฒเตเด
        self.rate_limit_tokens = 150000  # เดเดฐเต เดฎเดฟเดจเดฟเดฑเตเดฑเดฟเดฒเตเด
        
    async def initialize(self):
        """Initialize the Azure AI client."""
        
        try:
            self.client = AIProjectClient(
                endpoint=self.project_endpoint,
                credential=self.credential
            )
            
            # เดเดฃเดเตเดทเตป เดชเดฐเดฟเดถเตเดงเดจ
            await self._test_connection()
            
            logger.info("Embedding manager initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize embedding manager: {e}")
            raise
    
    async def _test_connection(self):
        """Test Azure OpenAI connection."""
        
        try:
            test_embedding = await self.generate_embedding("test connection")
            if len(test_embedding) != self.embedding_dimension:
                raise ValueError(f"Unexpected embedding dimension: {len(test_embedding)}")
            
            logger.info("Azure OpenAI connection test successful")
            
        except Exception as e:
            logger.error(f"Azure OpenAI connection test failed: {e}")
            raise
    
    async def generate_embedding(self, text: str, use_cache: bool = True) -> List[float]:
        """Generate embedding for a single text."""
        
        if not text or not text.strip():
            raise ValueError("Text cannot be empty")
        
        # เดเดฆเตเดฏเด เดเดพเดทเต เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
        if use_cache:
            cache_key = self._get_cache_key(text)
            cached_embedding = self._get_cached_embedding(cache_key)
            if cached_embedding:
                return cached_embedding
        
        try:
            # เดเตเดฒเดฏเดจเตเดฑเต เดเตปเดทเดฟเดฏเดฒเตเดธเต เดเตเดฏเตเดคเดฟเดเตเดเตเดฃเตเดเตเดจเตเดจเต เดเดฑเดชเตเดชเดพเดเตเดเตเด
            if not self.client:
                await self.initialize()
            
            # เดเดเดฌเตเดกเตเดกเดฟเดเดเต เดธเตเดทเตเดเดฟเดเตเดเตเด
            response = await self.client.embeddings.create(
                model=self.deployment_name,
                input=text.strip()
            )
            
            embedding = response.data[0].embedding
            
            # เดซเดฒเด เดเดพเดทเต เดเตเดฏเตเดฏเตเด
            if use_cache:
                self._cache_embedding(cache_key, embedding)
            
            logger.debug(f"Generated embedding for text (length: {len(text)})")
            
            return embedding
            
        except HttpResponseError as e:
            logger.error(f"Azure OpenAI API error: {e}")
            raise Exception(f"Embedding generation failed: {e}")
        except Exception as e:
            logger.error(f"Embedding generation error: {e}")
            raise
    
    async def generate_embeddings_batch(
        self, 
        texts: List[str], 
        use_cache: bool = True
    ) -> List[List[float]]:
        """Generate embeddings for multiple texts efficiently."""
        
        if not texts:
            return []
        
        embeddings = []
        cache_misses = []
        cache_miss_indices = []
        
        # เดเดฐเต เดเตเดเตเดธเตเดฑเตเดฑเดฟเดจเตเด เดเดพเดทเต เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
        for i, text in enumerate(texts):
            if not text or not text.strip():
                embeddings.append([])
                continue
                
            if use_cache:
                cache_key = self._get_cache_key(text)
                cached_embedding = self._get_cached_embedding(cache_key)
                if cached_embedding:
                    embeddings.append(cached_embedding)
                    continue
            
            # เดเดพเดทเต เดฎเดฟเดธเตเดธเตเดเตพ เดเตเดฐเดพเดเตเดเต เดเตเดฏเตเดฏเตเด
            embeddings.append(None)  # เดชเตเดฒเตเดธเตเดนเตเตพเดกเตผ
            cache_misses.append(text.strip())
            cache_miss_indices.append(i)
        
        # เดเดพเดทเต เดฎเดฟเดธเตเดธเตเดเตพเดเตเดเดพเดฏเดฟ เดเดเดฌเตเดกเตเดกเดฟเดเดเตเดเตพ เดธเตเดทเตเดเดฟเดเตเดเตเด
        if cache_misses:
            try:
                # API เดชเดฐเดฟเดงเดฟเดเตพ เดฎเดพเดจเดฟเดเตเดเต เดฌเดพเดเตเดเตเดเดณเดพเดฏเดฟ เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเด
                for batch_start in range(0, len(cache_misses), self.batch_size):
                    batch_end = min(batch_start + self.batch_size, len(cache_misses))
                    batch_texts = cache_misses[batch_start:batch_end]
                    
                    # เดฌเดพเดเตเดเต เดเดเดฌเตเดกเตเดกเดฟเดเดเตเดเตพ เดธเตเดทเตเดเดฟเดเตเดเตเด
                    response = await self.client.embeddings.create(
                        model=self.deployment_name,
                        input=batch_texts
                    )
                    
                    # เดฌเดพเดเตเดเต เดซเดฒเดเตเดเตพ เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเด
                    for j, embedding_data in enumerate(response.data):
                        actual_index = cache_miss_indices[batch_start + j]
                        embedding = embedding_data.embedding
                        embeddings[actual_index] = embedding
                        
                        # เดซเดฒเด เดเดพเดทเต เดเตเดฏเตเดฏเตเด
                        if use_cache:
                            text = batch_texts[j]
                            cache_key = self._get_cache_key(text)
                            self._cache_embedding(cache_key, embedding)
                    
                    # เดจเดฟเดฐเดเตเดเต เดชเดฐเดฟเดงเดฟ - เดฌเดพเดเตเดเตเดเตพเดเตเดเดฟเดเดฏเดฟเตฝ เดเตเดฑเดฟเดฏ เดตเตเดเดฟเดชเตเดชเต
                    if batch_end < len(cache_misses):
                        await asyncio.sleep(0.1)
                
                logger.info(f"Generated {len(cache_misses)} embeddings in batch")
                
            except Exception as e:
                logger.error(f"Batch embedding generation failed: {e}")
                raise
        
        return embeddings
    
    def _get_cache_key(self, text: str) -> str:
        """Generate cache key for text."""
        
        # เดเดพเดทเต เดเตเดเตเดเต เดเตเดเตเดธเตเดฑเตเดฑเต + เดฎเตเดกเดฒเดฟเดจเตเดฑเต SHA-256 เดนเดพเดทเต เดเดชเดฏเตเดเดฟเดเตเดเตเด
        content = f"{self.deployment_name}:{text.strip()}"
        return hashlib.sha256(content.encode()).hexdigest()
    
    def _get_cached_embedding(self, cache_key: str) -> Optional[List[float]]:
        """Get embedding from cache if not expired."""
        
        if cache_key in self.embedding_cache:
            embedding_data = self.embedding_cache[cache_key]
            
            # เดเดพเดทเต เดเตปเดเตเดฐเดฟ เดเดชเตเดชเตเดดเตเด เดธเดพเดงเตเดตเดพเดฃเต เดเดจเตเดจเต เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด
            if datetime.now() - embedding_data['timestamp'] < self.cache_ttl:
                return embedding_data['embedding']
            else:
                # เดเดพเดฒเดนเดฐเดฃเดชเตเดชเตเดเตเด เดเตปเดเตเดฐเดฟ เดจเตเดเตเดเด เดเตเดฏเตเดฏเตเด
                del self.embedding_cache[cache_key]
        
        return None
    
    def _cache_embedding(self, cache_key: str, embedding: List[float]):
        """Cache embedding with timestamp."""
        
        self.embedding_cache[cache_key] = {
            'embedding': embedding,
            'timestamp': datetime.now()
        }
        
        # เดเดพเดทเต เดตเดฒเตเดชเตเดชเด เดชเดฐเดฟเดงเดฟ
        if len(self.embedding_cache) > 10000:
            # เดชเดดเดฏ เดเตปเดเตเดฐเดฟเดเตพ เดจเตเดเตเดเด เดเตเดฏเตเดฏเตเด
            oldest_keys = sorted(
                self.embedding_cache.keys(),
                key=lambda k: self.embedding_cache[k]['timestamp']
            )[:1000]
            
            for key in oldest_keys:
                del self.embedding_cache[key]
    
    async def cleanup(self):
        """Cleanup resources."""
        
        if self.client:
            await self.client.close()
        
        logger.info("Embedding manager cleanup completed")

# เดเตเดฒเตเดฌเตฝ เดเดเดฌเตเดกเตเดกเดฟเดเดเต เดฎเดพเดจเตเดเตผ เดเตปเดธเตเดฑเตเดฑเตปเดธเต
embedding_manager = EmbeddingManager(
    project_endpoint=os.getenv('PROJECT_ENDPOINT'),
    deployment_name=os.getenv('EMBEDDING_DEPLOYMENT_NAME', 'text-embedding-3-small')
)
```

## ๐ เดเตฝเดชเตเดชเดจเตเดจ embedding เดธเตเดทเตเดเดฟเดเตเดเตฝ

### เดเดเตเดเตเดฎเตเดฑเตเดฑเดกเต embedding เดชเตเดชเตเดชเตโเดฒเตเตป

```python
# mcp_server/embeddings/product_embedder.py
"""
Product embedding generation and management.
"""
import asyncio
import asyncpg
from typing import List, Dict, Any, Optional
from datetime import datetime
import logging
from .embedding_manager import embedding_manager

logger = logging.getLogger(__name__)

class ProductEmbedder:
    """Generate and manage product embeddings for semantic search."""
    
    def __init__(self, db_provider):
        self.db_provider = db_provider
        self.embedding_manager = embedding_manager
        
        # เดเตฝเดชเตเดชเดจเตเดจเดเตเดเตพเดเตเดเต เดเตเดเตเดธเตเดฑเตเดฑเต เดธเดเดฏเตเดเดจเด เดคเดจเตเดคเตเดฐเด
        self.text_template = "{product_name} {brand} {description} {category} {tags}"
        
    async def generate_product_embeddings(
        self, 
        store_id: str,
        batch_size: int = 50,
        force_regenerate: bool = False
    ) -> Dict[str, Any]:
        """Generate embeddings for all products in a store."""
        
        async with self.db_provider.get_connection() as conn:
            try:
                # เดธเตเดฑเตเดฑเตเตผ เดเตเตบเดเตเดเตเดธเตเดฑเตเดฑเต เดธเดเตเดเดฎเดพเดเตเดเตเด
                await conn.execute("SELECT retail.set_store_context($1)", store_id)
                
                # เดเดเดฌเตเดกเดฟเดเดเตเดเตพ เดเดตเดถเตเดฏเดฎเดพเดฏ เดเตฝเดชเตเดชเดจเตเดจเดเตเดเตพ เดจเตเดเตเด
                if force_regenerate:
                    products_query = """
                        SELECT 
                            p.product_id,
                            p.product_name,
                            p.product_description,
                            p.brand,
                            pc.category_name,
                            array_to_string(p.tags, ' ') as tags_text
                        FROM retail.products p
                        LEFT JOIN retail.product_categories pc ON p.category_id = pc.category_id
                        WHERE p.is_active = TRUE
                        ORDER BY p.created_at DESC
                    """
                else:
                    products_query = """
                        SELECT 
                            p.product_id,
                            p.product_name,
                            p.product_description,
                            p.brand,
                            pc.category_name,
                            array_to_string(p.tags, ' ') as tags_text
                        FROM retail.products p
                        LEFT JOIN retail.product_categories pc ON p.category_id = pc.category_id
                        LEFT JOIN retail.product_embeddings pe ON p.product_id = pe.product_id
                        WHERE p.is_active = TRUE
                          AND (pe.product_id IS NULL OR pe.updated_at < p.updated_at)
                        ORDER BY p.created_at DESC
                    """
                
                products = await conn.fetch(products_query)
                
                if not products:
                    return {
                        'success': True,
                        'message': 'No products need embedding generation',
                        'processed_count': 0,
                        'store_id': store_id
                    }
                
                logger.info(f"Generating embeddings for {len(products)} products in store {store_id}")
                
                # เดเตฝเดชเตเดชเดจเตเดจเดเตเดเตพ เดฌเดพเดเตเดเตเดเดณเดพเดฏเดฟ เดชเตเดฐเตเดธเดธเตเดธเต เดเตเดฏเตเดฏเตเด
                processed_count = 0
                
                for i in range(0, len(products), batch_size):
                    batch = products[i:i + batch_size]
                    await self._process_product_batch(conn, batch, store_id)
                    processed_count += len(batch)
                    
                    logger.info(f"Processed {processed_count}/{len(products)} products")
                
                return {
                    'success': True,
                    'message': f'Successfully generated embeddings for {processed_count} products',
                    'processed_count': processed_count,
                    'store_id': store_id,
                    'total_products': len(products)
                }
                
            except Exception as e:
                logger.error(f"Product embedding generation failed: {e}")
                return {
                    'success': False,
                    'error': str(e),
                    'store_id': store_id
                }
    
    async def _process_product_batch(
        self, 
        conn: asyncpg.Connection, 
        products: List[Dict], 
        store_id: str
    ):
        """Process a batch of products for embedding generation."""
        
        # เดเดเดฌเตเดกเดฟเดเดเดฟเดจเดพเดฏเดฟ เดเตเดเตเดธเตเดฑเตเดฑเตเดเตพ เดคเดฏเตเดฏเดพเดฑเดพเดเตเดเตเด
        texts = []
        product_ids = []
        
        for product in products:
            # เดเตฝเดชเตเดชเดจเตเดจ เดตเดฟเดตเดฐเดเตเดเตพ เดคเดฟเดฐเดฏเดพเดตเตเดจเตเดจ เดเตเดเตเดธเตเดฑเตเดฑเดพเดฏเดฟ เดธเดเดฏเตเดเดฟเดชเตเดชเดฟเดเตเดเตเด
            combined_text = self._create_product_text(product)
            texts.append(combined_text)
            product_ids.append(product['product_id'])
        
        # เดเดเดฌเตเดกเดฟเดเดเตเดเตพ เดธเตเดทเตเดเดฟเดเตเดเตเด
        embeddings = await self.embedding_manager.generate_embeddings_batch(texts)
        
        # เดกเดพเดฑเตเดฑเดพเดฌเตเดธเดฟเตฝ เดเดเดฌเตเดกเดฟเดเดเตเดเตพ เดธเดเดญเดฐเดฟเดเตเดเตเด
        for i, (product_id, embedding) in enumerate(zip(product_ids, embeddings)):
            if embedding:  # เดชเดฐเดพเดเดฏเดชเตเดชเตเดเตเด เดเดเดฌเตเดกเดฟเดเดเตเดเตพ เดเดดเดฟเดตเดพเดเตเดเตเด
                await self._store_product_embedding(
                    conn, 
                    product_id, 
                    store_id, 
                    texts[i], 
                    embedding
                )
    
    def _create_product_text(self, product: Dict[str, Any]) -> str:
        """Create combined text for product embedding."""
        
        # None เดฎเตเดฒเตเดฏเดเตเดเตพ เดเตเดเดพเดฐเตเดฏเด เดเตเดฏเตเดฏเตเด
        product_name = product.get('product_name') or ''
        brand = product.get('brand') or ''
        description = product.get('product_description') or ''
        category = product.get('category_name') or ''
        tags = product.get('tags_text') or ''
        
        # เดคเดฟเดฐเดฏเดพเดตเตเดจเตเดจ เดเตเดเตเดธเตเดฑเตเดฑเดพเดฏเดฟ เดธเดเดฏเตเดเดฟเดชเตเดชเดฟเดเตเดเตเด
        combined_text = self.text_template.format(
            product_name=product_name,
            brand=brand,
            description=description,
            category=category,
            tags=tags
        )
        
        # เดเดงเดฟเด เดตเตเดณเดฟเดเตเดเด เดจเตเดเตเดเดเดเตเดฏเตเดฏเตเด
        return ' '.join(combined_text.split())
    
    async def _store_product_embedding(
        self,
        conn: asyncpg.Connection,
        product_id: str,
        store_id: str,
        embedding_text: str,
        embedding: List[float]
    ):
        """Store product embedding in database."""
        
        # เดเดเดฌเตเดกเดฟเดเดเต pgvector เดซเตเตผเดฎเดพเดฑเตเดฑเดฟเดฒเตเดเตเดเต เดฎเดพเดฑเตเดฑเตเด
        embedding_vector = f"[{','.join(map(str, embedding))}]"
        
        # เดเดเดฌเตเดกเดฟเดเดเต เดเดชเตเดธเตเตผเดเตเดเต เดเตเดฏเตเดฏเตเด
        upsert_query = """
            INSERT INTO retail.product_embeddings (
                product_id, store_id, embedding_text, embedding, embedding_model
            ) VALUES ($1, $2, $3, $4, $5)
            ON CONFLICT (product_id, embedding_model) 
            DO UPDATE SET
                store_id = EXCLUDED.store_id,
                embedding_text = EXCLUDED.embedding_text,
                embedding = EXCLUDED.embedding,
                updated_at = CURRENT_TIMESTAMP
        """
        
        await conn.execute(
            upsert_query,
            product_id,
            store_id,
            embedding_text,
            embedding_vector,
            self.embedding_manager.deployment_name
        )
    
    async def update_product_embedding(
        self, 
        product_id: str, 
        store_id: str
    ) -> Dict[str, Any]:
        """Update embedding for a single product."""
        
        async with self.db_provider.get_connection() as conn:
            try:
                # เดธเตเดฑเตเดฑเตเตผ เดเตเตบเดเตเดเตเดธเตเดฑเตเดฑเต เดธเดเตเดเดฎเดพเดเตเดเตเด
                await conn.execute("SELECT retail.set_store_context($1)", store_id)
                
                # เดเตฝเดชเตเดชเดจเตเดจ เดตเดฟเดตเดฐเดเตเดเตพ เดจเตเดเตเด
                product_query = """
                    SELECT 
                        p.product_id,
                        p.product_name,
                        p.product_description,
                        p.brand,
                        pc.category_name,
                        array_to_string(p.tags, ' ') as tags_text
                    FROM retail.products p
                    LEFT JOIN retail.product_categories pc ON p.category_id = pc.category_id
                    WHERE p.product_id = $1 AND p.is_active = TRUE
                """
                
                product = await conn.fetchrow(product_query, product_id)
                
                if not product:
                    return {
                        'success': False,
                        'error': f'Product {product_id} not found or inactive'
                    }
                
                # เดเดเดฌเตเดกเดฟเดเดเต เดธเตเดทเตเดเดฟเดเตเดเตเด
                combined_text = self._create_product_text(dict(product))
                embedding = await self.embedding_manager.generate_embedding(combined_text)
                
                # เดเดเดฌเตเดกเดฟเดเดเต เดธเดเดญเดฐเดฟเดเตเดเตเด
                await self._store_product_embedding(
                    conn, product_id, store_id, combined_text, embedding
                )
                
                return {
                    'success': True,
                    'message': f'Successfully updated embedding for product {product_id}',
                    'product_id': product_id,
                    'store_id': store_id
                }
                
            except Exception as e:
                logger.error(f"Single product embedding update failed: {e}")
                return {
                    'success': False,
                    'error': str(e),
                    'product_id': product_id
                }

# เดเดเตเดณ เดเตฝเดชเตเดชเดจเตเดจ เดเดเดฌเตเดกเตผ เดเตปเดธเตเดฑเตเดฑเตปเดธเต
product_embedder = ProductEmbedder(db_provider)
```

## ๐ เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต เดเตเดณเตเดเตพ

### เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดเตฝเดชเตเดชเดจเตเดจ เดธเตเตผเดเตเดเต เดเตเตพ

```python
# mcp_server/tools/semantic_search.py
"""
Semantic search tools for natural language product queries.
"""
from typing import Dict, Any, List, Optional
from ..tools.base import DatabaseTool, ToolResult, ToolCategory
from ..embeddings.embedding_manager import embedding_manager
import logging

logger = logging.getLogger(__name__)

class SemanticProductSearchTool(DatabaseTool):
    """Advanced semantic search tool for products using vector similarity."""
    
    def __init__(self, db_provider):
        super().__init__(
            name="semantic_search_products",
            description="Search products using natural language queries with semantic understanding",
            db_provider=db_provider
        )
        self.category = ToolCategory.DATABASE_QUERY
        self.embedding_manager = embedding_manager
    
    async def execute(self, **kwargs) -> ToolResult:
        """Execute semantic product search."""
        
        query = kwargs.get('query')
        store_id = kwargs.get('store_id')
        limit = kwargs.get('limit', 20)
        similarity_threshold = kwargs.get('similarity_threshold', 0.7)
        include_metadata = kwargs.get('include_metadata', True)
        
        if not query:
            return ToolResult(
                success=False,
                error="Search query is required"
            )
        
        if not store_id:
            return ToolResult(
                success=False,
                error="store_id is required for semantic search"
            )
        
        try:
            # เดเตเดตเดฑเดฟ เดเดเดฌเตเดกเดฟเดเดเต เดธเตเดทเตเดเดฟเดเตเดเตเด
            query_embedding = await self.embedding_manager.generate_embedding(query)
            
            # เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต เดจเดเดคเตเดคเตเด
            search_results = await self._perform_semantic_search(
                query_embedding,
                store_id,
                limit,
                similarity_threshold,
                include_metadata
            )
            
            return ToolResult(
                success=True,
                data=search_results,
                row_count=len(search_results),
                metadata={
                    'query': query,
                    'store_id': store_id,
                    'similarity_threshold': similarity_threshold,
                    'search_type': 'semantic'
                }
            )
            
        except Exception as e:
            logger.error(f"Semantic search failed: {e}")
            return ToolResult(
                success=False,
                error=f"Semantic search failed: {str(e)}"
            )
    
    async def _perform_semantic_search(
        self,
        query_embedding: List[float],
        store_id: str,
        limit: int,
        similarity_threshold: float,
        include_metadata: bool
    ) -> List[Dict[str, Any]]:
        """Perform vector similarity search."""
        
        # เดเดเดฌเตเดกเดฟเดเดเต PostgreSQL เดตเตเดเตเดเตผ เดซเตเตผเดฎเดพเดฑเตเดฑเดฟเดฒเตเดเตเดเต เดฎเดพเดฑเตเดฑเตเด
        embedding_vector = f"[{','.join(map(str, query_embedding))}]"
        
        # เดธเตเตผเดเตเดเต เดเตเดตเดฑเดฟ เดจเดฟเตผเดฎเตเดฎเดฟเดเตเดเตเด
        if include_metadata:
            search_query = """
                SELECT 
                    p.product_id,
                    p.product_name,
                    p.brand,
                    p.price,
                    p.product_description,
                    p.current_stock,
                    p.rating_average,
                    p.rating_count,
                    p.tags,
                    pc.category_name,
                    pe.embedding_text,
                    1 - (pe.embedding <=> $1::vector) as similarity_score
                FROM retail.product_embeddings pe
                JOIN retail.products p ON pe.product_id = p.product_id
                LEFT JOIN retail.product_categories pc ON p.category_id = pc.category_id
                WHERE pe.store_id = $2
                  AND p.is_active = TRUE
                  AND 1 - (pe.embedding <=> $1::vector) >= $3
                ORDER BY pe.embedding <=> $1::vector
                LIMIT $4
            """
        else:
            search_query = """
                SELECT 
                    p.product_id,
                    p.product_name,
                    p.brand,
                    p.price,
                    1 - (pe.embedding <=> $1::vector) as similarity_score
                FROM retail.product_embeddings pe
                JOIN retail.products p ON pe.product_id = p.product_id
                WHERE pe.store_id = $2
                  AND p.is_active = TRUE
                  AND 1 - (pe.embedding <=> $1::vector) >= $3
                ORDER BY pe.embedding <=> $1::vector
                LIMIT $4
            """
        
        async with self.get_connection() as conn:
            # เดธเตเดฑเตเดฑเตเตผ เดเตเตบเดเตเดเตเดธเตเดฑเตเดฑเต เดธเดเตเดเดฎเดพเดเตเดเตเด
            await conn.execute("SELECT retail.set_store_context($1)", store_id)
            
            # เดธเตเตผเดเตเดเต เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด
            results = await conn.fetch(
                search_query,
                embedding_vector,
                store_id,
                similarity_threshold,
                limit
            )
            
            return [dict(result) for result in results]
    
    def get_input_schema(self) -> Dict[str, Any]:
        """Get input schema for semantic search tool."""
        
        return {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Natural language search query",
                    "minLength": 1,
                    "maxLength": 500
                },
                "store_id": {
                    "type": "string",
                    "description": "Store ID for search scope",
                    "pattern": "^[a-zA-Z0-9_-]+$"
                },
                "limit": {
                    "type": "integer",
                    "description": "Maximum number of results to return",
                    "minimum": 1,
                    "maximum": 100,
                    "default": 20
                },
                "similarity_threshold": {
                    "type": "number",
                    "description": "Minimum similarity score (0.0 to 1.0)",
                    "minimum": 0.0,
                    "maximum": 1.0,
                    "default": 0.7
                },
                "include_metadata": {
                    "type": "boolean",
                    "description": "Include detailed product metadata in results",
                    "default": True
                }
            },
            "required": ["query", "store_id"],
            "additionalProperties": False
        }

class HybridSearchTool(DatabaseTool):
    """Hybrid search combining traditional keyword and semantic search."""
    
    def __init__(self, db_provider):
        super().__init__(
            name="hybrid_product_search",
            description="Hybrid search combining keyword matching and semantic similarity for optimal results",
            db_provider=db_provider
        )
        self.category = ToolCategory.DATABASE_QUERY
        self.embedding_manager = embedding_manager
    
    async def execute(self, **kwargs) -> ToolResult:
        """Execute hybrid product search."""
        
        query = kwargs.get('query')
        store_id = kwargs.get('store_id')
        limit = kwargs.get('limit', 20)
        semantic_weight = kwargs.get('semantic_weight', 0.7)
        keyword_weight = kwargs.get('keyword_weight', 0.3)
        
        if not query:
            return ToolResult(
                success=False,
                error="Search query is required"
            )
        
        if not store_id:
            return ToolResult(
                success=False,
                error="store_id is required for hybrid search"
            )
        
        try:
            # เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเดฟเดจเดพเดฏเดฟ เดเตเดตเดฑเดฟ เดเดเดฌเตเดกเดฟเดเดเต เดธเตเดทเตเดเดฟเดเตเดเตเด
            query_embedding = await self.embedding_manager.generate_embedding(query)
            
            # เดนเตเดฌเตเดฐเดฟเดกเต เดธเตเตผเดเตเดเต เดจเดเดคเตเดคเตเด
            search_results = await self._perform_hybrid_search(
                query,
                query_embedding,
                store_id,
                limit,
                semantic_weight,
                keyword_weight
            )
            
            return ToolResult(
                success=True,
                data=search_results,
                row_count=len(search_results),
                metadata={
                    'query': query,
                    'store_id': store_id,
                    'semantic_weight': semantic_weight,
                    'keyword_weight': keyword_weight,
                    'search_type': 'hybrid'
                }
            )
            
        except Exception as e:
            logger.error(f"Hybrid search failed: {e}")
            return ToolResult(
                success=False,
                error=f"Hybrid search failed: {str(e)}"
            )
    
    async def _perform_hybrid_search(
        self,
        query: str,
        query_embedding: List[float],
        store_id: str,
        limit: int,
        semantic_weight: float,
        keyword_weight: float
    ) -> List[Dict[str, Any]]:
        """Perform hybrid search combining keyword and semantic similarity."""
        
        # เดเดเดฌเตเดกเดฟเดเดเต PostgreSQL เดตเตเดเตเดเตผ เดซเตเตผเดฎเดพเดฑเตเดฑเดฟเดฒเตเดเตเดเต เดฎเดพเดฑเตเดฑเตเด
        embedding_vector = f"[{','.join(map(str, query_embedding))}]"
        
        # เดเตเดตเตเดกเต เดฎเดพเดเตเดเดฟเดเดเดฟเดจเดพเดฏเดฟ เดธเตเตผเดเตเดเต เดเตเตผเดฎเตเดเตพ เดธเตเดทเตเดเดฟเดเตเดเตเด
        search_terms = ' & '.join(query.lower().split())
        
        hybrid_query = """
            WITH keyword_scores AS (
                SELECT 
                    p.product_id,
                    ts_rank(
                        to_tsvector('english', 
                            p.product_name || ' ' || 
                            COALESCE(p.product_description, '') || ' ' || 
                            COALESCE(p.brand, '') || ' ' ||
                            COALESCE(array_to_string(p.tags, ' '), '')
                        ),
                        plainto_tsquery('english', $2)
                    ) as keyword_score
                FROM retail.products p
                WHERE p.is_active = TRUE
                  AND p.store_id = $3
                  AND (
                    to_tsvector('english', 
                        p.product_name || ' ' || 
                        COALESCE(p.product_description, '') || ' ' || 
                        COALESCE(p.brand, '') || ' ' ||
                        COALESCE(array_to_string(p.tags, ' '), '')
                    ) @@ plainto_tsquery('english', $2)
                    OR p.product_name ILIKE '%' || $2 || '%'
                    OR p.brand ILIKE '%' || $2 || '%'
                  )
            ),
            semantic_scores AS (
                SELECT 
                    pe.product_id,
                    1 - (pe.embedding <=> $1::vector) as semantic_score
                FROM retail.product_embeddings pe
                WHERE pe.store_id = $3
                  AND 1 - (pe.embedding <=> $1::vector) >= 0.5
            ),
            combined_scores AS (
                SELECT 
                    COALESCE(ks.product_id, ss.product_id) as product_id,
                    COALESCE(ks.keyword_score, 0) * $4 as weighted_keyword_score,
                    COALESCE(ss.semantic_score, 0) * $5 as weighted_semantic_score,
                    COALESCE(ks.keyword_score, 0) * $4 + COALESCE(ss.semantic_score, 0) * $5 as combined_score
                FROM keyword_scores ks
                FULL OUTER JOIN semantic_scores ss ON ks.product_id = ss.product_id
                WHERE COALESCE(ks.keyword_score, 0) * $4 + COALESCE(ss.semantic_score, 0) * $5 > 0
            )
            SELECT 
                p.product_id,
                p.product_name,
                p.brand,
                p.price,
                p.product_description,
                p.current_stock,
                p.rating_average,
                p.rating_count,
                p.tags,
                pc.category_name,
                cs.weighted_keyword_score,
                cs.weighted_semantic_score,
                cs.combined_score
            FROM combined_scores cs
            JOIN retail.products p ON cs.product_id = p.product_id
            LEFT JOIN retail.product_categories pc ON p.category_id = pc.category_id
            WHERE p.is_active = TRUE
            ORDER BY cs.combined_score DESC
            LIMIT $6
        """
        
        async with self.get_connection() as conn:
            # เดธเตเดฑเตเดฑเตเตผ เดเตเตบเดเตเดเตเดธเตเดฑเตเดฑเต เดธเดเตเดเดฎเดพเดเตเดเตเด
            await conn.execute("SELECT retail.set_store_context($1)", store_id)
            
            # เดนเตเดฌเตเดฐเดฟเดกเต เดธเตเตผเดเตเดเต เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด
            results = await conn.fetch(
                hybrid_query,
                embedding_vector,  # $1
                query,            # $2
                store_id,         # $3
                keyword_weight,   # $4
                semantic_weight,  # $5
                limit            # $6
            )
            
            return [dict(result) for result in results]
    
    def get_input_schema(self) -> Dict[str, Any]:
        """Get input schema for hybrid search tool."""
        
        return {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Search query (supports both keywords and natural language)",
                    "minLength": 1,
                    "maxLength": 500
                },
                "store_id": {
                    "type": "string",
                    "description": "Store ID for search scope",
                    "pattern": "^[a-zA-Z0-9_-]+$"
                },
                "limit": {
                    "type": "integer",
                    "description": "Maximum number of results to return",
                    "minimum": 1,
                    "maximum": 100,
                    "default": 20
                },
                "semantic_weight": {
                    "type": "number",
                    "description": "Weight for semantic similarity (0.0 to 1.0)",
                    "minimum": 0.0,
                    "maximum": 1.0,
                    "default": 0.7
                },
                "keyword_weight": {
                    "type": "number",
                    "description": "Weight for keyword matching (0.0 to 1.0)",
                    "minimum": 0.0,
                    "maximum": 1.0,
                    "default": 0.3
                }
            },
            "required": ["query", "store_id"],
            "additionalProperties": False
        }
```

## ๐ฏ เดถเตเดชเดพเตผเดถเดพ เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ

### เดเตฝเดชเตเดชเดจเตเดจ เดถเตเดชเดพเตผเดถ เดเดเตเดเดฟเตป

```python
# mcp_server/tools/recommendations.py
"""
Product recommendation system using embedding similarity.
"""
from typing import Dict, Any, List, Optional
from ..tools.base import DatabaseTool, ToolResult, ToolCategory
import logging

logger = logging.getLogger(__name__)

class ProductRecommendationTool(DatabaseTool):
    """Generate product recommendations based on similarity and user behavior."""
    
    def __init__(self, db_provider):
        super().__init__(
            name="get_product_recommendations",
            description="Generate personalized product recommendations using similarity analysis",
            db_provider=db_provider
        )
        self.category = ToolCategory.ANALYTICS
    
    async def execute(self, **kwargs) -> ToolResult:
        """Execute product recommendation generation."""
        
        recommendation_type = kwargs.get('type', 'similar_products')
        store_id = kwargs.get('store_id')
        
        if not store_id:
            return ToolResult(
                success=False,
                error="store_id is required for recommendations"
            )
        
        try:
            if recommendation_type == 'similar_products':
                return await self._get_similar_products(kwargs)
            elif recommendation_type == 'customer_based':
                return await self._get_customer_recommendations(kwargs)
            elif recommendation_type == 'trending':
                return await self._get_trending_products(kwargs)
            elif recommendation_type == 'cross_sell':
                return await self._get_cross_sell_recommendations(kwargs)
            else:
                return ToolResult(
                    success=False,
                    error=f"Unknown recommendation type: {recommendation_type}"
                )
        
        except Exception as e:
            logger.error(f"Product recommendation failed: {e}")
            return ToolResult(
                success=False,
                error=f"Recommendation generation failed: {str(e)}"
            )
    
    async def _get_similar_products(self, kwargs: Dict[str, Any]) -> ToolResult:
        """Get products similar to a given product using embedding similarity."""
        
        product_id = kwargs.get('product_id')
        store_id = kwargs['store_id']
        limit = kwargs.get('limit', 10)
        similarity_threshold = kwargs.get('similarity_threshold', 0.7)
        
        if not product_id:
            return ToolResult(
                success=False,
                error="product_id is required for similar product recommendations"
            )
        
        similar_products_query = """
            WITH target_product AS (
                SELECT embedding
                FROM retail.product_embeddings
                WHERE product_id = $1 AND store_id = $2
            )
            SELECT 
                p.product_id,
                p.product_name,
                p.brand,
                p.price,
                p.product_description,
                p.rating_average,
                p.rating_count,
                pc.category_name,
                1 - (pe.embedding <=> tp.embedding) as similarity_score
            FROM retail.product_embeddings pe
            CROSS JOIN target_product tp
            JOIN retail.products p ON pe.product_id = p.product_id
            LEFT JOIN retail.product_categories pc ON p.category_id = pc.category_id
            WHERE pe.store_id = $2
              AND pe.product_id != $1  -- Exclude the target product itself
              AND p.is_active = TRUE
              AND 1 - (pe.embedding <=> tp.embedding) >= $3
            ORDER BY pe.embedding <=> tp.embedding
            LIMIT $4
        """
        
        result = await self.execute_query(
            similar_products_query,
            (product_id, store_id, similarity_threshold, limit),
            store_id
        )
        
        if result.success:
            result.metadata = {
                'recommendation_type': 'similar_products',
                'target_product_id': product_id,
                'similarity_threshold': similarity_threshold,
                'store_id': store_id
            }
        
        return result
    
    async def _get_customer_recommendations(self, kwargs: Dict[str, Any]) -> ToolResult:
        """Get personalized recommendations based on customer purchase history."""
        
        customer_id = kwargs.get('customer_id')
        store_id = kwargs['store_id']
        limit = kwargs.get('limit', 10)
        days_back = kwargs.get('days_back', 90)
        
        if not customer_id:
            return ToolResult(
                success=False,
                error="customer_id is required for customer-based recommendations"
            )
        
        customer_recommendations_query = """
            WITH customer_purchases AS (
                -- Get products purchased by the customer
                SELECT DISTINCT p.product_id, pe.embedding
                FROM retail.sales_transactions st
                JOIN retail.sales_transaction_items sti ON st.transaction_id = sti.transaction_id
                JOIN retail.products p ON sti.product_id = p.product_id
                JOIN retail.product_embeddings pe ON p.product_id = pe.product_id
                WHERE st.customer_id = $1
                  AND st.transaction_date >= CURRENT_DATE - INTERVAL '%s days'
                  AND st.transaction_type = 'sale'
            ),
            avg_customer_embedding AS (
                -- Calculate average embedding vector for customer preferences
                SELECT 
                    (
                        SELECT ARRAY(
                            SELECT AVG(embedding_element)
                            FROM customer_purchases cp,
                                 LATERAL unnest(cp.embedding) WITH ORDINALITY AS t(embedding_element, ordinality)
                            GROUP BY ordinality
                            ORDER BY ordinality
                        )
                    )::vector as avg_embedding
                FROM (SELECT 1) dummy
                WHERE EXISTS (SELECT 1 FROM customer_purchases)
            )
            SELECT 
                p.product_id,
                p.product_name,
                p.brand,
                p.price,
                p.product_description,
                p.rating_average,
                p.rating_count,
                pc.category_name,
                1 - (pe.embedding <=> ace.avg_embedding) as preference_score
            FROM retail.product_embeddings pe
            CROSS JOIN avg_customer_embedding ace
            JOIN retail.products p ON pe.product_id = p.product_id
            LEFT JOIN retail.product_categories pc ON p.category_id = pc.category_id
            WHERE pe.store_id = $2
              AND p.is_active = TRUE
              AND pe.product_id NOT IN (SELECT product_id FROM customer_purchases)
              AND 1 - (pe.embedding <=> ace.avg_embedding) >= 0.6
            ORDER BY pe.embedding <=> ace.avg_embedding
            LIMIT $3
        """ % days_back
        
        result = await self.execute_query(
            customer_recommendations_query,
            (customer_id, store_id, limit),
            store_id
        )
        
        if result.success:
            result.metadata = {
                'recommendation_type': 'customer_based',
                'customer_id': customer_id,
                'days_back': days_back,
                'store_id': store_id
            }
        
        return result
    
    def get_input_schema(self) -> Dict[str, Any]:
        """Get input schema for recommendation tool."""
        
        return {
            "type": "object",
            "properties": {
                "type": {
                    "type": "string",
                    "enum": ["similar_products", "customer_based", "trending", "cross_sell"],
                    "description": "Type of recommendation to generate",
                    "default": "similar_products"
                },
                "store_id": {
                    "type": "string",
                    "description": "Store ID for recommendations",
                    "pattern": "^[a-zA-Z0-9_-]+$"
                },
                "product_id": {
                    "type": "string",
                    "description": "Product ID for similar product recommendations"
                },
                "customer_id": {
                    "type": "string",
                    "description": "Customer ID for personalized recommendations"
                },
                "limit": {
                    "type": "integer",
                    "description": "Maximum number of recommendations",
                    "minimum": 1,
                    "maximum": 50,
                    "default": 10
                },
                "similarity_threshold": {
                    "type": "number",
                    "description": "Minimum similarity score",
                    "minimum": 0.0,
                    "maximum": 1.0,
                    "default": 0.7
                },
                "days_back": {
                    "type": "integer",
                    "description": "Days of purchase history to consider",
                    "minimum": 1,
                    "maximum": 365,
                    "default": 90
                }
            },
            "required": ["store_id"],
            "additionalProperties": False
        }
```

## โก เดชเตเดฐเดเดเดจ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป

### เดตเตเดเตเดเตผ เดเตเดตเดฑเดฟ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป

```sql
-- Optimize pgvector performance
-- Add to postgresql.conf

# Increase work_mem for vector operations
work_mem = '256MB'

# Optimize shared_buffers for vector data
shared_buffers = '512MB'

# Enable parallel query execution
max_parallel_workers_per_gather = 4
max_parallel_workers = 8

# Vector-specific optimizations
SET maintenance_work_mem = '1GB';
SET max_parallel_maintenance_workers = 4;

-- Optimize HNSW index parameters
CREATE INDEX CONCURRENTLY idx_product_embeddings_vector_optimized 
ON retail.product_embeddings 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 200);

-- Create partial indexes for active products only
CREATE INDEX CONCURRENTLY idx_product_embeddings_active
ON retail.product_embeddings 
USING hnsw (embedding vector_cosine_ops)
WHERE store_id IN (SELECT store_id FROM retail.stores WHERE is_active = TRUE);

-- Analyze vector distribution for optimization
ANALYZE retail.product_embeddings;

-- Vector search performance monitoring
CREATE OR REPLACE FUNCTION retail.analyze_vector_performance()
RETURNS TABLE (
    avg_search_time_ms NUMERIC,
    index_size TEXT,
    total_vectors BIGINT,
    cache_hit_ratio NUMERIC
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        (SELECT AVG(EXTRACT(MILLISECONDS FROM clock_timestamp() - query_start))
         FROM pg_stat_activity 
         WHERE query LIKE '%embedding <=> %'
         AND state = 'active') as avg_search_time_ms,
        pg_size_pretty(pg_relation_size('idx_product_embeddings_vector')) as index_size,
        COUNT(*)::BIGINT as total_vectors,
        (SELECT 100.0 * blks_hit / (blks_hit + blks_read) 
         FROM pg_stat_user_indexes 
         WHERE indexrelname = 'idx_product_embeddings_vector') as cache_hit_ratio
    FROM retail.product_embeddings;
END;
$$ LANGUAGE plpgsql;
```

### embedding เดเดพเดทเต เดคเดจเตเดคเตเดฐเด

```python
# mcp_server/embeddings/cache_manager.py
"""
Advanced caching strategy for embeddings and search results.
"""
import redis.asyncio as redis
import json
import hashlib
from typing import Dict, Any, List, Optional
from datetime import timedelta
import logging

logger = logging.getLogger(__name__)

class EmbeddingCacheManager:
    """Advanced caching for embeddings and search results."""
    
    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis_client = None
        self.redis_url = redis_url
        
        # เดเดพเดทเต TTL เดเตเดฐเดฎเตเดเดฐเดฃเดเตเดเตพ
        self.embedding_ttl = timedelta(days=7)  # 1 เดเดดเตเดเดเตเดเดพเดฏเดฟ เดเดเดฌเตเดกเดฟเดเดเตเดเตพ เดเดพเดทเต เดเตเดฏเตเดฏเตเดจเตเดจเต
        self.search_ttl = timedelta(hours=1)    # 1 เดฎเดฃเดฟเดเตเดเตเตผเดเตเดเดพเดฏเดฟ เดคเดฟเดฐเดฏเตฝ เดซเดฒเดเตเดเตพ เดเดพเดทเต เดเตเดฏเตเดฏเตเดจเตเดจเต
        self.recommendation_ttl = timedelta(hours=4)  # 4 เดฎเดฃเดฟเดเตเดเตเตผเดเตเดเดพเดฏเดฟ เดถเตเดชเดพเตผเดถเดเตพ เดเดพเดทเต เดเตเดฏเตเดฏเตเดจเตเดจเต
        
        # เดเดพเดทเต เดเต เดชเตเดฐเดฟเดซเดฟเดเตเดธเตเดเตพ
        self.EMBEDDING_PREFIX = "emb:"
        self.SEARCH_PREFIX = "search:"
        self.RECOMMENDATION_PREFIX = "rec:"
    
    async def initialize(self):
        """Initialize Redis connection."""
        
        try:
            self.redis_client = redis.from_url(self.redis_url)
            # เดเดฃเดเตเดทเตป เดชเดฐเดฟเดถเตเดงเดจ
            await self.redis_client.ping()
            logger.info("Embedding cache manager initialized")
        
        except Exception as e:
            logger.warning(f"Redis cache not available: {e}")
            self.redis_client = None
    
    async def cache_embedding(self, text: str, embedding: List[float], model: str):
        """Cache text embedding."""
        
        if not self.redis_client:
            return
        
        try:
            cache_key = self._get_embedding_key(text, model)
            cache_data = {
                'embedding': embedding,
                'model': model,
                'cached_at': str(datetime.utcnow())
            }
            
            await self.redis_client.setex(
                cache_key,
                self.embedding_ttl,
                json.dumps(cache_data)
            )
            
        except Exception as e:
            logger.warning(f"Failed to cache embedding: {e}")
    
    async def get_cached_embedding(self, text: str, model: str) -> Optional[List[float]]:
        """Get cached embedding."""
        
        if not self.redis_client:
            return None
        
        try:
            cache_key = self._get_embedding_key(text, model)
            cached_data = await self.redis_client.get(cache_key)
            
            if cached_data:
                data = json.loads(cached_data)
                return data['embedding']
        
        except Exception as e:
            logger.warning(f"Failed to retrieve cached embedding: {e}")
        
        return None
    
    async def cache_search_results(
        self, 
        query: str, 
        store_id: str, 
        results: List[Dict],
        search_params: Dict[str, Any]
    ):
        """Cache search results."""
        
        if not self.redis_client:
            return
        
        try:
            cache_key = self._get_search_key(query, store_id, search_params)
            cache_data = {
                'results': results,
                'query': query,
                'store_id': store_id,
                'params': search_params,
                'cached_at': str(datetime.utcnow())
            }
            
            await self.redis_client.setex(
                cache_key,
                self.search_ttl,
                json.dumps(cache_data, default=str)
            )
            
        except Exception as e:
            logger.warning(f"Failed to cache search results: {e}")
    
    async def get_cached_search_results(
        self, 
        query: str, 
        store_id: str, 
        search_params: Dict[str, Any]
    ) -> Optional[List[Dict]]:
        """Get cached search results."""
        
        if not self.redis_client:
            return None
        
        try:
            cache_key = self._get_search_key(query, store_id, search_params)
            cached_data = await self.redis_client.get(cache_key)
            
            if cached_data:
                data = json.loads(cached_data)
                return data['results']
        
        except Exception as e:
            logger.warning(f"Failed to retrieve cached search results: {e}")
        
        return None
    
    def _get_embedding_key(self, text: str, model: str) -> str:
        """Generate cache key for embedding."""
        
        content = f"{model}:{text.strip()}"
        hash_key = hashlib.sha256(content.encode()).hexdigest()
        return f"{self.EMBEDDING_PREFIX}{hash_key}"
    
    def _get_search_key(self, query: str, store_id: str, params: Dict[str, Any]) -> str:
        """Generate cache key for search results."""
        
        # เดเตเดตเดฑเดฟ เฎฎเฎฑเฏเฎฑเฏเฎฎเฏ เดชเดพเดฐเดพเดฎเตเดฑเตเดฑเดฑเตเดเดณเดฟเตฝ เดจเดฟเดจเตเดจเต เดธเตเดฅเดฟเดฐเดฎเดพเดฏ เดนเดพเดทเต เดธเตเดทเตเดเดฟเดเตเดเตเด
        content = f"{query}:{store_id}:{json.dumps(params, sort_keys=True)}"
        hash_key = hashlib.sha256(content.encode()).hexdigest()
        return f"{self.SEARCH_PREFIX}{hash_key}"
    
    async def invalidate_store_cache(self, store_id: str):
        """Invalidate all cached data for a store."""
        
        if not self.redis_client:
            return
        
        try:
            # เดธเตเดฑเตเดฑเตเดฑเตเดฎเดพเดฏเดฟ เดฌเดจเตเดงเดชเตเดชเตเดเตเด เดเดฒเตเดฒเดพ เดเตเดเดณเตเด เดเดฃเตเดเตเดคเตเดคเตเด
            pattern = f"*:{store_id}:*"
            keys = await self.redis_client.keys(pattern)
            
            if keys:
                await self.redis_client.delete(*keys)
                logger.info(f"Invalidated {len(keys)} cache entries for store {store_id}")
        
        except Exception as e:
            logger.warning(f"Failed to invalidate store cache: {e}")
    
    async def cleanup(self):
        """Cleanup cache resources."""
        
        if self.redis_client:
            await self.redis_client.close()

# เดเตเดฒเตเดฌเตฝ เดเดพเดทเต เดฎเดพเดจเตเดเตผ
cache_manager = EmbeddingCacheManager()
```

## ๐ฏ เดชเตเดฐเดงเดพเดจเดชเตเดชเตเดเตเด เดเดพเดฐเตเดฏเดเตเดเตพ

เด เดฒเดพเดฌเต เดชเตเตผเดคเตเดคเดฟเดฏเดพเดเตเดเดฟเดฏ เดถเตเดทเด, เดจเดฟเดเตเดเตพเดเตเดเตเดฃเตเดเดพเดเดฃเด:

โ **Azure OpenAI เดเดจเตเดฑเดเตเดฐเตเดทเตป**: เดเดพเดทเดฟเดเดเต, เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป เดเดจเตเดจเดฟเดตเดฏเตเดเต เดชเตเตผเดฃเตเดฃเดฎเดพเดฏ embedding เดธเตเดทเตเดเดฟเดเตเดเตฝ  
โ **เดตเตเดเตเดเตผ เดธเตเตผเดเตเดเต เดจเดเดชเตเดชเดพเดเตเดเตฝ**: pgvector เดเดชเดฏเตเดเดฟเดเตเดเต เดชเตเดฐเตเดกเดเตเดทเตป-เดธเดเตเดเดฎเดพเดฏ เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต  
โ **เดนเตเดฌเตเดฐเดฟเดกเต เดธเตเตผเดเตเดเต เดเดดเดฟเดตเตเดเตพ**: เดฎเดฟเดเดเตเด เดซเดฒเดเตเดเตพเดเตเดเต เดเตเดตเตเดกเต, เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต เดธเดเดฏเตเดเดจเด  
โ **เดถเตเดชเดพเตผเดถเดพ เดธเดฟเดธเตเดฑเตเดฑเดเตเดเตพ**: เดธเดฎเดพเดจเดค เดเดชเดฏเตเดเดฟเดเตเดเต AI-เดถเดเตเดคเดฟเดฏเตเดณเตเดณ เดเตฝเดชเตเดชเดจเตเดจ เดถเตเดชเดพเตผเดถเดเตพ  
โ **เดชเตเดฐเดเดเดจ เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป**: เดตเตเดเตเดเตผ เดเตปเดกเดเตเดธเต เดเดชเตเดฑเตเดฑเดฟเดฎเตเดธเตเดทเตป, เดฌเตเดฆเตเดงเดฟเดฎเตเดเตเดเตเดณเตเดณ เดเดพเดทเดฟเดเดเต  
โ **เดธเตเดเตเดฏเดฟเดฒเดฌเดฟเตพ เดเตผเดเตเดเดฟเดเตเดเตเดเตผ**: เดเดจเตเดฑเตผเดชเตเดฐเตเดธเต-เดธเดเตเดเดฎเดพเดฏ เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต เดเดเดฟเดธเตเดฅเดพเดจเดธเตเดเดฐเตเดฏเด  

## ๐ เดเดเตเดคเตเดคเดคเต เดเดจเตเดคเดพเดฃเต

**[Lab 08: Testing and Debugging](../08-Testing/README.md)**-เดจเตเดชเตเดชเด เดคเตเดเดฐเตเด:

- เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเดฟเดจเตเดณเตเดณ เดธเดฎเดเตเดฐเดฎเดพเดฏ เดเตเดธเตเดฑเตเดฑเดฟเดเดเต เดคเดจเตเดคเตเดฐเดเตเดเตพ เดจเดเดชเตเดชเดฟเดฒเดพเดเตเดเตเด  
- เดตเตเดเตเดเตผ เดธเตเตผเดเตเดเต เดชเตเดฐเดเดเดจ เดชเตเดฐเดถเตเดจเดเตเดเตพ เดกเตเดฌเดเต เดเตเดฏเตเดฏเตเด  
- embedding เดเตเดฃเดฎเตเดจเตเดฎเดฏเตเด เดชเตเดฐเดธเดเตเดคเดฟเดฏเตเด เดธเตเดฅเดฟเดฐเตเดเดฐเดฟเดเตเดเตเด  
- เดถเตเดชเดพเตผเดถเดพ เดธเดฟเดธเตเดฑเตเดฑเดคเตเดคเดฟเดจเตเดฑเต เดเตเดคเตเดฏเดค เดชเดฐเดฟเดถเตเดงเดฟเดเตเดเตเด  

## ๐ เดเดงเดฟเด เดธเตเดฐเตเดคเดธเตเดเตพ

### Azure OpenAI
- [Azure OpenAI Service Documentation](https://docs.microsoft.com/azure/cognitive-services/openai/) - เดธเดฎเดเตเดฐ เดธเตเดตเดจ เดฎเดพเตผเดเตเดเดจเดฟเตผเดฆเตเดฆเตเดถเด  
- [Embeddings API Reference](https://platform.openai.com/docs/api-reference/embeddings) - API เดกเตเดเตเดฏเตเดฎเตเดจเตเดฑเตเดทเตป  
- [Best Practices for Embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings) - เดจเดเดชเตเดชเดพเดเตเดเตฝ เดฎเดพเตผเดเตเดเดจเดฟเตผเดฆเตเดฆเตเดถเด  

### เดตเตเดเตเดเตผ เดกเดพเดฑเตเดฑเดพเดฌเตเดธเตเดเตพ
- [pgvector Documentation](https://github.com/pgvector/pgvector) - PostgreSQL เดตเตเดเตเดเตผ เดเดเตเดธเตเดฑเตเดฑเตปเดทเตป  
- [Vector Search Optimization](https://www.pinecone.io/learn/vector-search-optimization/) - เดชเตเดฐเดเดเดจ เดเตเดฏเตเดฃเดฟเดเดเต  
- [HNSW Algorithm](https://arxiv.org/abs/1603.09320) - เดนเดฏเตผเดเตผเดเตเดเดฟเดเตเดเตฝ เดจเดพเดตเดฟเดเดฌเดฟเตพ เดธเตเดฎเตเตพ เดตเตเตพเดกเต เดเตเดฐเดพเดซเตเดเตพ  

### เดธเตเดฎเดพเดจเตเดฑเดฟเดเต เดธเตเตผเดเตเดเต
- [Information Retrieval Fundamentals](https://nlp.stanford.edu/IR-book/) - เดธเตเดฑเตเดฑเดพเตปเดซเตเตผเดกเต IR เดชเดพเดเดชเตเดธเตเดคเดเด  
- [Vector Search Best Practices](https://weaviate.io/blog/vector-search-best-practices) - เดจเดเดชเตเดชเดพเดเตเดเตฝ เดฎเดพเดคเตเดเดเตพ  
- [Hybrid Search Strategies](https://blog.vespa.ai/hybrid-search/) - เดตเตเดฏเดคเตเดฏเดธเตเดค เดธเตเตผเดเตเดเต เดธเดฎเตเดชเดจเดเตเดเตพ เดธเดเดฏเตเดเดฟเดชเตเดชเดฟเดเตเดเตฝ  

---

**เดฎเตเตปเดชเต**: [Lab 06: Tool Development](../06-Tools/README.md)  
**เดเดเตเดคเตเดคเดคเต**: [Lab 08: Testing and Debugging](../08-Testing/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**เดเดธเตเดฏเดพ**:  
เด เดฐเตเด AI เดตเดฟเดตเตผเดคเตเดคเดจ เดธเตเดตเดจเด [Co-op Translator](https://github.com/Azure/co-op-translator) เดเดชเดฏเตเดเดฟเดเตเดเต เดตเดฟเดตเตผเดคเตเดคเดจเด เดเตเดฏเตเดคเดคเดพเดฃเต. เดจเดพเด เดเตเดคเตเดฏเดคเดฏเตเดเตเดเต เดถเตเดฐเดฎเดฟเดเตเดเดฟเดเตเดเตเดฃเตเดเตเดเตเดเดฟเดฒเตเด, เดธเตเดตเดฏเด เดชเตเดฐเดตเตผเดคเตเดคเดฟเดเตเดเตเดจเตเดจ เดตเดฟเดตเตผเดคเตเดคเดจเดเตเดเดณเดฟเตฝ เดชเดฟเดถเดเตเดเตพ เดเดฒเตเดฒเตเดเตเดเดฟเตฝ เดคเตเดฑเตเดฑเตเดเตพ เดเดฃเตเดเดพเดเดพเดฎเตเดจเตเดจเต เดฆเดฏเดตเดพเดฏเดฟ เดถเตเดฐเดฆเตเดงเดฟเดเตเดเตเด. เดเดคเดฟเดจเตเดฑเต เดฎเดพเดคเตเดญเดพเดทเดฏเดฟเดฒเตเดณเตเดณ เดฏเดฅเดพเตผเดคเตเดฅ เดฐเตเดเดฏเดพเดฃเต เดชเตเดฐเดพเดฎเดพเดฃเดฟเดเดฎเดพเดฏ เดเดฑเดตเดฟเดเด เดเดจเตเดจเต เดชเดฐเดฟเดเดฃเดฟเดเตเดเตเดฃเตเดเดคเดพเดฃเต. เดจเดฟเตผเดฃเดพเดฏเดเดฎเดพเดฏ เดตเดฟเดตเดฐเดเตเดเตพเดเตเดเต, เดชเตเดฐเตเดซเดทเดฃเตฝ เดฎเดจเตเดทเตเดฏ เดตเดฟเดตเตผเดคเตเดคเดจเด เดถเตเดชเดพเตผเดถ เดเตเดฏเตเดฏเดชเตเดชเตเดเตเดจเตเดจเต. เด เดตเดฟเดตเตผเดคเตเดคเดจเด เดเดชเดฏเตเดเดฟเดเตเดเตเดจเตเดจเดคเดฟเตฝ เดจเดฟเดจเตเดจเตเดฃเตเดเดพเดเตเดจเตเดจ เดเดคเตเดเตเดเดฟเดฒเตเด เดคเตเดฑเตเดฑเดฟเดฆเตเดงเดพเดฐเดฃเดเตพเดเตเดเต เดคเตเดฑเตเดฑเดพเดฏ เดตเตเดฏเดพเดเตเดฏเดพเดจเดเตเดเตพเดเตเดเต เดเดเตเดเตพ เดเดคเตเดคเดฐเดตเดพเดฆเดฟเดเดณเดฒเตเดฒ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->