# Explorare DetaliatÄƒ a FuncÈ›iilor Protocolului MCP

Acest ghid exploreazÄƒ funcÈ›ii avansate ale protocolului MCP care depÄƒÈ™esc gestionarea de bazÄƒ a uneltelor È™i resurselor. ÃnÈ›elegerea acestor funcÈ›ii te ajutÄƒ sÄƒ construieÈ™ti servere MCP mai robuste, uÈ™or de utilizat È™i gata pentru producÈ›ie.

## FuncÈ›ii Acoperite

1. **NotificÄƒri de Progres** - Raportarea progresului pentru operaÈ›iuni de duratÄƒ lungÄƒ  
2. **Anularea Cererilor** - Permite clienÈ›ilor sÄƒ anuleze cererile Ã®n curs  
3. **È˜abloane de Resurse** - URI-uri dinamice de resurse cu parametri  
4. **Evenimente Ã®n Ciclu de ViaÈ›Äƒ al Serverului** - IniÈ›ializare È™i Ã®nchidere corectÄƒ  
5. **Controlul LogÄƒrii** - Configurarea logÄƒrii pe partea de server  
6. **Modele de Gestionare a Erorilor** - RÄƒspunsuri consistente la erori  

---

## 1. NotificÄƒri de Progres

Pentru operaÈ›iuni care necesitÄƒ timp (procesarea datelor, descÄƒrcÄƒri de fiÈ™iere, apeluri API), notificÄƒrile de progres È›in utilizatorii informaÈ›i.

### Cum FuncÈ›ioneazÄƒ

```mermaid
sequenceDiagram
    participant Client
    participant Server
    
    Client->>Server: tools/call (operaÈ›ie Ã®ndelungatÄƒ)
    Server-->>Client: notificare: progres 10%
    Server-->>Client: notificare: progres 50%
    Server-->>Client: notificare: progres 90%
    Server->>Client: rezultat (finalizat)
```  
### Implementare Python

```python
from mcp.server import Server, NotificationOptions
from mcp.types import ProgressNotification
import asyncio

app = Server("progress-server")

@app.tool()
async def process_large_file(file_path: str, ctx) -> str:
    """Process a large file with progress updates."""
    
    # ObÈ›ine dimensiunea fiÈ™ierului pentru calculul progresului
    file_size = os.path.getsize(file_path)
    processed = 0
    
    with open(file_path, 'rb') as f:
        while chunk := f.read(8192):
            # ProceseazÄƒ fragmentul
            await process_chunk(chunk)
            processed += len(chunk)
            
            # Trimite notificare de progres
            progress = (processed / file_size) * 100
            await ctx.send_notification(
                ProgressNotification(
                    progressToken=ctx.request_id,
                    progress=progress,
                    total=100,
                    message=f"Processing: {progress:.1f}%"
                )
            )
    
    return f"Processed {file_size} bytes"

@app.tool()
async def batch_operation(items: list[str], ctx) -> str:
    """Process multiple items with progress."""
    
    results = []
    total = len(items)
    
    for i, item in enumerate(items):
        result = await process_item(item)
        results.append(result)
        
        # RaporteazÄƒ progresul dupÄƒ fiecare element
        await ctx.send_notification(
            ProgressNotification(
                progressToken=ctx.request_id,
                progress=i + 1,
                total=total,
                message=f"Processed {i + 1}/{total}: {item}"
            )
        )
    
    return f"Completed {total} items"
```
  
### Implementare TypeScript

```typescript
import { Server } from "@modelcontextprotocol/sdk/server/index.js";

server.setRequestHandler(CallToolSchema, async (request, extra) => {
  const { name, arguments: args } = request.params;
  
  if (name === "process_data") {
    const items = args.items as string[];
    const results = [];
    
    for (let i = 0; i < items.length; i++) {
      const result = await processItem(items[i]);
      results.push(result);
      
      // Trimite notificare de progres
      await extra.sendNotification({
        method: "notifications/progress",
        params: {
          progressToken: request.id,
          progress: i + 1,
          total: items.length,
          message: `Processing item ${i + 1}/${items.length}`
        }
      });
    }
    
    return { content: [{ type: "text", text: JSON.stringify(results) }] };
  }
});
```
  
### Gestionarea pe Client (Python)

```python
async def handle_progress(notification):
    """Handle progress notifications from server."""
    params = notification.params
    print(f"Progress: {params.progress}/{params.total} - {params.message}")

# ÃnregistreazÄƒ handler
session.on_notification("notifications/progress", handle_progress)

# ApeleazÄƒ instrumentul (actualizÄƒrile de progres vor fi primite prin handler)
result = await session.call_tool("process_large_file", {"file_path": "/data/large.csv"})
```
  
---

## 2. Anularea Cererilor

Permite clienÈ›ilor sÄƒ anuleze cererile care nu mai sunt necesare sau care dureazÄƒ prea mult.

### Implementare Python

```python
from mcp.server import Server
from mcp.types import CancelledError
import asyncio

app = Server("cancellable-server")

@app.tool()
async def long_running_search(query: str, ctx) -> str:
    """Search that can be cancelled."""
    
    results = []
    
    try:
        for page in range(100):  # CautÄƒ prin mai multe pagini
            # VerificÄƒ dacÄƒ a fost solicitatÄƒ anularea
            if ctx.is_cancelled:
                raise CancelledError("Search cancelled by user")
            
            # SimuleazÄƒ cÄƒutarea pe paginÄƒ
            page_results = await search_page(query, page)
            results.extend(page_results)
            
            # O Ã®ntÃ¢rziere micÄƒ permite verificÄƒri de anulare
            await asyncio.sleep(0.1)
            
    except CancelledError:
        # ReturneazÄƒ rezultate parÈ›iale
        return f"Cancelled. Found {len(results)} results before cancellation."
    
    return f"Found {len(results)} total results"

@app.tool()
async def download_file(url: str, ctx) -> str:
    """Download with cancellation support."""
    
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            chunks = []
            
            async for chunk in response.content.iter_chunked(8192):
                if ctx.is_cancelled:
                    return f"Download cancelled at {downloaded}/{total_size} bytes"
                
                chunks.append(chunk)
                downloaded += len(chunk)
            
            return f"Downloaded {downloaded} bytes"
```
  
### Implementarea Contextului de Anulare

```python
class CancellableContext:
    """Context object that tracks cancellation state."""
    
    def __init__(self, request_id: str):
        self.request_id = request_id
        self._cancelled = asyncio.Event()
        self._cancel_reason = None
    
    @property
    def is_cancelled(self) -> bool:
        return self._cancelled.is_set()
    
    def cancel(self, reason: str = "Cancelled"):
        self._cancel_reason = reason
        self._cancelled.set()
    
    async def check_cancelled(self):
        """Raise if cancelled, otherwise continue."""
        if self.is_cancelled:
            raise CancelledError(self._cancel_reason)
    
    async def sleep_or_cancel(self, seconds: float):
        """Sleep that can be interrupted by cancellation."""
        try:
            await asyncio.wait_for(
                self._cancelled.wait(),
                timeout=seconds
            )
            raise CancelledError(self._cancel_reason)
        except asyncio.TimeoutError:
            pass  # Timeout normal, continuÄƒ
```
  
### Anularea pe Partea de Client

```python
import asyncio

async def search_with_timeout(session, query, timeout=30):
    """Search with automatic cancellation on timeout."""
    
    task = asyncio.create_task(
        session.call_tool("long_running_search", {"query": query})
    )
    
    try:
        result = await asyncio.wait_for(task, timeout=timeout)
        return result
    except asyncio.TimeoutError:
        # Cerere de anulare
        await session.send_notification({
            "method": "notifications/cancelled",
            "params": {"requestId": task.request_id, "reason": "Timeout"}
        })
        return "Search timed out"
```
  
---

## 3. È˜abloane de Resurse

È˜abloanele de resurse permit construirea dinamicÄƒ a URI-urilor cu parametri, utile pentru API-uri È™i baze de date.

### Definirea È˜abloanelor

```python
from mcp.server import Server
from mcp.types import ResourceTemplate

app = Server("template-server")

@app.list_resource_templates()
async def list_templates() -> list[ResourceTemplate]:
    """Return available resource templates."""
    return [
        ResourceTemplate(
            uriTemplate="db://users/{user_id}",
            name="User Profile",
            description="Fetch user profile by ID",
            mimeType="application/json"
        ),
        ResourceTemplate(
            uriTemplate="api://weather/{city}/{date}",
            name="Weather Data",
            description="Historical weather for city and date",
            mimeType="application/json"
        ),
        ResourceTemplate(
            uriTemplate="file://{path}",
            name="File Content",
            description="Read file at given path",
            mimeType="text/plain"
        )
    ]

@app.read_resource()
async def read_resource(uri: str) -> str:
    """Read resource, expanding template parameters."""
    
    # AnalizeazÄƒ URI-ul pentru a extrage parametrii
    if uri.startswith("db://users/"):
        user_id = uri.split("/")[-1]
        return await fetch_user(user_id)
    
    elif uri.startswith("api://weather/"):
        parts = uri.replace("api://weather/", "").split("/")
        city, date = parts[0], parts[1]
        return await fetch_weather(city, date)
    
    elif uri.startswith("file://"):
        path = uri.replace("file://", "")
        return await read_file(path)
    
    raise ValueError(f"Unknown resource URI: {uri}")
```
  
### Implementare TypeScript

```typescript
server.setRequestHandler(ListResourceTemplatesSchema, async () => {
  return {
    resourceTemplates: [
      {
        uriTemplate: "github://repos/{owner}/{repo}/issues/{issue_number}",
        name: "GitHub Issue",
        description: "Fetch a specific GitHub issue",
        mimeType: "application/json"
      },
      {
        uriTemplate: "db://tables/{table}/rows/{id}",
        name: "Database Row",
        description: "Fetch a row from a database table",
        mimeType: "application/json"
      }
    ]
  };
});

server.setRequestHandler(ReadResourceSchema, async (request) => {
  const uri = request.params.uri;
  
  // AnalizeazÄƒ URI-ul problemei GitHub
  const githubMatch = uri.match(/^github:\/\/repos\/([^/]+)\/([^/]+)\/issues\/(\d+)$/);
  if (githubMatch) {
    const [_, owner, repo, issueNumber] = githubMatch;
    const issue = await fetchGitHubIssue(owner, repo, parseInt(issueNumber));
    return {
      contents: [{
        uri,
        mimeType: "application/json",
        text: JSON.stringify(issue, null, 2)
      }]
    };
  }
  
  throw new Error(`Unknown resource URI: ${uri}`);
});
```
  
---

## 4. Evenimente Ã®n Ciclu de ViaÈ›Äƒ al Serverului

Gestionarea corectÄƒ a iniÈ›ializÄƒrii È™i Ã®nchiderii asigurÄƒ o administrare curatÄƒ a resurselor.

### Managementul Ciclu de ViaÈ›Äƒ Ã®n Python

```python
from mcp.server import Server
from contextlib import asynccontextmanager

app = Server("lifecycle-server")

# Stare partajatÄƒ
db_connection = None
cache = None

@asynccontextmanager
async def lifespan(server: Server):
    """Manage server lifecycle."""
    global db_connection, cache
    
    # Pornire
    print("ğŸš€ Server starting...")
    db_connection = await create_database_connection()
    cache = await create_cache_client()
    print("âœ… Resources initialized")
    
    yield  # Serverul ruleazÄƒ aici
    
    # Oprire
    print("ğŸ›‘ Server shutting down...")
    await db_connection.close()
    await cache.close()
    print("âœ… Resources cleaned up")

app = Server("lifecycle-server", lifespan=lifespan)

@app.tool()
async def query_database(sql: str) -> str:
    """Use the shared database connection."""
    result = await db_connection.execute(sql)
    return str(result)
```
  
### Ciclu de ViaÈ›Äƒ Ã®n TypeScript

```typescript
import { Server } from "@modelcontextprotocol/sdk/server/index.js";

class ManagedServer {
  private server: Server;
  private dbConnection: DatabaseConnection | null = null;
  
  constructor() {
    this.server = new Server({
      name: "lifecycle-server",
      version: "1.0.0"
    });
    
    this.setupHandlers();
  }
  
  async start() {
    // IniÈ›ializeazÄƒ resursele
    console.log("ğŸš€ Server starting...");
    this.dbConnection = await createDatabaseConnection();
    console.log("âœ… Database connected");
    
    // PorneÈ™te serverul
    await this.server.connect(transport);
  }
  
  async stop() {
    // CurÄƒÈ›Äƒ resursele
    console.log("ğŸ›‘ Server shutting down...");
    if (this.dbConnection) {
      await this.dbConnection.close();
    }
    await this.server.close();
    console.log("âœ… Cleanup complete");
  }
  
  private setupHandlers() {
    this.server.setRequestHandler(CallToolSchema, async (request) => {
      // FoloseÈ™te this.dbConnection Ã®n siguranÈ›Äƒ
      // ...
    });
  }
}

// Utilizare cu oprire controlatÄƒ
const server = new ManagedServer();

process.on('SIGINT', async () => {
  await server.stop();
  process.exit(0);
});

await server.start();
```
  
---

## 5. Controlul LogÄƒrii

MCP suportÄƒ niveluri de logare pe partea de server pe care clienÈ›ii le pot controla.

### Implementarea Nivelurilor de Logare

```python
from mcp.server import Server
from mcp.types import LoggingLevel
import logging

app = Server("logging-server")

# MapeazÄƒ nivelurile MCP la nivelurile de logare Python
LEVEL_MAP = {
    LoggingLevel.DEBUG: logging.DEBUG,
    LoggingLevel.INFO: logging.INFO,
    LoggingLevel.WARNING: logging.WARNING,
    LoggingLevel.ERROR: logging.ERROR,
}

logger = logging.getLogger("mcp-server")

@app.set_logging_level()
async def set_logging_level(level: LoggingLevel) -> None:
    """Handle client request to change logging level."""
    python_level = LEVEL_MAP.get(level, logging.INFO)
    logger.setLevel(python_level)
    logger.info(f"Logging level set to {level}")

@app.tool()
async def debug_operation(data: str) -> str:
    """Tool with various logging levels."""
    logger.debug(f"Processing data: {data}")
    
    try:
        result = process(data)
        logger.info(f"Successfully processed: {result}")
        return result
    except Exception as e:
        logger.error(f"Processing failed: {e}")
        raise
```
  
### Trimiterea Mesajelor de Log cÄƒtre Client

```python
@app.tool()
async def complex_operation(input: str, ctx) -> str:
    """Operation that logs to client."""
    
    # Trimite notificare de jurnal cÄƒtre client
    await ctx.send_log(
        level="info",
        message=f"Starting complex operation with input: {input}"
    )
    
    # EfectueazÄƒ lucrarea...
    result = await do_work(input)
    
    await ctx.send_log(
        level="debug",
        message=f"Operation complete, result size: {len(result)}"
    )
    
    return result
```
  
---

## 6. Modele de Gestionare a Erorilor

Gestionarea consistentÄƒ a erorilor Ã®mbunÄƒtÄƒÈ›eÈ™te depanarea È™i experienÈ›a utilizatorului.

### Coduri de Eroare MCP

```python
from mcp.types import McpError, ErrorCode

class ToolError(McpError):
    """Base class for tool errors."""
    pass

class ValidationError(ToolError):
    """Invalid input parameters."""
    def __init__(self, message: str):
        super().__init__(ErrorCode.INVALID_PARAMS, message)

class NotFoundError(ToolError):
    """Requested resource not found."""
    def __init__(self, resource: str):
        super().__init__(ErrorCode.INVALID_REQUEST, f"Not found: {resource}")

class PermissionError(ToolError):
    """Access denied."""
    def __init__(self, action: str):
        super().__init__(ErrorCode.INVALID_REQUEST, f"Permission denied: {action}")

class InternalError(ToolError):
    """Internal server error."""
    def __init__(self, message: str):
        super().__init__(ErrorCode.INTERNAL_ERROR, message)
```
  
### RÄƒspunsuri Structurate la Erori

```python
@app.tool()
async def safe_operation(input: str) -> str:
    """Tool with comprehensive error handling."""
    
    # ValideazÄƒ intrarea
    if not input:
        raise ValidationError("Input cannot be empty")
    
    if len(input) > 10000:
        raise ValidationError(f"Input too large: {len(input)} chars (max 10000)")
    
    try:
        # VerificÄƒ permisiunile
        if not await check_permission(input):
            raise PermissionError(f"read {input}")
        
        # EfectueazÄƒ operaÈ›ia
        result = await perform_operation(input)
        
        if result is None:
            raise NotFoundError(input)
        
        return result
        
    except ConnectionError as e:
        raise InternalError(f"Database connection failed: {e}")
    except TimeoutError as e:
        raise InternalError(f"Operation timed out: {e}")
    except Exception as e:
        # ÃnregistreazÄƒ erorile neaÈ™teptate
        logger.exception(f"Unexpected error in safe_operation")
        raise InternalError(f"Unexpected error: {type(e).__name__}")
```
  
### Gestionarea Erorilor Ã®n TypeScript

```typescript
import { McpError, ErrorCode } from "@modelcontextprotocol/sdk/types.js";

function validateInput(data: unknown): asserts data is ValidInput {
  if (typeof data !== "object" || data === null) {
    throw new McpError(
      ErrorCode.InvalidParams,
      "Input must be an object"
    );
  }
  // Mai multe validÄƒri...
}

server.setRequestHandler(CallToolSchema, async (request) => {
  try {
    validateInput(request.params.arguments);
    
    const result = await performOperation(request.params.arguments);
    
    return {
      content: [{ type: "text", text: JSON.stringify(result) }]
    };
    
  } catch (error) {
    if (error instanceof McpError) {
      throw error;  // Eroare MCP deja existentÄƒ
    }
    
    // ConverteÈ™te alte erori
    if (error instanceof NotFoundError) {
      throw new McpError(ErrorCode.InvalidRequest, error.message);
    }
    
    // Eroare necunoscutÄƒ
    console.error("Unexpected error:", error);
    throw new McpError(
      ErrorCode.InternalError,
      "An unexpected error occurred"
    );
  }
});
```
  
---

## FuncÈ›ii Experimentale (MCP 2025-11-25)

Aceste funcÈ›ii sunt marcate ca experimentale Ã®n specificaÈ›ie:

### Task-uri (OperaÈ›iuni de DuratÄƒ LungÄƒ)

```python
# Sarcinile permit urmÄƒrirea operaÈ›iunilor de lungÄƒ duratÄƒ cu stare
@app.task()
async def training_task(model_id: str, data_path: str, ctx) -> str:
    """Long-running ML training task."""
    
    # RaportaÈ›i Ã®nceputul sarcinii
    await ctx.report_status("running", "Initializing training...")
    
    # Bucla de antrenament
    for epoch in range(100):
        await train_epoch(model_id, data_path, epoch)
        await ctx.report_status(
            "running",
            f"Training epoch {epoch + 1}/100",
            progress=epoch + 1,
            total=100
        )
    
    await ctx.report_status("completed", "Training finished")
    return f"Model {model_id} trained successfully"
```
  
### AnotÄƒri pentru Unelte

```python
# AnotÄƒrile oferÄƒ metadate despre comportamentul uneltei
@app.tool(
    annotations={
        "destructive": False,      # Nu modificÄƒ datele
        "idempotent": True,        # Sigur de Ã®ncercat din nou
        "timeout_seconds": 30,     # Durata maximÄƒ aÈ™teptatÄƒ
        "requires_approval": False # Nu este necesarÄƒ aprobarea utilizatorului
    }
)
async def safe_query(query: str) -> str:
    """A read-only database query tool."""
    return await execute_read_query(query)
```
  
---

## Ce UrmeazÄƒ

- [Modulul 8 - Cele Mai Bune Practici](../../08-BestPractices/README.md)  
- [5.14 - Ingineria Contextului](../mcp-contextengineering/README.md)  
- [SchimbÄƒri Ã®n SpecificaÈ›ia MCP](https://spec.modelcontextprotocol.io/)  

---

## Resurse Suplimentare

- [SpecificaÈ›ia MCP 2025-11-25](https://spec.modelcontextprotocol.io/specification/2025-11-25/)  
- [Coduri de Eroare JSON-RPC 2.0](https://www.jsonrpc.org/specification#error_object)  
- [Exemple SDK Python](https://github.com/modelcontextprotocol/python-sdk/tree/main/examples)  
- [Exemple SDK TypeScript](https://github.com/modelcontextprotocol/typescript-sdk/tree/main/examples)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Declinare a responsabilitÄƒÈ›ii**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim pentru acurateÈ›e, vÄƒ rugÄƒm sÄƒ reÈ›ineÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original, Ã®n limba sa nativÄƒ, trebuie considerat sursa autorizatÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist. Nu ne asumÄƒm rÄƒspunderea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite ce pot apÄƒrea Ã®n urma utilizÄƒrii acestei traduceri.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->