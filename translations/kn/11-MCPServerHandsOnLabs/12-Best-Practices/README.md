# ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤Ö‡≤≠‡≥ç‡≤Ø‡≤æ‡≤∏‡≤ó‡≤≥‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç

## üéØ ‡≤à ‡≤™‡≥ç‡≤∞‡≤Ø‡≥ã‡≤ó‡≤∂‡≤æ‡≤≤‡≥Ü ‡≤è‡≤®‡≥Å ‡≤í‡≤≥‡≤ó‡≥ä‡≤Ç‡≤°‡≤ø‡≤¶‡≥Ü

‡≤à ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤™‡≥ç‚Äå‡≤∏‡≥ç‡≤ü‡≥ã‡≤®‡≥ç ‡≤™‡≥ç‡≤∞‡≤Ø‡≥ã‡≤ó‡≤∂‡≤æ‡≤≤‡≥Ü ‡≤¨‡≤≤‡≤µ‡≤æ‡≤¶, ‡≤µ‡≤ø‡≤∏‡≥ç‡≤§‡≤∞‡≤ø‡≤∏‡≤¨‡≤π‡≥Å‡≤¶‡≤æ‡≤¶ ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤∏‡≥Å‡≤∞‡≤ï‡≥ç‡≤∑‡≤ø‡≤§ MCP ‡≤∏‡≤∞‡≥ç‡≤µ‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤°‡≥á‡≤ü‡≤æ‡≤¨‡≥á‡≤∏‡≥ç ‡≤è‡≤ï‡≥Ä‡≤ï‡≤∞‡≤£‡≤¶‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü ‡≤®‡≤ø‡≤∞‡≥ç‡≤Æ‡≤ø‡≤∏‡≤≤‡≥Å ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤Ö‡≤≠‡≥ç‡≤Ø‡≤æ‡≤∏‡≤ó‡≤≥‡≥Å, ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≤æ ‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ó‡≤∏‡≥Ç‡≤ö‡≤ø‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≤Ç‡≤Ø‡≥ã‡≤ú‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü. ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Ö‡≤®‡≥Å‡≤∑‡≥ç‡≤†‡≤æ‡≤®‡≤µ‡≥Å ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß‡≤µ‡≤æ‡≤ó‡≤ø‡≤∞‡≥Å‡≤µ‡≥Å‡≤¶‡≤®‡≥ç‡≤®‡≥Å ‡≤ñ‡≤ö‡≤ø‡≤§‡≤™‡≤°‡≤ø‡≤∏‡≤≤‡≥Å ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤®‡≥à‡≤ú-‡≤ú‡≤ó‡≤§‡≥ç‡≤§‡≤ø‡≤® ‡≤Ö‡≤®‡≥Å‡≤≠‡≤µ ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤ï‡≥à‡≤ó‡≤æ‡≤∞‡≤ø‡≤ï‡≤æ ‡≤Æ‡≤æ‡≤®‡≤¶‡≤Ç‡≤°‡≤ó‡≤≥‡≤ø‡≤Ç‡≤¶ ‡≤ï‡≤≤‡≤ø‡≤Ø‡≥Å‡≤§‡≥ç‡≤§‡≥Ä‡≤∞‡≤ø.

## ‡≤Ö‡≤µ‡≤≤‡≥ã‡≤ï‡≤®

‡≤Ø‡≤∂‡≤∏‡≥ç‡≤µ‡≤ø MCP ‡≤∏‡≤∞‡≥ç‡≤µ‡≤∞‡≥ç ‡≤®‡≤ø‡≤∞‡≥ç‡≤Æ‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤ï‡≥á‡≤µ‡≤≤ ‡≤ï‡≥ã‡≤°‡≥ç ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤®‡≤ø‡≤∞‡≥ç‡≤µ‡≤π‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≤ï‡≥ç‡≤ï‡≤ø‡≤Ç‡≤§ ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≥Å. ‡≤à ‡≤™‡≥ç‡≤∞‡≤Ø‡≥ã‡≤ó‡≤∂‡≤æ‡≤≤‡≥Ü ‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß‡≤æ‡≤Ç‡≤§-‡≤™‡≥ç‡≤∞‡≤Æ‡≤æ‡≤£ ‡≤Ö‡≤®‡≥Å‡≤∑‡≥ç‡≤†‡≤æ‡≤®‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤∏‡≥ç‡≤•‡≥Ü‡≤ó‡≤≥‡≤ø‡≤Ç‡≤¶ ‡≤µ‡≤ø‡≤≠‡≤ú‡≤ø‡≤∏‡≥Å‡≤µ ‡≤Ö‡≤ó‡≤§‡≥ç‡≤Ø ‡≤Ö‡≤≠‡≥ç‡≤Ø‡≤æ‡≤∏‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤í‡≤≥‡≤ó‡≥ä‡≤Ç‡≤°‡≤ø‡≤¶‡≥Ü, ‡≤Ö‡≤µ‡≥Å ‡≤µ‡≤ø‡≤∏‡≥ç‡≤§‡≤∞‡≤ø‡≤∏‡≤¨‡≤π‡≥Å‡≤¶‡≤æ‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥Å, ‡≤µ‡≤ø‡≤∂‡≥ç‡≤µ‡≤æ‡≤∏‡≤æ‡≤∞‡≥ç‡≤π‡≤µ‡≤æ‡≤ó‡≤ø ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤®‡≤ø‡≤∞‡≥ç‡≤µ‡≤π‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≤æ ‡≤Æ‡≤æ‡≤®‡≤¶‡≤Ç‡≤°‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤æ‡≤™‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤µ‡≥Ü.

‡≤à ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤Ö‡≤≠‡≥ç‡≤Ø‡≤æ‡≤∏‡≤ó‡≤≥‡≥Å ‡≤®‡≥à‡≤ú-‡≤ú‡≤ó‡≤§‡≥ç‡≤§‡≤ø‡≤® ‡≤®‡≤ø‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü‡≤ó‡≤≥‡≤ø‡≤Ç‡≤¶, ‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤Ø‡≤ø‡≤Ç‡≤¶ ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤é‡≤Ç‡≤ü‡≤∞‡≥ç‚Äå‡≤™‡≥ç‡≤∞‡≥à‡≤∏‡≥ç ‡≤Ö‡≤®‡≥Å‡≤∑‡≥ç‡≤†‡≤æ‡≤®‡≤ó‡≤≥‡≤ø‡≤Ç‡≤¶ ‡≤ï‡≤≤‡≤ø‡≤§ ‡≤™‡≤æ‡≤†‡≤ó‡≤≥‡≤ø‡≤Ç‡≤¶ ‡≤™‡≤°‡≥Ü‡≤¶‡≤ø‡≤µ‡≥Ü.

## ‡≤ï‡≤≤‡≤ø‡≤ï‡≥Ü‡≤Ø ‡≤â‡≤¶‡≥ç‡≤¶‡≥á‡≤∂‡≤ó‡≤≥‡≥Å

‡≤à ‡≤™‡≥ç‡≤∞‡≤Ø‡≥ã‡≤ó‡≤∂‡≤æ‡≤≤‡≥Ü‡≤Ø ‡≤Ö‡≤Ç‡≤§‡≥ç‡≤Ø‡≤ï‡≥ç‡≤ï‡≥Ü, ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤∏‡≤æ‡≤ß‡≥ç‡≤Ø‡≤µ‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü:

- **‡≤Ö‡≤®‡≥ç‡≤µ‡≤Ø‡≤ø‡≤∏‡≥Å** MCP ‡≤∏‡≤∞‡≥ç‡≤µ‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤°‡≥á‡≤ü‡≤æ‡≤¨‡≥á‡≤∏‡≥ç‚Äå‡≤ó‡≤≥ ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ï‡≥ç‡≤∑‡≤Æ‡≤§‡≥Ü ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å  
- **‡≤Ö‡≤®‡≥Å‡≤∑‡≥ç‡≤†‡≤æ‡≤®‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≥Å** ‡≤∏‡≤Æ‡≤ó‡≥ç‡≤∞ ‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≤æ ‡≤ï‡≤†‡≤ø‡≤£‡≥Ä‡≤ï‡≤∞‡≤£ ‡≤ï‡≥ç‡≤∞‡≤Æ‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å  
- **‡≤∞‡≤ö‡≤ø‡≤∏‡≥Å** ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≤æ ‡≤™‡≤∞‡≤ø‡≤∏‡≤∞‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü ‡≤µ‡≤ø‡≤∏‡≥ç‡≤§‡≤∞‡≤ø‡≤∏‡≤¨‡≤π‡≥Å‡≤¶‡≤æ‡≤¶ ‡≤µ‡≤æ‡≤∏‡≥ç‡≤§‡≥Å‡≤∂‡≤ø‡≤≤‡≥ç‡≤™ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å  
- **‡≤∏‡≥ç‡≤•‡≤æ‡≤™‡≤ø‡≤∏‡≥Å** ‡≤Æ‡≥á‡≤≤‡≥ç‡≤µ‡≤ø‡≤ö‡≤æ‡≤∞‡≤£‡≥Ü, ‡≤®‡≤ø‡≤∞‡≥ç‡≤µ‡≤π‡≤£‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤æ‡≤ö‡≤∞‡≤£‡≥Ü ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å  
- **‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤∏‡≥ç** ‡≤µ‡≥Ü‡≤ö‡≥ç‡≤ö‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ï‡≥ç‡≤∑‡≤Æ‡≤§‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤µ‡≤ø‡≤∂‡≥ç‡≤µ‡≤æ‡≤∏‡≤æ‡≤∞‡≥ç‡≤π‡≤§‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤æ‡≤™‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤æ  
- **‡≤π‡≤Ç‡≤ö‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≥Å** MCP ‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤™‡≤∞‡≤ø‡≤∏‡≤∞ ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤∏‡≥ç‡≤•‡≥Ü‡≤ó‡≥Ü

## üöÄ ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ï‡≥ç‡≤∑‡≤Æ‡≤§‡≥Ü ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç

### ‡≤°‡≥á‡≤ü‡≤æ‡≤¨‡≥á‡≤∏‡≥ç ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ï‡≥ç‡≤∑‡≤Æ‡≤§‡≥Ü

#### ‡≤∏‡≤Ç‡≤™‡≤∞‡≥ç‡≤ï ‡≤™‡≥Ç‡≤≤‡≥ç ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç

```python
# ‡≤∏‡≥Å‡≤ß‡≤æ‡≤∞‡≤ø‡≤§ ‡≤∏‡≤Ç‡≤™‡≤∞‡≥ç‡≤ï ‡≤™‡≥Ç‡≤≤‡≥ç ‡≤∏‡≤Ç‡≤∞‡≤ö‡≤®‡≥Ü
POOL_CONFIG = {
    # ‡≤ó‡≤æ‡≤§‡≥ç‡≤∞ ‡≤∏‡≤Ç‡≤∞‡≤ö‡≤®‡≥Ü
    "min_size": max(2, cpu_count()),           # ‡≤ï‡≤®‡≤ø‡≤∑‡≥ç‡≤† 2, CPU ‡≤Ö‡≤®‡≥Å‡≤∏‡≤æ‡≤∞ ‡≤™‡≥ç‡≤∞‡≤Æ‡≤æ‡≤£ ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≤ø‡≤∏‡≤ø
    "max_size": min(20, cpu_count() * 4),     # ‡≤Ø‡≥Å‡≤ï‡≥ç‡≤§‡≤ø‡≤Ø‡≥Å‡≤§ ‡≤ó‡≤∞‡≤ø‡≤∑‡≥ç‡≤† ‡≤Æ‡≤ø‡≤§‡≤ø
    
    # ‡≤∏‡≤Æ‡≤Ø ‡≤∏‡≤Ç‡≤∞‡≤ö‡≤®‡≥Ü
    "max_inactive_connection_lifetime": 300,   # 5 ‡≤®‡≤ø‡≤Æ‡≤ø‡≤∑‡≤ó‡≤≥‡≥Å
    "command_timeout": 30,                     # 30 ‡≤∏‡≥Ü‡≤ï‡≥Ü‡≤Ç‡≤°‡≥Å‡≤ó‡≤≥‡≥Å
    "max_queries": 50000,                      # ‡≤∏‡≤Ç‡≤™‡≤∞‡≥ç‡≤ï‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤§‡≤ø‡≤∞‡≥Å‡≤ó‡≤ø‡≤∏‡≤ø
    
    # PostgreSQL ‡≤∏‡≥Ü‡≤ü‡≥ç‡≤ü‡≤ø‡≤Ç‡≤ó‡≥ç‚Äå‡≤ó‡≤≥‡≥Å
    "server_settings": {
        "application_name": "mcp-server-prod",
        "jit": "off",                          # ‡≤∏‡≤Æ‡≥ç‡≤Æ‡≤ø‡≤≤‡≤®‡≤ï‡≥ç‡≤ï‡≤æ‡≤ó‡≤ø ‡≤®‡≤ø‡≤∑‡≥ç‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤ø
        "work_mem": "8MB",                     # ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü ‡≤Ö‡≤®‡≥Å‡≤ï‡≥Ç‡≤≤‡≤ï‡≤∞‡≤µ‡≤æ‡≤ó‡≤ø ‡≤∏‡≥Å‡≤ß‡≤æ‡≤∞‡≤ø‡≤∏‡≤ø
        "shared_preload_libraries": "pg_stat_statements",
        "log_statement": "mod",                # ‡≤¨‡≤¶‡≤≤‡≤æ‡≤µ‡≤£‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤Æ‡≤æ‡≤§‡≥ç‡≤∞ ‡≤≤‡≤æ‡≤ó‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø
        "log_min_duration_statement": "1s",   # ‡≤®‡≤ø‡≤ß‡≤æ‡≤®‡≤µ‡≤æ‡≤¶ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤≤‡≤æ‡≤ó‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø
    }
}
```

#### ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤ó‡≤≥‡≥Å

```python
class QueryOptimizer:
    """Database query optimization utilities."""
    
    def __init__(self):
        self.query_cache = {}
        self.slow_query_threshold = 1.0  # ‡≤∏‡≥Ü‡≤ï‡≥Ü‡≤Ç‡≤°‡≥Å‡≤ó‡≤≥‡≥Å
        
    async def execute_optimized_query(
        self, 
        query: str, 
        params: tuple = None,
        cache_key: str = None,
        cache_ttl: int = 300
    ):
        """Execute query with optimization and caching."""
        
        # ‡≤Æ‡≥ä‡≤¶‡≤≤‡≥Å ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≥Ü ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø
        if cache_key and cache_key in self.query_cache:
            cache_entry = self.query_cache[cache_key]
            if time.time() - cache_entry['timestamp'] < cache_ttl:
                return cache_entry['result']
        
        # ‡≤Æ‡≥á‡≤≤‡≥ç‡≤µ‡≤ø‡≤ö‡≤æ‡≤∞‡≤£‡≥Ü‡≤Ø‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ó‡≤§‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤ø
        start_time = time.time()
        
        try:
            async with db_provider.get_connection() as conn:
                # ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ó‡≤§‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≥Å‡≤µ‡≤ø‡≤ï‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≥Å‡≤ß‡≤æ‡≤∞‡≤ø‡≤∏‡≤ø
                await conn.execute("SET enable_seqscan = off")  # ‡≤∏‡≥Ç‡≤ö‡≥ç‡≤Ø‡≤Ç‡≤ï‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤Ü‡≤¶‡≥ç‡≤Ø‡≤§‡≥Ü ‡≤®‡≥Ä‡≤°‡≤ø
                await conn.execute("SET work_mem = '16MB'")     # ‡≤à ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≥Å ‡≤Æ‡≥Ü‡≤Æ‡≥ä‡≤∞‡≤ø
                
                result = await conn.fetch(query, *params if params else ())
                
                duration = time.time() - start_time
                
                # ‡≤®‡≤ø‡≤ß‡≤æ‡≤®‡≤µ‡≤æ‡≤¶ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤≤‡≤æ‡≤ó‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø
                if duration > self.slow_query_threshold:
                    logger.warning(f"Slow query detected: {duration:.2f}s", extra={
                        "query": query[:200],
                        "duration": duration,
                        "params_count": len(params) if params else 0
                    })
                
                # ‡≤Ø‡≤∂‡≤∏‡≥ç‡≤µ‡≤ø ‡≤´‡≤≤‡≤ø‡≤§‡≤æ‡≤Ç‡≤∂‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≥Ü ‡≤Æ‡≤æ‡≤°‡≤ø
                if cache_key and len(result) < 1000:  # ‡≤¶‡≥ä‡≤°‡≥ç‡≤° ‡≤´‡≤≤‡≤ø‡≤§‡≤æ‡≤Ç‡≤∂‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≥Ü ‡≤Æ‡≤æ‡≤°‡≤¨‡≥á‡≤°‡≤ø
                    self.query_cache[cache_key] = {
                        'result': result,
                        'timestamp': time.time()
                    }
                
                return result
                
        except Exception as e:
            logger.error(f"Query optimization failed: {e}")
            raise

# ‡≤∏‡≥Ç‡≤ö‡≥ç‡≤Ø‡≤Ç‡≤ï ‡≤∂‡≤ø‡≤´‡≤æ‡≤∞‡≤∏‡≥Å‡≤ó‡≤≥‡≥Å
RECOMMENDED_INDEXES = [
    # ‡≤ï‡≥ã‡≤∞‡≥ç ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤π‡≤æ‡≤∞ ‡≤∏‡≥Ç‡≤ö‡≥ç‡≤Ø‡≤Ç‡≤ï‡≤ó‡≤≥‡≥Å
    "CREATE INDEX CONCURRENTLY idx_orders_store_date ON retail.orders (store_id, order_date DESC);",
    "CREATE INDEX CONCURRENTLY idx_order_items_product ON retail.order_items (product_id);",
    "CREATE INDEX CONCURRENTLY idx_customers_store_email ON retail.customers (store_id, email);",
    
    # ‡≤µ‡≤ø‡≤∂‡≥ç‡≤≤‡≥á‡≤∑‡≤£‡≤æ ‡≤∏‡≥Ç‡≤ö‡≥ç‡≤Ø‡≤Ç‡≤ï‡≤ó‡≤≥‡≥Å
    "CREATE INDEX CONCURRENTLY idx_orders_date_amount ON retail.orders (order_date, total_amount);",
    "CREATE INDEX CONCURRENTLY idx_products_category_price ON retail.products (category_id, unit_price);",
    
    # ‡≤µ‡≥Ü‡≤ï‡≥ç‡≤ü‡≤∞‡≥ç ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤æ‡≤ü ‡≤∏‡≥Å‡≤ß‡≤æ‡≤∞‡≤£‡≥Ü
    "CREATE INDEX CONCURRENTLY idx_embeddings_vector ON retail.product_description_embeddings USING ivfflat (description_embedding vector_cosine_ops) WITH (lists = 100);",
]
```

### ‡≤Ö‡≤™‡≥ç‡≤≤‡≤ø‡≤ï‡≥á‡≤∂‡≤®‡≥ç ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ï‡≥ç‡≤∑‡≤Æ‡≤§‡≥Ü

#### ‡≤Ö‡≤∏‡≤ø‡≤Ç‡≤ï‡≥ç ‡≤™‡≥ç‡≤∞‡≥ã‡≤ó‡≥ç‡≤∞‡≤æ‡≤Æ‡≤ø‡≤Ç‡≤ó‡≥ç ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤Ö‡≤≠‡≥ç‡≤Ø‡≤æ‡≤∏‡≤ó‡≤≥‡≥Å

```python
import asyncio
from asyncio import Semaphore
from typing import List, Any

class AsyncOptimizer:
    """Async operation optimization patterns."""
    
    def __init__(self, max_concurrent: int = 10):
        self.semaphore = Semaphore(max_concurrent)
        self.circuit_breaker = CircuitBreaker()
    
    async def batch_process(
        self, 
        items: List[Any], 
        process_func: callable,
        batch_size: int = 100
    ):
        """Process items in optimized batches."""
        
        async def process_batch(batch):
            async with self.semaphore:
                return await asyncio.gather(
                    *[process_func(item) for item in batch],
                    return_exceptions=True
                )
        
        # ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤∏‡≥ç‡≤•‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤§‡≤ø‡≤≠‡≤æ‡≤∞‡≤µ‡≤æ‡≤ó‡≤¶‡≤Ç‡≤§‡≥Ü ‡≤¨‡≥ç‡≤Ø‡≤æ‡≤ö‡≥ç‚Äå‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü ‡≤Æ‡≤æ‡≤°‡≤ø
        results = []
        for i in range(0, len(items), batch_size):
            batch = items[i:i + batch_size]
            batch_results = await process_batch(batch)
            results.extend(batch_results)
            
            # ‡≤∏‡≤Ç‡≤™‡≤®‡≥ç‡≤Æ‡≥Ç‡≤≤ ‡≤¶‡≥Å‡≤∞‡•Å‡§™‡≤Ø‡≥ã‡≤ó‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤§‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤¨‡≥ç‡≤Ø‡≤æ‡≤ö‡≥ç‚Äå‡≤ó‡≤≥ ‡≤®‡≤°‡≥Å‡≤µ‡≥Ü ‡≤∏‡≤£‡≥ç‡≤£ ‡≤µ‡≤ø‡≤≥‡≤Ç‡≤¨
            if i + batch_size < len(items):
                await asyncio.sleep(0.1)
        
        return results
    
    @circuit_breaker_decorator
    async def resilient_operation(self, operation: callable, *args, **kwargs):
        """Execute operation with circuit breaker protection."""
        return await operation(*args, **kwargs)

# ‡≤∏‡≤∞‡≥ç‡≤ï‡≥ç‡≤Ø‡≥Ç‡≤ü‡≥ç ‡≤¨‡≥ç‡≤∞‡≥á‡≤ï‡≤∞‡≥ç ‡≤Ö‡≤®‡≥Å‡≤∑‡≥ç‡≤†‡≤æ‡≤®
class CircuitBreaker:
    """Circuit breaker for external service calls."""
    
    def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "CLOSED"  # ‡≤Æ‡≥Å‡≤ö‡≥ç‡≤ö‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü, ‡≤§‡≥Ü‡≤∞‡≥Ü‡≤Ø‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü, ‡≤Ö‡≤∞‡≥ç‡≤ß ‡≤§‡≥Ü‡≤∞‡≥Ü‡≤Ø‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü
    
    async def call(self, func, *args, **kwargs):
        """Execute function with circuit breaker protection."""
        
        if self.state == "OPEN":
            if time.time() - self.last_failure_time > self.recovery_timeout:
                self.state = "HALF_OPEN"
            else:
                raise Exception("Circuit breaker is OPEN")
        
        try:
            result = await func(*args, **kwargs)
            
            # ‡≤Ø‡≤∂‡≤∏‡≥ç‡≤∏‡≤ø‡≤® ‡≤Æ‡≥á‡≤≤‡≥Ü ‡≤Æ‡≤∞‡≥Å‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤∏‡≤ø
            if self.state == "HALF_OPEN":
                self.state = "CLOSED"
                self.failure_count = 0
            
            return result
            
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()
            
            if self.failure_count >= self.failure_threshold:
                self.state = "OPEN"
            
            raise
```

### ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≤ø‡≤Ç‡≤ó‡≥ç ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å

```python
import redis
import pickle
from typing import Union, Optional

class SmartCache:
    """Multi-level caching system."""
    
    def __init__(self, redis_url: Optional[str] = None):
        self.memory_cache = {}
        self.redis_client = redis.Redis.from_url(redis_url) if redis_url else None
        self.max_memory_items = 1000
    
    async def get(self, key: str) -> Optional[Any]:
        """Get from cache with fallback levels."""
        
        # ‡≤Æ‡≤ü‡≥ç‡≤ü 1: ‡≤Æ‡≥Ü‡≤Æ‡≥ä‡≤∞‡≤ø ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≥Ü
        if key in self.memory_cache:
            return self.memory_cache[key]['value']
        
        # ‡≤Æ‡≤ü‡≥ç‡≤ü 2: ‡≤∞‡≥Ü‡≤°‡≤ø‡≤∏‡≥ç ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≥Ü
        if self.redis_client:
            try:
                cached_data = self.redis_client.get(key)
                if cached_data:
                    value = pickle.loads(cached_data)
                    
                    # ‡≤Æ‡≥Ü‡≤Æ‡≥ä‡≤∞‡≤ø ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≥Ü‡≤ó‡≥Ü ‡≤â‡≤§‡≥ç‡≤§‡≥á‡≤ú‡≤® ‡≤®‡≥Ä‡≤°‡≤ø
                    self._set_memory_cache(key, value)
                    return value
            except Exception as e:
                logger.warning(f"Redis cache error: {e}")
        
        return None
    
    async def set(
        self, 
        key: str, 
        value: Any, 
        ttl: int = 300,
        cache_level: str = "both"
    ):
        """Set cache value at specified levels."""
        
        if cache_level in ["memory", "both"]:
            self._set_memory_cache(key, value, ttl)
        
        if cache_level in ["redis", "both"] and self.redis_client:
            try:
                self.redis_client.setex(
                    key, 
                    ttl, 
                    pickle.dumps(value)
                )
            except Exception as e:
                logger.warning(f"Redis set error: {e}")
    
    def _set_memory_cache(self, key: str, value: Any, ttl: int = 300):
        """Set value in memory cache with LRU eviction."""
        
        # LRU ‡≤§‡≥Ü‡≤∞‡≤µ‡≥Å‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≥Å‡≤µ‡≤ø‡≤ï‡≥Ü ‡≤Ö‡≤®‡≥Å‡≤∑‡≥ç‡≤†‡≤æ‡≤®‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤ø
        if len(self.memory_cache) >= self.max_memory_items:
            oldest_key = min(
                self.memory_cache.keys(),
                key=lambda k: self.memory_cache[k]['timestamp']
            )
            del self.memory_cache[oldest_key]
        
        self.memory_cache[key] = {
            'value': value,
            'timestamp': time.time(),
            'ttl': ttl
        }

# ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≥Ü ‡≤ï‡≥Ä ‡≤ú‡≤®‡≤∞‡≥á‡≤∂‡≤®‡≥ç
def generate_cache_key(query: str, user_context: str, params: dict = None) -> str:
    """Generate consistent cache keys."""
    key_components = [
        query.strip().lower(),
        user_context,
        json.dumps(params, sort_keys=True) if params else ""
    ]
    
    key_string = "|".join(key_components)
    return hashlib.sha256(key_string.encode()).hexdigest()
```

## üîí ‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≤æ ‡≤ï‡≤†‡≤ø‡≤£‡≥Ä‡≤ï‡≤∞‡≤£

### ‡≤™‡≥ç‡≤∞‡≤æ‡≤Æ‡≤æ‡≤£‡≥Ä‡≤ï‡≤∞‡≤£ ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤™‡≥ç‡≤∞‡≤æ‡≤ß‡≤ø‡≤ï‡≤æ‡≤∞

```python
from azure.identity import DefaultAzureCredential, ClientSecretCredential
from azure.keyvault.secrets import SecretClient
import jwt
from typing import Dict, List

class SecurityManager:
    """Comprehensive security management."""
    
    def __init__(self):
        self.key_vault_client = self._setup_key_vault()
        self.token_blacklist = set()
        
    def _setup_key_vault(self) -> SecretClient:
        """Initialize Azure Key Vault client."""
        credential = DefaultAzureCredential()
        vault_url = os.getenv("AZURE_KEY_VAULT_URL")
        
        if vault_url:
            return SecretClient(vault_url=vault_url, credential=credential)
        return None
    
    async def validate_request(self, request_headers: Dict[str, str]) -> Dict[str, Any]:
        """Comprehensive request validation."""
        
        # ‡≤™‡≥ç‡≤∞‡≤æ‡≤Æ‡≤æ‡≤£‡≥Ä‡≤ï‡≤∞‡≤£‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥ä‡≤∞‡≤§‡≥Ü‡≤ó‡≥Ü‡≤Ø‡≤ø‡≤∞‡≤ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø
        auth_token = request_headers.get("authorization", "").replace("Bearer ", "")
        if not auth_token:
            raise AuthenticationError("Missing authentication token")
        
        # ‡≤ü‡≥ã‡≤ï‡≤®‡≥ç ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø
        user_context = await self._validate_token(auth_token)
        
        # ‡≤¶‡≤∞ ‡≤Æ‡≤ø‡≤§‡≤ø ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø
        await self._check_rate_limit(user_context["user_id"])
        
        # RLS ‡≤∏‡≤Ç‡≤¶‡≤∞‡≥ç‡≤≠‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø
        rls_user_id = request_headers.get("x-rls-user-id")
        if not self._validate_rls_access(user_context, rls_user_id):
            raise AuthorizationError("Invalid RLS context for user")
        
        return {
            "user_id": user_context["user_id"],
            "roles": user_context["roles"],
            "rls_user_id": rls_user_id,
            "permissions": user_context["permissions"]
        }
    
    async def _validate_token(self, token: str) -> Dict[str, Any]:
        """Validate JWT token."""
        
        if token in self.token_blacklist:
            raise AuthenticationError("Token has been revoked")
        
        try:
            # ‡≤ï‡≥Ä ‡≤µ‡≤æ‡≤≤‡≥ç‡≤ü‡≥ç ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≥Ü ‡≤®‡≤ø‡≤Ç‡≤¶ ‡≤∏‡≤æ‡≤∞‡≥ç‡≤µ‡≤ú‡≤®‡≤ø‡≤ï ‡≤ï‡≥Ä ‡≤™‡≤°‡≥Ü‡≤Ø‡≤ø‡≤∞‡≤ø
            public_key = await self._get_public_key()
            
            # ‡≤ü‡≥ã‡≤ï‡≤®‡≥ç ‡≤°‡≤ø‡≤ï‡≥ã‡≤°‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø
            payload = jwt.decode(
                token, 
                public_key, 
                algorithms=["RS256"],
                audience="mcp-server",
                issuer="zava-auth"
            )
            
            return {
                "user_id": payload["sub"],
                "roles": payload.get("roles", []),
                "permissions": payload.get("permissions", []),
                "expires_at": payload["exp"]
            }
            
        except jwt.InvalidTokenError as e:
            raise AuthenticationError(f"Invalid token: {e}")
    
    def _validate_rls_access(self, user_context: Dict, rls_user_id: str) -> bool:
        """Validate RLS context access."""
        
        # ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç ‡≤Ü‡≤°‡≥ç‡≤Æ‡≤ø‡≤®‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤∏‡≤Ç‡≤¶‡≤∞‡≥ç‡≤≠‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≤µ‡≥á‡≤∂‡≤ø‡≤∏‡≤¨‡≤π‡≥Å‡≤¶‡≥Å
        if "super_admin" in user_context["roles"]:
            return True
        
        # ‡≤∏‡≥ç‡≤ü‡≥ã‡≤∞‡≥ç ‡≤Æ‡≥ç‡≤Ø‡≤æ‡≤®‡≥á‡≤ú‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤§‡≤Æ‡≥ç‡≤Æ‡≤¶‡≥á ‡≤∏‡≥ç‡≤ü‡≥ã‡≤∞‡≥ç ‡≤Ö‡≤®‡≥ç‡≤®‡≥Å ‡≤Æ‡≤æ‡≤§‡≥ç‡≤∞ ‡≤™‡≥ç‡≤∞‡≤µ‡≥á‡≤∂‡≤ø‡≤∏‡≤¨‡≤π‡≥Å‡≤¶‡≥Å
        if "store_manager" in user_context["roles"]:
            allowed_stores = user_context.get("allowed_stores", [])
            return rls_user_id in allowed_stores
        
        # ‡≤™‡≥ç‡≤∞‡≤æ‡≤¶‡≥á‡≤∂‡≤ø‡≤ï ‡≤Æ‡≥ç‡≤Ø‡≤æ‡≤®‡≥á‡≤ú‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤π‡≤≤‡≤µ‡≤æ‡≤∞‡≥Å ‡≤∏‡≥ç‡≤ü‡≥ã‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≤µ‡≥á‡≤∂‡≤ø‡≤∏‡≤¨‡≤π‡≥Å‡≤¶‡≥Å
        if "regional_manager" in user_context["roles"]:
            allowed_regions = user_context.get("allowed_regions", [])
            return self._check_store_in_regions(rls_user_id, allowed_regions)
        
        return False

# ‡≤á‡≤®‡≥ç‚Äå‡≤™‡≥Å‡≤ü‡≥ç ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤®‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤∂‡≥Å‡≤¶‡≥ç‡≤ß‡≥Ä‡≤ï‡≤∞‡≤£
class InputValidator:
    """SQL injection prevention and input validation."""
    
    @staticmethod
    def validate_sql_query(query: str) -> bool:
        """Validate SQL query for safety."""
        
        # ‡≤®‡≤ø‡≤∑‡≤ø‡≤¶‡≥ç‡≤ß ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤ó‡≤≥‡≥Å
        forbidden_patterns = [
            r";\s*(DROP|DELETE|UPDATE|INSERT|ALTER|CREATE)\s+",
            r"--.*",
            r"/\*.*\*/",
            r"xp_cmdshell",
            r"sp_executesql",
            r"EXEC\s*\(",
        ]
        
        query_upper = query.upper()
        
        for pattern in forbidden_patterns:
            if re.search(pattern, query_upper, re.IGNORECASE):
                logger.warning(f"Blocked potentially dangerous query: {pattern}")
                return False
        
        # SELECT ‡≤π‡≥á‡≤≥‡≤ø‡≤ï‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤Æ‡≤æ‡≤§‡≥ç‡≤∞ ‡≤Ö‡≤®‡≥Å‡≤Æ‡≤§‡≤ø‡≤∏‡≤ø
        if not query_upper.strip().startswith("SELECT"):
            return False
        
        return True
    
    @staticmethod
    def sanitize_table_name(table_name: str) -> str:
        """Sanitize table name input."""
        
        # ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≤æ, ‡≤Ö‡≤Ç‡≤°‡≤∞‡≥ç‚Äå‡≤∏‡≥ç‡≤ï‡≥ã‡≤∞‡≥ç ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤°‡≤æ‡≤ü‡≥ç ‡≤Ö‡≤®‡≥ç‡≤®‡≥Å ‡≤Æ‡≤æ‡≤§‡≥ç‡≤∞ ‡≤Ö‡≤®‡≥Å‡≤Æ‡≤§‡≤ø‡≤∏‡≤ø
        if not re.match(r"^[a-zA-Z0-9_.]+$", table_name):
            raise ValueError("Invalid table name format")
        
        # ‡≤Ö‡≤®‡≥Å‡≤Æ‡≤§‡≤ø‡≤∏‡≤≤‡≤æ‡≤¶ ‡≤ü‡≥á‡≤¨‡≤≤‡≥ç‚Äå‡≤ó‡≤≥ ‡≤µ‡≤ø‡≤∞‡≥Å‡≤¶‡≥ç‡≤ß ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø
        if table_name not in VALID_TABLES:
            raise ValueError(f"Table {table_name} not allowed")
        
        return table_name
```

### ‡≤°‡≥á‡≤ü‡≤æ ‡≤∞‡≤ï‡≥ç‡≤∑‡≤£‡≥Ü

```python
from cryptography.fernet import Fernet
import hashlib

class DataProtection:
    """Data encryption and protection utilities."""
    
    def __init__(self):
        self.encryption_key = self._get_encryption_key()
        self.cipher_suite = Fernet(self.encryption_key)
    
    def _get_encryption_key(self) -> bytes:
        """Get encryption key from secure storage."""
        
        # ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø, ‡≤Ö‡≤ú‡≥Ç‡≤∞‡≥ç ‡≤ï‡≥Ä ‡≤µ‡≤æ‡≤≤‡≥ç‡≤ü‡≥ç‚Äå‡≤®‡≤ø‡≤Ç‡≤¶ ‡≤™‡≤°‡≥Ü‡≤Ø‡≤ø‡≤∞‡≤ø
        key_vault_secret = os.getenv("ENCRYPTION_KEY_SECRET_NAME")
        if key_vault_secret and self.key_vault_client:
            secret = self.key_vault_client.get_secret(key_vault_secret)
            return secret.value.encode()
        
        # ‡≤Ö‡≤≠‡≤ø‡≤µ‡≥É‡≤¶‡≥ç‡≤ß‡≤ø‡≤ó‡≤æ‡≤ó‡≤ø ‡≤¨‡≥ç‡≤Ø‡≤æ‡≤ï‡≤™‡≥ç (‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≥Ü‡≤ó‡≤æ‡≤ó‡≤ø ‡≤Ö‡≤≤‡≥ç‡≤≤!)
        dev_key = os.getenv("DEV_ENCRYPTION_KEY")
        if dev_key:
            return dev_key.encode()
        
        raise ValueError("No encryption key available")
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """Encrypt sensitive data."""
        return self.cipher_suite.encrypt(data.encode()).decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """Decrypt sensitive data."""
        return self.cipher_suite.decrypt(encrypted_data.encode()).decode()
    
    @staticmethod
    def hash_password(password: str, salt: str = None) -> tuple:
        """Hash password with salt."""
        if not salt:
            salt = os.urandom(32).hex()
        
        password_hash = hashlib.pbkdf2_hmac(
            'sha256',
            password.encode(),
            salt.encode(),
            100000  # ‡≤™‡≥Å‡≤®‡≤∞‡≤æ‡≤µ‡≥É‡≤§‡≥ç‡≤§‡≤ø‡≤ó‡≤≥‡≥Å
        ).hex()
        
        return password_hash, salt
    
    @staticmethod
    def mask_sensitive_logs(log_data: dict) -> dict:
        """Mask sensitive information in logs."""
        
        sensitive_fields = [
            'password', 'token', 'secret', 'key', 'authorization',
            'x-api-key', 'client_secret', 'connection_string'
        ]
        
        masked_data = log_data.copy()
        
        for field in sensitive_fields:
            if field in masked_data:
                value = str(masked_data[field])
                if len(value) > 4:
                    masked_data[field] = value[:2] + "*" * (len(value) - 4) + value[-2:]
                else:
                    masked_data[field] = "***"
        
        return masked_data
```

## üìä ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≤æ ‡≤®‡≤ø‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü ‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ó‡≤∏‡≥Ç‡≤ö‡≤ø‡≤ó‡≤≥‡≥Å

### ‡≤á‡≤®‡≥ç‚Äå‡≤´‡≥ç‡≤∞‡≤æ‡≤∏‡≥ç‡≤ü‡≥ç‡≤∞‡≤ï‡≥ç‡≤ö‡≤∞‡≥ç ‡≤Ö‡≤∏‡≥ç ‡≤ï‡≥ã‡≤°‡≥ç

```yaml
# azure-pipelines.yml
trigger:
  branches:
    include:
      - main
      - release/*

variables:
  - group: mcp-server-secrets
  - name: imageRepository
    value: 'zava-mcp-server'
  - name: containerRegistry
    value: 'zavamcpregistry.azurecr.io'

stages:
- stage: Build
  displayName: Build and Test
  jobs:
  - job: Build
    displayName: Build
    pool:
      vmImage: ubuntu-latest
    
    steps:
    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.11'
        displayName: 'Use Python 3.11'
    
    - script: |
        python -m pip install --upgrade pip
        pip install -r requirements.lock.txt
        pip install pytest pytest-cov
      displayName: 'Install dependencies'
    
    - script: |
        pytest tests/ --cov=mcp_server --cov-report=xml
      displayName: 'Run tests with coverage'
    
    - task: PublishCodeCoverageResults@1
      inputs:
        codeCoverageTool: Cobertura
        summaryFileLocation: 'coverage.xml'
    
    - task: Docker@2
      displayName: Build Docker image
      inputs:
        command: build
        repository: $(imageRepository)
        dockerfile: Dockerfile
        tags: |
          $(Build.BuildId)
          latest

- stage: Deploy
  displayName: Deploy to Production
  dependsOn: Build
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
  
  jobs:
  - deployment: DeployProduction
    displayName: Deploy to Production
    environment: 'production'
    pool:
      vmImage: ubuntu-latest
    
    strategy:
      runOnce:
        deploy:
          steps:
          - task: AzureContainerApps@1
            inputs:
              azureSubscription: $(azureServiceConnection)
              containerAppName: 'zava-mcp-server'
              resourceGroup: '$(resourceGroupName)'
              imageToDeploy: '$(containerRegistry)/$(imageRepository):$(Build.BuildId)'
```

### ‡≤ï‡≤Ç‡≤ü‡≥á‡≤®‡≤∞‡≥ç ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç

```dockerfile
# Multi-stage Dockerfile for production
FROM python:3.11-slim as builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Create virtual environment
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Copy requirements and install Python dependencies
COPY requirements.lock.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.lock.txt

# Production stage
FROM python:3.11-slim as production

# Create non-root user
RUN groupadd -r mcpserver && useradd -r -g mcpserver mcpserver

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Set working directory
WORKDIR /app

# Copy application code
COPY mcp_server/ ./mcp_server/
COPY --chown=mcpserver:mcpserver . .

# Set security configurations
RUN chmod -R 755 /app && \
    chown -R mcpserver:mcpserver /app

# Switch to non-root user
USER mcpserver

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Expose port
EXPOSE 8000

# Start application
CMD ["python", "-m", "mcp_server.sales_analysis"]
```

### ‡≤™‡≤∞‡≤ø‡≤∏‡≤∞ ‡≤∏‡≤Ç‡≤∞‡≤ö‡≤®‡≥Ü

```python
# ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≤æ ‡≤∏‡≤Ç‡≤∞‡≤ö‡≤®‡≤æ ‡≤®‡≤ø‡≤∞‡≥ç‡≤µ‡≤π‡≤£‡≥Ü
class ProductionConfig:
    """Production-specific configuration."""
    
    def __init__(self):
        self.validate_production_requirements()
        self.setup_logging()
        self.configure_security()
    
    def validate_production_requirements(self):
        """Validate all required production settings."""
        
        required_settings = [
            "AZURE_CLIENT_ID",
            "AZURE_CLIENT_SECRET", 
            "AZURE_TENANT_ID",
            "PROJECT_ENDPOINT",
            "AZURE_OPENAI_ENDPOINT",
            "POSTGRES_HOST",
            "POSTGRES_PASSWORD",
            "APPLICATIONINSIGHTS_CONNECTION_STRING"
        ]
        
        missing_settings = [
            setting for setting in required_settings 
            if not os.getenv(setting)
        ]
        
        if missing_settings:
            raise EnvironmentError(
                f"Missing required production settings: {missing_settings}"
            )
    
    def setup_logging(self):
        """Configure production logging."""
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.handlers.RotatingFileHandler(
                    '/var/log/mcp-server.log',
                    maxBytes=50*1024*1024,  # 50MB
                    backupCount=5
                )
            ]
        )
        
        # ‡≤Æ‡≥Ç‡≤∞‡≤®‡≥á ‡≤™‡≤ï‡≥ç‡≤∑‡≤¶ ‡≤≤‡≤æ‡≤ó‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤é‡≤ö‡≥ç‡≤ö‡≤∞‡≤ø‡≤ï‡≥Ü‡≤ó‡≥Ü ‡≤∏‡≥Ü‡≤ü‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø
        logging.getLogger('azure').setLevel(logging.WARNING)
        logging.getLogger('urllib3').setLevel(logging.WARNING)
    
    def configure_security(self):
        """Configure production security settings."""
        
        # ‡≤°‡≤ø‡≤¨‡≤ó‡≥ç ‡≤Æ‡≥ã‡≤°‡≥ç ‡≤®‡≤ø‡≤∑‡≥ç‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤ø
        os.environ['DEBUG'] = 'False'
        
        # ‡≤∏‡≥Å‡≤∞‡≤ï‡≥ç‡≤∑‡≤ø‡≤§ ‡≤π‡≥Ü‡≤°‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≥Ü‡≤ü‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø
        os.environ['SECURE_SSL_REDIRECT'] = 'True'
        os.environ['SECURE_HSTS_SECONDS'] = '31536000'
        os.environ['SECURE_CONTENT_TYPE_NOSNIFF'] = 'True'
        os.environ['SECURE_BROWSER_XSS_FILTER'] = 'True'
```

## üí∞ ‡≤µ‡≥Ü‡≤ö‡≥ç‡≤ö ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç

### ‡≤∏‡≤Ç‡≤™‡≤®‡≥ç‡≤Æ‡≥Ç‡≤≤ ‡≤®‡≤ø‡≤∞‡≥ç‡≤µ‡≤π‡≤£‡≥Ü

```python
class CostOptimizer:
    """Cost optimization strategies."""
    
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.auto_scaler = AutoScaler()
    
    async def optimize_database_connections(self):
        """Dynamically adjust connection pool based on load."""
        
        current_load = await self.metrics_collector.get_current_load()
        
        if current_load < 0.3:  # ‡≤ï‡≤°‡≤ø‡≤Æ‡≥Ü ‡≤≤‡≥ã‡≤°‡≥ç
            target_pool_size = max(2, int(current_load * 10))
        elif current_load < 0.7:  # ‡≤Æ‡≤ß‡≥ç‡≤Ø‡≤Æ ‡≤≤‡≥ã‡≤°‡≥ç
            target_pool_size = max(5, int(current_load * 15))
        else:  # ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≤ø‡≤® ‡≤≤‡≥ã‡≤°‡≥ç
            target_pool_size = min(20, int(current_load * 25))
        
        await db_provider.adjust_pool_size(target_pool_size)
        
        logger.info(f"Adjusted pool size to {target_pool_size} for load {current_load}")
    
    async def implement_smart_caching(self):
        """Implement intelligent caching to reduce compute costs."""
        
        # ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≥Ü ‡≤¶‡≥Å‡≤¨‡≤æ‡≤∞‡≤ø ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ó‡≤≥‡≥Å
        expensive_queries = await self.identify_expensive_queries()
        
        for query in expensive_queries:
            cache_key = self.generate_cache_key(query)
            ttl = self.calculate_optimal_ttl(query)
            
            await smart_cache.set(cache_key, None, ttl=ttl)
    
    def calculate_azure_costs(self) -> Dict[str, float]:
        """Calculate estimated Azure resource costs."""
        
        return {
            "container_apps": self.estimate_container_costs(),
            "postgresql": self.estimate_database_costs(),
            "openai": self.estimate_ai_costs(),
            "application_insights": self.estimate_monitoring_costs(),
            "storage": self.estimate_storage_costs()
        }

# ‡≤∏‡≥ç‡≤µ‡≤Ø‡≤Ç-‡≤∏‡≥ç‡≤ï‡≥á‡≤≤‡≤ø‡≤Ç‡≤ó‡≥ç ‡≤∏‡≤Ç‡≤∞‡≤ö‡≤®‡≥Ü
class AutoScaler:
    """Automatic scaling based on metrics."""
    
    async def scale_decision(self) -> str:
        """Determine scaling action based on metrics."""
        
        metrics = await self.collect_scaling_metrics()
        
        # ‡≤∏‡≤ø‡≤™‡≤ø‡≤Ø‡≥Å ‡≤Ü‡≤ß‡≤æ‡≤∞‡≤ø‡≤§ ‡≤∏‡≥ç‡≤ï‡≥á‡≤≤‡≤ø‡≤Ç‡≤ó‡≥ç
        if metrics['cpu_usage'] > 80:
            return "scale_up"
        elif metrics['cpu_usage'] < 20 and metrics['instance_count'] > 1:
            return "scale_down"
        
        # ‡≤Æ‡≥Ü‡≤Æ‡≥ä‡≤∞‡≤ø ‡≤Ü‡≤ß‡≤æ‡≤∞‡≤ø‡≤§ ‡≤∏‡≥ç‡≤ï‡≥á‡≤≤‡≤ø‡≤Ç‡≤ó‡≥ç
        if metrics['memory_usage'] > 85:
            return "scale_up"
        
        # ‡≤µ‡≤ø‡≤®‡≤Ç‡≤§‡≤ø ‡≤∏‡≤æ‡≤≤‡≥Å ‡≤∏‡≥ç‡≤ï‡≥á‡≤≤‡≤ø‡≤Ç‡≤ó‡≥ç
        if metrics['queue_length'] > 100:
            return "scale_up"
        elif metrics['queue_length'] < 10 and metrics['instance_count'] > 1:
            return "scale_down"
        
        return "no_action"
```

## üîß ‡≤®‡≤ø‡≤∞‡≥ç‡≤µ‡≤π‡≤£‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤æ‡≤ö‡≤∞‡≤£‡≥Ü

### ‡≤Ü‡≤∞‡≥ã‡≤ó‡≥ç‡≤Ø ‡≤Æ‡≥á‡≤≤‡≥ç‡≤µ‡≤ø‡≤ö‡≤æ‡≤∞‡≤£‡≥Ü

```python
class OperationalHealth:
    """Comprehensive operational health monitoring."""
    
    def __init__(self):
        self.alert_manager = AlertManager()
        self.health_checks = {}
        
    async def comprehensive_health_check(self) -> Dict[str, Any]:
        """Perform comprehensive system health check."""
        
        health_report = {
            "timestamp": datetime.utcnow().isoformat(),
            "overall_status": "healthy",
            "components": {}
        }
        
        # ‡≤°‡≥á‡≤ü‡≤æ‡≤¨‡≥á‡≤∏‡≥ç ‡≤Ü‡≤∞‡≥ã‡≤ó‡≥ç‡≤Ø
        db_health = await self.check_database_health()
        health_report["components"]["database"] = db_health
        
        # ‡≤¨‡≤æ‡≤π‡≥ç‡≤Ø ‡≤∏‡≥á‡≤µ‡≥Ü‡≤ó‡≤≥ ‡≤Ü‡≤∞‡≥ã‡≤ó‡≥ç‡≤Ø
        ai_health = await self.check_ai_service_health()
        health_report["components"]["ai_service"] = ai_health
        
        # ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤∏‡≥ç‡≤•‡≥Ü‡≤Ø ‡≤∏‡≤Ç‡≤™‡≤®‡≥ç‡≤Æ‡≥Ç‡≤≤‡≤ó‡≤≥‡≥Å
        system_health = await self.check_system_resources()
        health_report["components"]["system"] = system_health
        
        # ‡≤Ö‡≤™‡≥ç‡≤≤‡≤ø‡≤ï‡≥á‡≤∂‡≤®‡≥ç ‡≤Æ‡≥Ü‡≤ü‡≥ç‡≤∞‡≤ø‡≤ï‡≥ç‡≤∏‡≥ç
        app_health = await self.check_application_health()
        health_report["components"]["application"] = app_health
        
        # ‡≤í‡≤ü‡≥ç‡≤ü‡≥Å ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≤ø‡≤∞‡≥ç‡≤ß‡≤∞‡≤ø‡≤∏‡≤ø
        failed_components = [
            name for name, status in health_report["components"].items()
            if status.get("status") != "healthy"
        ]
        
        if failed_components:
            health_report["overall_status"] = "unhealthy"
            health_report["failed_components"] = failed_components
            
            # ‡≤é‡≤ö‡≥ç‡≤ö‡≤∞‡≤ø‡≤ï‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≥á‡≤∞‡≥á‡≤™‡≤ø‡≤∏‡≤ø
            await self.alert_manager.send_alert(
                severity="high",
                message=f"Health check failed for: {failed_components}",
                details=health_report
            )
        
        return health_report
    
    async def check_database_health(self) -> Dict[str, Any]:
        """Check database connectivity and performance."""
        
        try:
            start_time = time.time()
            
            async with db_provider.get_connection() as conn:
                # ‡≤Æ‡≥Ç‡≤≤ ‡≤∏‡≤Ç‡≤™‡≤∞‡≥ç‡≤ï‡≤§‡≥Ü
                await conn.fetchval("SELECT 1")
                
                # ‡≤®‡≤ø‡≤ß‡≤æ‡≤®‡≤µ‡≤æ‡≤¶ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø
                slow_queries = await conn.fetch("""
                    SELECT query, mean_exec_time, calls 
                    FROM pg_stat_statements 
                    WHERE mean_exec_time > 1000 
                    ORDER BY mean_exec_time DESC 
                    LIMIT 5
                """)
                
                # ‡≤∏‡≤Ç‡≤™‡≤∞‡≥ç‡≤ï ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø
                connection_count = await conn.fetchval("""
                    SELECT count(*) FROM pg_stat_activity 
                    WHERE state = 'active'
                """)
                
                response_time = time.time() - start_time
                
                return {
                    "status": "healthy",
                    "response_time_ms": response_time * 1000,
                    "active_connections": connection_count,
                    "slow_queries_count": len(slow_queries),
                    "pool_size": db_provider.connection_pool.get_size()
                }
                
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "last_check": datetime.utcnow().isoformat()
            }

# ‡≤∏‡≥ç‡≤µ‡≤Ø‡≤Ç‡≤ö‡≤æ‡≤≤‡≤ø‡≤§ ‡≤¨‡≥ç‡≤Ø‡≤æ‡≤ï‡≤™‡≥ç ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤™‡≥Å‡≤®‡≤∞‡≥Å‡≤¶‡≥ç‡≤ß‡≤æ‡≤∞
class BackupManager:
    """Database backup and recovery management."""
    
    async def create_backup(self, backup_type: str = "full") -> str:
        """Create database backup."""
        
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        backup_name = f"zava_backup_{backup_type}_{timestamp}"
        
        if backup_type == "full":
            await self.create_full_backup(backup_name)
        elif backup_type == "incremental":
            await self.create_incremental_backup(backup_name)
        
        # ‡≤Ö‡≤ú‡≥Ç‡≤∞‡≥ç ‡≤¨‡≥ç‡≤≤‡≤æ‡≤¨‡≥ç ‡≤∏‡≥ç‡≤ü‡≥ã‡≤∞‡≥á‡≤ú‡≥ç‚Äå‡≤ó‡≥Ü ‡≤Ö‡≤™‡≥ç‡≤≤‡≥ã‡≤°‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø
        await self.upload_backup_to_azure(backup_name)
        
        return backup_name
    
    async def schedule_automated_backups(self):
        """Schedule regular automated backups."""
        
        # ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤¶‡≤ø‡≤® 2 AM ‡≤Ø‡≥Å‡≤ü‡≤ø‡≤∏‡≤ø ‡≤®‡≤≤‡≥ç‡≤≤‡≤ø ‡≤∏‡≤Ç‡≤™‡≥Ç‡≤∞‡≥ç‡≤£ ‡≤¨‡≥ç‡≤Ø‡≤æ‡≤ï‡≤™‡≥ç
        schedule.every().day.at("02:00").do(
            lambda: asyncio.create_task(self.create_backup("full"))
        )
        
        # ‡≤™‡≥ç‡≤∞‡≤§‡≤ø ‡≤ó‡≤Ç‡≤ü‡≥Ü‡≤ó‡≥Ü ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≥Å‡≤µ‡≤∞‡≤ø ‡≤¨‡≥ç‡≤Ø‡≤æ‡≤ï‡≤™‡≥ç
        schedule.every().hour.do(
            lambda: asyncio.create_task(self.create_backup("incremental"))
        )
```

## üåç ‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø ‡≤ï‡≥ä‡≤°‡≥Å‡≤ó‡≥Ü‡≤ó‡≤≥‡≥Å

### ‡≤ì‡≤™‡≤®‡≥ç ‡≤∏‡≥ã‡≤∞‡≥ç‡≤∏‡≥ç ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤Ö‡≤≠‡≥ç‡≤Ø‡≤æ‡≤∏‡≤ó‡≤≥‡≥Å

```markdown
# Contributing to MCP Database Integration

## Development Guidelines

### Code Quality Standards
- Follow PEP 8 for Python code style
- Maintain test coverage above 90%
- Use type hints throughout the codebase
- Write comprehensive docstrings

### Testing Requirements
- Unit tests for all new functionality
- Integration tests for database operations
- Performance benchmarks for critical paths
- Security tests for authentication/authorization

### Documentation Standards
- Update README.md for any new features
- Add inline code documentation
- Create examples for new tools or patterns
- Maintain API documentation

## Security Considerations

### Reporting Security Issues
- Report security vulnerabilities privately
- Use encrypted communication channels
- Provide detailed reproduction steps
- Include potential impact assessment

### Security Review Process
- All PRs undergo security review
- Static analysis tools required to pass
- Dependency vulnerability scanning
- Manual security testing for critical changes
```

### ‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø ‡≤§‡≥ä‡≤°‡≤ó‡≤ø‡≤∏‡≤ø‡≤ï‡≥Ü‡≥Ç‡≤≥‡≥ç‡≤≥‡≥Å‡≤µ‡≤ø‡≤ï‡≥Ü

```python
class CommunityContributor:
    """Tools for community engagement and contribution."""
    
    @staticmethod
    def generate_contribution_guide():
        """Generate personalized contribution guide."""
        
        return {
            "getting_started": {
                "setup": "Follow setup guide in Lab 03",
                "first_contribution": "Start with documentation improvements",
                "testing": "Run full test suite before submitting PR"
            },
            
            "contribution_areas": {
                "documentation": "Improve learning labs and examples",
                "testing": "Add test cases and improve coverage",
                "features": "Implement new MCP tools and capabilities",
                "performance": "Optimize queries and caching",
                "security": "Enhance security measures and validation"
            },
            
            "community_resources": {
                "discord": "https://discord.com/invite/ByRwuEEgH4",
                "discussions": "GitHub Discussions for Q&A",
                "issues": "GitHub Issues for bug reports",
                "examples": "Share your implementation examples"
            }
        }
    
    @staticmethod
    def validate_contribution(pr_data: Dict) -> Dict[str, bool]:
        """Validate contribution meets standards."""
        
        return {
            "has_tests": "test" in pr_data.get("files_changed", []),
            "has_documentation": "README" in str(pr_data.get("files_changed", [])),
            "follows_conventions": True,  # ‡≤®‡≤ø‡≤ú‡≤µ‡≤æ‡≤¶ ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤®‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤ú‡≤æ‡≤∞‡≤ø‡≤ó‡≥Ü ‡≤§‡≤∞‡≥Å‡≤µ‡≥Å‡≤¶‡≤æ‡≤ó‡≤ø‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü
            "security_reviewed": pr_data.get("security_review", False),
            "performance_tested": pr_data.get("benchmark_results", False)
        }
```

## üéØ ‡≤™‡≥ç‡≤∞‡≤Æ‡≥Å‡≤ñ ‡≤™‡≤æ‡≤†‡≤ó‡≤≥‡≥Å

‡≤à ‡≤∏‡≤Æ‡≤ó‡≥ç‡≤∞ ‡≤ï‡≤≤‡≤ø‡≤ï‡≥Ü‡≤Ø ‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ó‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥Ç‡≤∞‡≥ç‡≤£‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤ø‡≤¶ ‡≤®‡≤Ç‡≤§‡≤∞, ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤™‡≤∞‡≤ø‡≤£‡≤§‡≤ø ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤∞‡≤¨‡≥á‡≤ï‡≥Å:

‚úÖ **‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ï‡≥ç‡≤∑‡≤Æ‡≤§‡≥Ü ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç**: ‡≤°‡≥á‡≤ü‡≤æ‡≤¨‡≥á‡≤∏‡≥ç ‡≤ü‡≥ç‡≤Ø‡≥Ç‡≤®‡≤ø‡≤Ç‡≤ó‡≥ç, ‡≤Ö‡≤∏‡≤ø‡≤Ç‡≤ï‡≥ç ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤ó‡≤≥‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤∂‡≤ø‡≤Ç‡≤ó‡≥ç ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å  
‚úÖ **‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≤æ ‡≤ï‡≤†‡≤ø‡≤£‡≥Ä‡≤ï‡≤∞‡≤£**: ‡≤™‡≥ç‡≤∞‡≤æ‡≤Æ‡≤æ‡≤£‡≥Ä‡≤ï‡≤∞‡≤£, ‡≤™‡≥ç‡≤∞‡≤æ‡≤ß‡≤ø‡≤ï‡≤æ‡≤∞ ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤°‡≥á‡≤ü‡≤æ ‡≤∞‡≤ï‡≥ç‡≤∑‡≤£‡≥Ü  
‚úÖ **‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≤æ ‡≤®‡≤ø‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü**: ‡≤á‡≤®‡≥ç‚Äå‡≤´‡≥ç‡≤∞‡≤æ‡≤∏‡≥ç‡≤ü‡≥ç‡≤∞‡≤ï‡≥ç‡≤ö‡≤∞‡≥ç ‡≤Ö‡≤∏‡≥ç ‡≤ï‡≥ã‡≤°‡≥ç ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤ï‡≤Ç‡≤ü‡≥á‡≤®‡≤∞‡≥ç ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç  
‚úÖ **‡≤µ‡≥Ü‡≤ö‡≥ç‡≤ö ‡≤®‡≤ø‡≤∞‡≥ç‡≤µ‡≤π‡≤£‡≥Ü**: ‡≤∏‡≤Ç‡≤™‡≤®‡≥ç‡≤Æ‡≥Ç‡≤≤ ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤¨‡≥Å‡≤¶‡≥ç‡≤ß‡≤ø‡≤µ‡≤Ç‡≤§‡≤ø‡≤ï‡≥Ü‡≤Ø ‡≤µ‡≤ø‡≤∏‡≥ç‡≤§‡≤∞‡≤£‡≥Ü  
‚úÖ **‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤æ‡≤ö‡≤∞‡≤£‡≥Ü ‡≤∂‡≥ç‡≤∞‡≥á‡≤∑‡≥ç‡≤†‡≤§‡≥Ü**: ‡≤Æ‡≥á‡≤≤‡≥ç‡≤µ‡≤ø‡≤ö‡≤æ‡≤∞‡≤£‡≥Ü, ‡≤®‡≤ø‡≤∞‡≥ç‡≤µ‡≤π‡≤£‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤∏‡≥ç‡≤µ‡≤Ø‡≤Ç‡≤ö‡≤æ‡≤≤‡≤®‡≥Ü  
‚úÖ **‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø ‡≤§‡≥ä‡≤°‡≤ó‡≤ø‡≤∏‡≤ø‡≤ï‡≥Ü‡≥Ç‡≤≥‡≥ç‡≤≥‡≥Å‡≤µ‡≤ø‡≤ï‡≥Ü**: MCP ‡≤™‡≤∞‡≤ø‡≤∏‡≤∞ ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤∏‡≥ç‡≤•‡≥Ü‡≤ó‡≥Ü ‡≤ï‡≥ä‡≤°‡≥Å‡≤ó‡≥Ü ‡≤®‡≥Ä‡≤°‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å  

## üèÜ ‡≤™‡≥ç‡≤∞‡≤Æ‡≤æ‡≤£‡≤™‡≤§‡≥ç‡≤∞ ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≤ø‡≤® ‡≤π‡≤Ç‡≤§‡≤ó‡≤≥‡≥Å

### ‡≤™‡≥ç‡≤∞‡≤æ‡≤Ø‡≥ã‡≤ó‡≤ø‡≤ï ‡≤Æ‡≥å‡≤≤‡≥ç‡≤Ø‡≤Æ‡≤æ‡≤™‡≤®

‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤™‡≤∞‡≤ø‡≤£‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≤¶‡≤∞‡≥ç‡≤∂‡≤ø‡≤∏‡≤≤‡≥Å ‡≤à ‡≤Ö‡≤Ç‡≤§‡≤ø‡≤Æ ‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥Ç‡≤∞‡≥ç‡≤£‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤ø:

**‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß MCP ‡≤∏‡≤∞‡≥ç‡≤µ‡≤∞‡≥ç ‡≤®‡≤ø‡≤∞‡≥ç‡≤Æ‡≤ø‡≤∏‡≤ø** ‡≤á‡≤¶‡≤∞‡≤≤‡≥ç‡≤≤‡≤ø ‡≤∏‡≥á‡≤∞‡≤ø‡≤µ‡≥Ü:  
- [ ] RLS ‡≤ú‡≥ä‡≤§‡≥Ü‡≤ó‡≥Ü ‡≤¨‡≤π‡≥Å-‡≤≠‡≤æ‡≤°‡≤ø‡≤ó‡≥Ü ‡≤∞‡≤ø‡≤ü‡≥á‡≤≤‡≥ç ‡≤µ‡≤ø‡≤∂‡≥ç‡≤≤‡≥á‡≤∑‡≤£‡≥Ü  
- [ ] ‡≤Ö‡≤ú‡≥Ç‡≤∞‡≥ç ‡≤ì‡≤™‡≤®‡≥ç‚Äå‡≤é‡≤ê ‡≤ú‡≥ä‡≤§‡≥Ü‡≤ó‡≥Ü ‡≤Ö‡≤∞‡≥ç‡≤•‡≤™‡≥Ç‡≤∞‡≥ç‡≤£ ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≤æ‡≤ü  
- [ ] ‡≤∏‡≤Æ‡≤ó‡≥ç‡≤∞ ‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≤æ ‡≤Ö‡≤®‡≥Å‡≤∑‡≥ç‡≤†‡≤æ‡≤®  
- [ ] ‡≤Ö‡≤ú‡≥Ç‡≤∞‡≥ç‚Äå‡≤®‡≤≤‡≥ç‡≤≤‡≤ø ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≤æ ‡≤®‡≤ø‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü  
- [ ] ‡≤Æ‡≥á‡≤≤‡≥ç‡≤µ‡≤ø‡≤ö‡≤æ‡≤∞‡≤£‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤é‡≤ö‡≥ç‡≤ö‡≤∞‡≤ø‡≤ï‡≥Ü ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤∏‡≥ç‡≤•‡≥Ü  
- [ ] ‡≤°‡≤æ‡≤ï‡≥ç‡≤Ø‡≥Å‡≤Æ‡≥Ü‡≤Ç‡≤ü‡≥á‡≤∂‡≤®‡≥ç ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤™‡≤∞‡≥Ä‡≤ï‡≥ç‡≤∑‡≥Ü

### ‡≤â‡≤®‡≥ç‡≤®‡≤§ ‡≤ï‡≤≤‡≤ø‡≤ï‡≥Ü‡≤Ø ‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ó‡≤ó‡≤≥‡≥Å

‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ MCP ‡≤™‡≥ç‡≤∞‡≤Ø‡≤æ‡≤£‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤∏‡≤ø:

- **MCP ‡≤µ‡≤æ‡≤∏‡≥ç‡≤§‡≥Å‡≤∂‡≤ø‡≤≤‡≥ç‡≤™ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤ó‡≤≥‡≥Å**: ‡≤â‡≤®‡≥ç‡≤®‡≤§ ‡≤Æ‡≤ü‡≥ç‡≤ü‡≤¶ ‡≤∏‡≤∞‡≥ç‡≤µ‡≤∞‡≥ç ‡≤µ‡≤æ‡≤∏‡≥ç‡≤§‡≥Å‡≤∂‡≤ø‡≤≤‡≥ç‡≤™‡≤ó‡≤≥‡≥Å  
- **‡≤¨‡≤π‡≥Å-‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤è‡≤ï‡≥Ä‡≤ï‡≤∞‡≤£**: ‡≤µ‡≤ø‡≤≠‡≤ø‡≤®‡≥ç‡≤® AI ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≤Ç‡≤Ø‡≥ã‡≤ú‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å  
- **‡≤é‡≤Ç‡≤ü‡≤∞‡≥ç‚Äå‡≤™‡≥ç‡≤∞‡≥à‡≤∏‡≥ç ‡≤µ‡≤ø‡≤∏‡≥ç‡≤§‡≤∞‡≤£‡≥Ü**: ‡≤¶‡≥ä‡≤°‡≥ç‡≤° ‡≤Æ‡≤ü‡≥ç‡≤ü‡≤¶ MCP ‡≤®‡≤ø‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü‡≤ó‡≤≥‡≥Å  
- **‡≤ï‡≤∏‡≥ç‡≤ü‡≤Æ‡≥ç ‡≤ü‡≥Ç‡≤≤‡≥ç ‡≤Ö‡≤≠‡≤ø‡≤µ‡≥É‡≤¶‡≥ç‡≤ß‡≤ø**: ‡≤µ‡≤ø‡≤∂‡≥á‡≤∑ MCP ‡≤â‡≤™‡≤ï‡≤∞‡≤£‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≤ø‡≤∞‡≥ç‡≤Æ‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å  
- **MCP ‡≤™‡≤∞‡≤ø‡≤∏‡≤∞ ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤∏‡≥ç‡≤•‡≥Ü**: ‡≤µ‡≥ç‡≤Ø‡≤æ‡≤™‡≤ï ‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø‡≤ï‡≥ç‡≤ï‡≥Ü ‡≤ï‡≥ä‡≤°‡≥Å‡≤ó‡≥Ü ‡≤®‡≥Ä‡≤°‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å

### ‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø‡≤§‡≥Ü

‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤∏‡≤æ‡≤ß‡≤®‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≤Ç‡≤ö‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤ø:  
- **GitHub ‡≤™‡≥ã‡≤∞‡≥ç‡≤ü‡≥ç‚Äå‡≤´‡≥ã‡≤≤‡≤ø‡≤Ø‡≥ä**: ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Ö‡≤®‡≥Å‡≤∑‡≥ç‡≤†‡≤æ‡≤®‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≤¶‡≤∞‡≥ç‡≤∂‡≤ø‡≤∏‡≤ø  
- **‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø ‡≤ï‡≥ä‡≤°‡≥Å‡≤ó‡≥Ü‡≤ó‡≤≥‡≥Å**: ‡≤∏‡≥Å‡≤ß‡≤æ‡≤∞‡≤£‡≥Ü‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤â‡≤¶‡≤æ‡≤π‡≤∞‡≤£‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≤≤‡≥ç‡≤≤‡≤ø‡≤∏‡≤ø  
- **‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≥Å‡≤µ ‡≤Ö‡≤µ‡≤ï‡≤æ‡≤∂‡≤ó‡≤≥‡≥Å**: ‡≤Æ‡≥Ä‡≤ü‡≤™‡≥ç‚Äå‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤∏‡≤Æ‡≥ç‡≤Æ‡≥á‡≤≥‡≤®‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤™‡≥ç‡≤∞‡≤∏‡≥ç‡≤§‡≥Å‡≤§‡≤™‡≤°‡≤ø‡≤∏‡≤ø  
- **‡≤Æ‡≥Ü‡≤Ç‡≤ü‡≤∞‡≤ø‡≤Ç‡≤ó‡≥ç**: ‡≤á‡≤§‡≤∞ ‡≤°‡≥Ü‡≤µ‡≤≤‡≤™‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü MCP ‡≤ï‡≤≤‡≤ø‡≤∏‡≤≤‡≥Å ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤Æ‡≤æ‡≤°‡≤ø

## üìö ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≥Å‡≤µ‡≤∞‡≤ø ‡≤∏‡≤Ç‡≤™‡≤®‡≥ç‡≤Æ‡≥Ç‡≤≤‡≤ó‡≤≥‡≥Å

### ‡≤â‡≤®‡≥ç‡≤®‡≤§ ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤ó‡≤≥‡≥Å
- [PostgreSQL ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ï‡≥ç‡≤∑‡≤Æ‡≤§‡≥Ü ‡≤ü‡≥ç‡≤Ø‡≥Ç‡≤®‡≤ø‡≤Ç‡≤ó‡≥ç](https://www.postgresql.org/docs/current/performance-tips.html) - ‡≤°‡≥á‡≤ü‡≤æ‡≤¨‡≥á‡≤∏‡≥ç ‡≤Ü‡≤™‡≥ç‡≤ü‡≤ø‡≤Æ‡≥à‡≤ú‡≥Ü‡≤∑‡≤®‡≥ç  
- [‡≤Ö‡≤ú‡≥Ç‡≤∞‡≥ç ‡≤ï‡≤Ç‡≤ü‡≥á‡≤®‡≤∞‡≥ç ‡≤Ö‡≤™‡≥ç‡≤∏‡≥ç ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤Ö‡≤≠‡≥ç‡≤Ø‡≤æ‡≤∏‡≤ó‡≤≥‡≥Å](https://docs.microsoft.com/azure/container-apps/overview) - ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≤æ ‡≤®‡≤ø‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü  
- [Python ‡≤Ö‡≤∏‡≤ø‡≤Ç‡≤ï‡≥ç ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤Ö‡≤≠‡≥ç‡≤Ø‡≤æ‡≤∏‡≤ó‡≤≥‡≥Å](https://docs.python.org/3/library/asyncio-dev.html) - ‡≤Ö‡≤∏‡≤ø‡≤Ç‡≤ï‡≥ç ‡≤™‡≥ç‡≤∞‡≥ã‡≤ó‡≥ç‡≤∞‡≤æ‡≤Æ‡≤ø‡≤Ç‡≤ó‡≥ç

### ‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≤æ ‡≤∏‡≤Ç‡≤™‡≤®‡≥ç‡≤Æ‡≥Ç‡≤≤‡≤ó‡≤≥‡≥Å
- [OWASP ‡≤ü‡≤æ‡≤™‡≥ç 10](https://owasp.org/www-project-top-ten/) - ‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≤æ ‡≤¶‡≥Å‡≤∞‡≥ç‡≤¨‡≤≤‡≤§‡≥Ü‡≤ó‡≤≥‡≥Å  
- [‡≤Ö‡≤ú‡≥Ç‡≤∞‡≥ç ‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≤æ ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤Ö‡≤≠‡≥ç‡≤Ø‡≤æ‡≤∏‡≤ó‡≤≥‡≥Å](https://docs.microsoft.com/azure/security/) - ‡≤ï‡≥ç‡≤≤‡≥å‡≤°‡≥ç ‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≥Ü  
- [Python ‡≤≠‡≤¶‡≥ç‡≤∞‡≤§‡≤æ ‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ó‡≤∏‡≥Ç‡≤ö‡≤ø‡≤ó‡≤≥‡≥Å](https://python.org/dev/security/) - ‡≤∏‡≥Å‡≤∞‡≤ï‡≥ç‡≤∑‡≤ø‡≤§ ‡≤ï‡≥ã‡≤°‡≤ø‡≤Ç‡≤ó‡≥ç

### ‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø
- [MCP ‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø ‡≤°‡≤ø‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞‡≥ç‡≤°‡≥ç](https://discord.com/invite/ByRwuEEgH4) - ‡≤®‡≥á‡≤∞ ‡≤ö‡≤∞‡≥ç‡≤ö‡≥Ü‡≤ó‡≤≥‡≥Å  
- [GitHub ‡≤ö‡≤∞‡≥ç‡≤ö‡≥Ü‡≤ó‡≤≥‡≥Å](https://github.com/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail/discussions) - ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥ã‡≤§‡≥ç‡≤§‡≤∞ ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤π‡≤Ç‡≤ö‡≤ø‡≤ï‡≥Ü  
- [‡≤∏‡≥ç‡≤ü‡≤æ‡≤ï‡≥ç ‡≤ì‡≤µ‡≤∞‡≥ç‚Äå‡≤´‡≥ç‡≤≤‡≥ã](https://stackoverflow.com/questions/tagged/model-context-protocol) - ‡≤§‡≤æ‡≤Ç‡≤§‡≥ç‡≤∞‡≤ø‡≤ï ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≥Å

---

**üéâ ‡≤Ö‡≤≠‡≤ø‡≤®‡≤Ç‡≤¶‡≤®‡≥Ü‡≤ó‡≤≥‡≥Å!** ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤∏‡≤Æ‡≤ó‡≥ç‡≤∞ MCP ‡≤°‡≥á‡≤ü‡≤æ‡≤¨‡≥á‡≤∏‡≥ç ‡≤è‡≤ï‡≥Ä‡≤ï‡≤∞‡≤£ ‡≤ï‡≤≤‡≤ø‡≤ï‡≥Ü‡≤Ø ‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ó‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥Ç‡≤∞‡≥ç‡≤£‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø. ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤à‡≤ó AI ‡≤∏‡≤π‡≤æ‡≤Ø‡≤ï‡≤∞‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≥à‡≤ú-‡≤ú‡≤ó‡≤§‡≥ç‡≤§‡≤ø‡≤® ‡≤°‡≥á‡≤ü‡≤æ ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤∏‡≥ç‡≤•‡≥Ü‡≤ó‡≤≥‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü ‡≤∏‡≥á‡≤∞‡≥Å‡≤µ ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß MCP ‡≤∏‡≤∞‡≥ç‡≤µ‡≤∞‡≥ç‚Äå‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≤ø‡≤∞‡≥ç‡≤Æ‡≤ø‡≤∏‡≤≤‡≥Å ‡≤ú‡≥ç‡≤û‡≤æ‡≤® ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤ï‡≥å‡≤∂‡≤≤‡≥ç‡≤Ø‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø.

**‡≤ï‡≥ä‡≤°‡≥Å‡≤ó‡≥Ü ‡≤®‡≥Ä‡≤°‡≤≤‡≥Å ‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß‡≤∞‡≤æ?** ‡≤®‡≤Æ‡≥ç‡≤Æ ‡≤∏‡≤Æ‡≥Å‡≤¶‡≤æ‡≤Ø‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤∏‡≥á‡≤∞‡≤ø ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Ö‡≤®‡≥Å‡≤≠‡≤µ‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≤Ç‡≤ö‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤ø, ‡≤ï‡≥ã‡≤°‡≥ç ‡≤∏‡≥Å‡≤ß‡≤æ‡≤∞‡≤£‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≥ä‡≤°‡≥Å‡≤ó‡≥Ü ‡≤®‡≥Ä‡≤°‡≤ø ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≥Å‡≤µ‡≤∞‡≤ø ‡≤ï‡≤≤‡≤ø‡≤ï‡≥Ü‡≤Ø ‡≤∏‡≤Ç‡≤™‡≤®‡≥ç‡≤Æ‡≥Ç‡≤≤‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤∞‡≤ö‡≤ø‡≤∏‡≤ø MCP ‡≤ï‡≤≤‡≤ø‡≤ï‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤Æ‡≤æ‡≤°‡≤ø.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**‡≤Ö‡≤∏‡≥ç‡≤µ‡≥Ä‡≤ï‡≤æ‡≤∞**:  
‡≤à ‡≤¶‡≤∏‡≥ç‡≤§‡≤æ‡≤µ‡≥á‡≤ú‡≥Å AI ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶ ‡≤∏‡≥á‡≤µ‡≥Ü [Co-op Translator](https://github.com/Azure/co-op-translator) ‡≤¨‡≤≥‡≤∏‡≤ø ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤®‡≤æ‡≤µ‡≥Å ‡≤®‡≤ø‡≤ñ‡≤∞‡≤§‡≥Ü‡≤Ø‡≤ø‡≤ó‡≤æ‡≤ó‡≤ø ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≤∞‡≥Ç, ‡≤∏‡≥ç‡≤µ‡≤Ø‡≤Ç‡≤ö‡≤æ‡≤≤‡≤ø‡≤§ ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤§‡≤™‡≥ç‡≤™‡≥Å‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤Ö‡≤∏‡≤§‡≥ç‡≤Ø‡≤§‡≥Ü‡≤ó‡≤≥‡≥Å ‡≤á‡≤∞‡≤¨‡≤π‡≥Å‡≤¶‡≥Å ‡≤é‡≤Ç‡≤¶‡≥Å ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤ó‡≤Æ‡≤®‡≤ø‡≤∏‡≤ø. ‡≤Æ‡≥Ç‡≤≤ ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤Æ‡≥Ç‡≤≤ ‡≤¶‡≤∏‡≥ç‡≤§‡≤æ‡≤µ‡≥á‡≤ú‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤ß‡≤ø‡≤ï‡≥É‡≤§ ‡≤Æ‡≥Ç‡≤≤‡≤µ‡≥Ü‡≤Ç‡≤¶‡≥Å ‡≤™‡≤∞‡≤ø‡≤ó‡≤£‡≤ø‡≤∏‡≤¨‡≥á‡≤ï‡≥Å. ‡≤™‡≥ç‡≤∞‡≤Æ‡≥Å‡≤ñ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤ó‡≤æ‡≤ó‡≤ø, ‡≤µ‡≥É‡≤§‡≥ç‡≤§‡≤ø‡≤™‡≤∞ ‡≤Æ‡≤æ‡≤®‡≤µ ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤∂‡≤ø‡≤´‡≤æ‡≤∞‡≤∏‡≥Å ‡≤Æ‡≤æ‡≤°‡≤≤‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü. ‡≤à ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶ ‡≤¨‡≤≥‡≤ï‡≥Ü‡≤Ø‡≤ø‡≤Ç‡≤¶ ‡≤â‡≤Ç‡≤ü‡≤æ‡≤ó‡≥Å‡≤µ ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤§‡≤™‡≥ç‡≤™‡≥Å ‡≤Ö‡≤∞‡≥ç‡≤•‡≤Æ‡≤æ‡≤°‡≤ø‡≤ï‡≥Ü‡≥Ç‡≤≥‡≥ç‡≤≥‡≥Å‡≤µ‡≤ø‡≤ï‡≥Ü ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤§‡≤™‡≥ç‡≤™‡≥Å ‡≤µ‡≤ø‡≤µ‡≤∞‡≤£‡≥Ü‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü ‡≤®‡≤æ‡≤µ‡≥Å ‡≤π‡≥ä‡≤£‡≥Ü‡≤ó‡≤æ‡≤∞‡≤∞‡≤æ‡≤ó‡≥Å‡≤µ‡≥Å‡≤¶‡≤ø‡≤≤‡≥ç‡≤≤.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->